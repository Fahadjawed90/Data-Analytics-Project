{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdYDZt5uuofH",
        "outputId": "489c6be6-791c-43cb-b290-339caeda8770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive/MyDrive/Ramanspec.csv\n",
            "          id  392.0cm-1  393.5cm-1  394.8cm-1  396.2cm-1  397.5cm-1  \\\n",
            "0          0   0.252686   0.591797   0.500488   0.335205   0.354492   \n",
            "1          1   0.313477   0.404541   0.434082   0.537598   0.467773   \n",
            "2          2   0.357666   0.383057   0.283936   0.356201   0.272461   \n",
            "3          3   0.294922   0.160889   0.185425   0.193115   0.170288   \n",
            "4          4   0.517090   0.337891   0.508789   0.395508   0.500977   \n",
            "...      ...        ...        ...        ...        ...        ...   \n",
            "46495  46495   0.314697   0.270508   0.275391   0.223022   0.252441   \n",
            "46496  46496   0.390137   0.355713   0.321045   0.226318   0.206787   \n",
            "46497  46497   0.296631   0.331543   0.309326   0.250732   0.348145   \n",
            "46498  46498   0.389404   0.332031   0.450928   0.270264   0.354004   \n",
            "46499  46499   0.343018   0.418213   0.483643   0.401855   0.349609   \n",
            "\n",
            "       399.0cm-1  400.5cm-1  401.8cm-1  403.2cm-1  ...  1779.0cm-1  \\\n",
            "0       0.508789   0.393066   0.448975   0.382324  ...    0.573242   \n",
            "1       0.422852   0.427490   0.382568   0.214111  ...    0.463867   \n",
            "2       0.297852   0.385742   0.239746   0.389648  ...    0.668945   \n",
            "3       0.093689   0.209229   0.166382   0.157227  ...    0.210449   \n",
            "4       0.409180   0.383301   0.466797   0.506348  ...    0.737793   \n",
            "...          ...        ...        ...        ...  ...         ...   \n",
            "46495   0.330811   0.262207   0.168823   0.255371  ...    0.414551   \n",
            "46496   0.262207   0.257568   0.463379   0.218506  ...    0.489258   \n",
            "46497   0.294678   0.376465   0.291992   0.373779  ...    0.276123   \n",
            "46498   0.331787   0.397949   0.375977   0.424316  ...    0.655273   \n",
            "46499   0.336670   0.343262   0.369385   0.434570  ...    0.503418   \n",
            "\n",
            "       1781.0cm-1  1782.0cm-1  1784.0cm-1  1785.0cm-1  1786.0cm-1  1788.0cm-1  \\\n",
            "0        0.364258    0.327637    0.438477    0.426514    0.488037    0.488281   \n",
            "1        0.267578    0.553711    0.480957    0.321777    0.595215    0.609375   \n",
            "2        0.279053    0.590332    0.262695    0.215332    0.495361    0.416992   \n",
            "3        0.308105    0.274658    0.136475    0.157227    0.350098    0.212524   \n",
            "4        0.715820    0.540527    0.583984    0.627930    0.518066    0.693359   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "46495    0.306641    0.312988    0.434082    0.203369    0.496094    0.387939   \n",
            "46496    0.400879    0.477539    0.343750    0.180176    0.467041    0.378662   \n",
            "46497    0.375000    0.328613    0.313232    0.349854    0.230835    0.413086   \n",
            "46498    0.814941    0.710449    0.588379    0.448730    0.555664    0.468994   \n",
            "46499    0.343750    0.468018    0.543457    0.334717    0.380615    0.377686   \n",
            "\n",
            "       1789.0cm-1  1791.0cm-1  label  \n",
            "0        0.513184    0.525879     15  \n",
            "1        0.747070    0.550781     25  \n",
            "2        0.385254    0.696289     26  \n",
            "3        0.156128    0.265137      1  \n",
            "4        0.364502    0.802734      7  \n",
            "...           ...         ...    ...  \n",
            "46495    0.328857    0.441650     21  \n",
            "46496    0.440186    0.501953     16  \n",
            "46497    0.096619    0.331055      0  \n",
            "46498    0.470215    0.612793     30  \n",
            "46499    0.266846    0.489014      5  \n",
            "\n",
            "[46500 rows x 1002 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!ls drive/MyDrive/Ramanspec.csv\n",
        "\n",
        "data = pd.read_csv('drive/MyDrive/Ramanspec.csv')\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Change this path to point to the actual location of your CSV file\n",
        "csv_path = \"/content/drive/MyDrive/Ramanspec.csv\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Extract columns from the DataFrame\n",
        "x = data['392.0cm-1']\n",
        "y = data['label']\n",
        "labels = data['label']\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(x, y, marker='o', linestyle='')\n",
        "\n",
        "# Add labels to the points\n",
        "for i, txt in enumerate(labels):\n",
        "    plt.annotate(txt, (x[i], y[i]))\n",
        "\n",
        "# Add labels to the axes and the title\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Plot with Labels')\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "YFcAtDQwIdfb",
        "outputId": "0e990158-64d2-4100-a4db-0acf382e9dd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "X=data.drop('label', axis=1).values\n",
        "y=data['label'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=26, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.fc1 = nn.Linear(input_size, 512)\n",
        "      self.fc2 = nn.Linear(512,256)\n",
        "      self.fc3 = nn.Linear(256,128)\n",
        "      self.fc4 = nn.Linear(128,output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = torch.relu(self.fc3(x))\n",
        "      x = self.fc4(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "model = MLP(input_size=X_train.shape[1], output_size=len(np.unique(y_train)))\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "  model.train()\n",
        "  for xb, yb in train_dataloader:\n",
        "    correct_cnt = 0\n",
        "    train_cnt = 0\n",
        "    losses = []\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(xb)\n",
        "    y_pred = torch.argmax(logits, dim=1)\n",
        "    correct = y_pred == yb\n",
        "    correct_cnt += correct.sum().item()\n",
        "    train_cnt += correct.size(0)\n",
        "    loss = criterion(logits, yb)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_losses = []\n",
        "      test_cnt = 0\n",
        "      tesr_correct_cnt = 0\n",
        "      for xt, yt in test_dataloader:\n",
        "        test_logits = model(xt)\n",
        "        test_loss = criterion(test_logits, yt)\n",
        "        test_pred = torch.argmax(test_logits, dim=1)\n",
        "        correct = test_pred == yt\n",
        "        tesr_correct_cnt += correct.sum().item()\n",
        "        test_cnt += correct.size(0)\n",
        "        test_losses.append(test_loss.item())\n",
        "\n",
        "      print(\"Epoch {0:d}: train loss {1:f} test loss {2:f}\".format(epoch, np.mean(losses), np.mean(test_losses)))\n",
        "      print(\"Epoch {0:d}: train acc {1:f} test acc {2:f}\".format(epoch, correct_cnt/train_cnt, tesr_correct_cnt/test_cnt))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8CBfdIX0z6dD",
        "outputId": "bd1407c1-da57-4736-92e1-4fded5455aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss 46.178383 test loss 48.740959\n",
            "Epoch 0: train acc 0.076923 test acc 0.031290\n",
            "Epoch 0: train loss 48.337410 test loss 45.897984\n",
            "Epoch 0: train acc 0.000000 test acc 0.032473\n",
            "Epoch 0: train loss 40.512016 test loss 40.692253\n",
            "Epoch 0: train acc 0.000000 test acc 0.031720\n",
            "Epoch 0: train loss 46.112625 test loss 35.695919\n",
            "Epoch 0: train acc 0.038462 test acc 0.033333\n",
            "Epoch 0: train loss 29.610138 test loss 29.936270\n",
            "Epoch 0: train acc 0.000000 test acc 0.030753\n",
            "Epoch 0: train loss 30.211439 test loss 26.279312\n",
            "Epoch 0: train acc 0.000000 test acc 0.032581\n",
            "Epoch 0: train loss 27.358189 test loss 22.998598\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 21.819496 test loss 19.871119\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 20.969063 test loss 20.500727\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 26.970772 test loss 19.815647\n",
            "Epoch 0: train acc 0.038462 test acc 0.029570\n",
            "Epoch 0: train loss 16.804741 test loss 18.698790\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 17.945986 test loss 18.718565\n",
            "Epoch 0: train acc 0.000000 test acc 0.029355\n",
            "Epoch 0: train loss 17.116936 test loss 17.983070\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 12.776855 test loss 16.561592\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 16.532787 test loss 14.870575\n",
            "Epoch 0: train acc 0.000000 test acc 0.031398\n",
            "Epoch 0: train loss 18.707289 test loss 14.706030\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 23.470783 test loss 14.326500\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 11.017838 test loss 13.650126\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 19.053860 test loss 12.433595\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 12.559630 test loss 11.662041\n",
            "Epoch 0: train acc 0.000000 test acc 0.030753\n",
            "Epoch 0: train loss 10.210998 test loss 11.634050\n",
            "Epoch 0: train acc 0.038462 test acc 0.030753\n",
            "Epoch 0: train loss 12.631135 test loss 10.986752\n",
            "Epoch 0: train acc 0.038462 test acc 0.030430\n",
            "Epoch 0: train loss 11.774744 test loss 10.139287\n",
            "Epoch 0: train acc 0.038462 test acc 0.031075\n",
            "Epoch 0: train loss 8.763299 test loss 9.702206\n",
            "Epoch 0: train acc 0.038462 test acc 0.031398\n",
            "Epoch 0: train loss 9.964069 test loss 9.013340\n",
            "Epoch 0: train acc 0.076923 test acc 0.031290\n",
            "Epoch 0: train loss 8.457093 test loss 8.274776\n",
            "Epoch 0: train acc 0.000000 test acc 0.031505\n",
            "Epoch 0: train loss 6.602915 test loss 7.834741\n",
            "Epoch 0: train acc 0.000000 test acc 0.035806\n",
            "Epoch 0: train loss 6.138534 test loss 7.249534\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 8.137194 test loss 7.061000\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 7.647671 test loss 7.187550\n",
            "Epoch 0: train acc 0.076923 test acc 0.039462\n",
            "Epoch 0: train loss 7.262362 test loss 6.884764\n",
            "Epoch 0: train acc 0.038462 test acc 0.031290\n",
            "Epoch 0: train loss 8.286894 test loss 6.740996\n",
            "Epoch 0: train acc 0.038462 test acc 0.035699\n",
            "Epoch 0: train loss 4.967164 test loss 6.781972\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 9.187091 test loss 6.614840\n",
            "Epoch 0: train acc 0.000000 test acc 0.031720\n",
            "Epoch 0: train loss 8.567669 test loss 6.477508\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 5.293167 test loss 6.285795\n",
            "Epoch 0: train acc 0.115385 test acc 0.033548\n",
            "Epoch 0: train loss 4.706015 test loss 6.067174\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 7.409777 test loss 5.564758\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 5.427820 test loss 5.345423\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 5.137391 test loss 5.239982\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 4.583932 test loss 5.072814\n",
            "Epoch 0: train acc 0.038462 test acc 0.033333\n",
            "Epoch 0: train loss 5.556987 test loss 4.937741\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 4.818114 test loss 4.916505\n",
            "Epoch 0: train acc 0.038462 test acc 0.035054\n",
            "Epoch 0: train loss 4.533140 test loss 4.704368\n",
            "Epoch 0: train acc 0.000000 test acc 0.031935\n",
            "Epoch 0: train loss 5.697334 test loss 4.627044\n",
            "Epoch 0: train acc 0.038462 test acc 0.035699\n",
            "Epoch 0: train loss 4.194589 test loss 4.579143\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 4.668396 test loss 4.536554\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 4.352302 test loss 4.383543\n",
            "Epoch 0: train acc 0.038462 test acc 0.032366\n",
            "Epoch 0: train loss 4.171129 test loss 4.220850\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.885181 test loss 4.133442\n",
            "Epoch 0: train acc 0.038462 test acc 0.030860\n",
            "Epoch 0: train loss 4.490131 test loss 4.129914\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 4.266493 test loss 4.192238\n",
            "Epoch 0: train acc 0.076923 test acc 0.034086\n",
            "Epoch 0: train loss 4.491935 test loss 4.296400\n",
            "Epoch 0: train acc 0.076923 test acc 0.032258\n",
            "Epoch 0: train loss 4.674752 test loss 4.194140\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 3.833316 test loss 4.202876\n",
            "Epoch 0: train acc 0.038462 test acc 0.029032\n",
            "Epoch 0: train loss 3.905338 test loss 4.118109\n",
            "Epoch 0: train acc 0.076923 test acc 0.031828\n",
            "Epoch 0: train loss 3.724791 test loss 3.996212\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 4.329568 test loss 4.038167\n",
            "Epoch 0: train acc 0.000000 test acc 0.033548\n",
            "Epoch 0: train loss 3.748701 test loss 4.087609\n",
            "Epoch 0: train acc 0.000000 test acc 0.037097\n",
            "Epoch 0: train loss 4.025665 test loss 3.893984\n",
            "Epoch 0: train acc 0.038462 test acc 0.030430\n",
            "Epoch 0: train loss 4.133165 test loss 3.708077\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 3.808430 test loss 3.838833\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 3.738026 test loss 3.961234\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 4.393634 test loss 3.968726\n",
            "Epoch 0: train acc 0.000000 test acc 0.031398\n",
            "Epoch 0: train loss 4.205184 test loss 3.927459\n",
            "Epoch 0: train acc 0.000000 test acc 0.029892\n",
            "Epoch 0: train loss 3.683592 test loss 4.014206\n",
            "Epoch 0: train acc 0.038462 test acc 0.031075\n",
            "Epoch 0: train loss 4.063930 test loss 4.196939\n",
            "Epoch 0: train acc 0.115385 test acc 0.031183\n",
            "Epoch 0: train loss 4.973161 test loss 4.078116\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 4.287625 test loss 4.270333\n",
            "Epoch 0: train acc 0.000000 test acc 0.030968\n",
            "Epoch 0: train loss 3.635592 test loss 4.342489\n",
            "Epoch 0: train acc 0.038462 test acc 0.029570\n",
            "Epoch 0: train loss 4.579400 test loss 3.899664\n",
            "Epoch 0: train acc 0.115385 test acc 0.031613\n",
            "Epoch 0: train loss 3.577265 test loss 3.867054\n",
            "Epoch 0: train acc 0.038462 test acc 0.032151\n",
            "Epoch 0: train loss 3.926294 test loss 3.970105\n",
            "Epoch 0: train acc 0.038462 test acc 0.031828\n",
            "Epoch 0: train loss 3.818390 test loss 4.035965\n",
            "Epoch 0: train acc 0.038462 test acc 0.032366\n",
            "Epoch 0: train loss 3.794123 test loss 4.172095\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 4.466189 test loss 4.178702\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 4.335539 test loss 3.982402\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.352590 test loss 4.184725\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 4.533095 test loss 4.142873\n",
            "Epoch 0: train acc 0.076923 test acc 0.035054\n",
            "Epoch 0: train loss 4.023373 test loss 3.887481\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.013454 test loss 3.948870\n",
            "Epoch 0: train acc 0.038462 test acc 0.030000\n",
            "Epoch 0: train loss 3.619138 test loss 4.166352\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 4.139966 test loss 4.324320\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.068836 test loss 4.183500\n",
            "Epoch 0: train acc 0.038462 test acc 0.037527\n",
            "Epoch 0: train loss 3.820477 test loss 3.992877\n",
            "Epoch 0: train acc 0.038462 test acc 0.039677\n",
            "Epoch 0: train loss 4.081255 test loss 4.020030\n",
            "Epoch 0: train acc 0.038462 test acc 0.030860\n",
            "Epoch 0: train loss 3.927588 test loss 4.066595\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 3.876826 test loss 4.074563\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.422248 test loss 4.088466\n",
            "Epoch 0: train acc 0.000000 test acc 0.029892\n",
            "Epoch 0: train loss 3.825566 test loss 3.965051\n",
            "Epoch 0: train acc 0.115385 test acc 0.032151\n",
            "Epoch 0: train loss 4.183612 test loss 4.020548\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 4.069391 test loss 3.896319\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.709356 test loss 3.970634\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 4.128631 test loss 4.068797\n",
            "Epoch 0: train acc 0.000000 test acc 0.047527\n",
            "Epoch 0: train loss 4.003344 test loss 4.074872\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.946316 test loss 4.091915\n",
            "Epoch 0: train acc 0.038462 test acc 0.032796\n",
            "Epoch 0: train loss 3.956788 test loss 4.019604\n",
            "Epoch 0: train acc 0.038462 test acc 0.030323\n",
            "Epoch 0: train loss 3.635948 test loss 4.014074\n",
            "Epoch 0: train acc 0.038462 test acc 0.030430\n",
            "Epoch 0: train loss 3.683824 test loss 4.189000\n",
            "Epoch 0: train acc 0.000000 test acc 0.031183\n",
            "Epoch 0: train loss 5.010775 test loss 4.136565\n",
            "Epoch 0: train acc 0.038462 test acc 0.030860\n",
            "Epoch 0: train loss 3.827569 test loss 4.001077\n",
            "Epoch 0: train acc 0.115385 test acc 0.029570\n",
            "Epoch 0: train loss 4.096839 test loss 3.838611\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 4.677711 test loss 3.738898\n",
            "Epoch 0: train acc 0.038462 test acc 0.034839\n",
            "Epoch 0: train loss 3.647827 test loss 3.801022\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.549246 test loss 3.997894\n",
            "Epoch 0: train acc 0.076923 test acc 0.035376\n",
            "Epoch 0: train loss 3.799609 test loss 4.211004\n",
            "Epoch 0: train acc 0.076923 test acc 0.035161\n",
            "Epoch 0: train loss 4.776838 test loss 4.100203\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 4.366642 test loss 4.034142\n",
            "Epoch 0: train acc 0.038462 test acc 0.039355\n",
            "Epoch 0: train loss 4.183219 test loss 4.197300\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 3.757643 test loss 4.559711\n",
            "Epoch 0: train acc 0.076923 test acc 0.033548\n",
            "Epoch 0: train loss 4.411881 test loss 4.413318\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.546440 test loss 4.169204\n",
            "Epoch 0: train acc 0.076923 test acc 0.033226\n",
            "Epoch 0: train loss 4.279408 test loss 4.059403\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 4.027728 test loss 4.089505\n",
            "Epoch 0: train acc 0.000000 test acc 0.031290\n",
            "Epoch 0: train loss 3.868871 test loss 4.133030\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.032389 test loss 4.134897\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 4.328035 test loss 4.058890\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 3.902789 test loss 4.161938\n",
            "Epoch 0: train acc 0.038462 test acc 0.030645\n",
            "Epoch 0: train loss 4.690772 test loss 4.201482\n",
            "Epoch 0: train acc 0.038462 test acc 0.030215\n",
            "Epoch 0: train loss 4.549918 test loss 4.116770\n",
            "Epoch 0: train acc 0.000000 test acc 0.030860\n",
            "Epoch 0: train loss 3.872803 test loss 4.014752\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 4.477573 test loss 4.120213\n",
            "Epoch 0: train acc 0.076923 test acc 0.031720\n",
            "Epoch 0: train loss 4.184426 test loss 4.218941\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 4.378056 test loss 4.275897\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.359490 test loss 4.381007\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 4.437205 test loss 4.246826\n",
            "Epoch 0: train acc 0.115385 test acc 0.032043\n",
            "Epoch 0: train loss 3.385249 test loss 4.513405\n",
            "Epoch 0: train acc 0.038462 test acc 0.030968\n",
            "Epoch 0: train loss 4.568380 test loss 4.361702\n",
            "Epoch 0: train acc 0.076923 test acc 0.030430\n",
            "Epoch 0: train loss 4.242099 test loss 4.082578\n",
            "Epoch 0: train acc 0.000000 test acc 0.034516\n",
            "Epoch 0: train loss 4.600617 test loss 3.931995\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 3.647209 test loss 3.938823\n",
            "Epoch 0: train acc 0.153846 test acc 0.031935\n",
            "Epoch 0: train loss 4.441554 test loss 3.896673\n",
            "Epoch 0: train acc 0.000000 test acc 0.032581\n",
            "Epoch 0: train loss 3.729278 test loss 3.977297\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 3.826712 test loss 4.092588\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 3.775198 test loss 4.051336\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 4.175839 test loss 3.948246\n",
            "Epoch 0: train acc 0.000000 test acc 0.044086\n",
            "Epoch 0: train loss 3.838056 test loss 3.999482\n",
            "Epoch 0: train acc 0.038462 test acc 0.054301\n",
            "Epoch 0: train loss 4.026237 test loss 3.982870\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 4.224110 test loss 3.897017\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 3.831058 test loss 3.911165\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 3.807212 test loss 3.875940\n",
            "Epoch 0: train acc 0.038462 test acc 0.032366\n",
            "Epoch 0: train loss 4.380988 test loss 3.776164\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 3.956586 test loss 3.843971\n",
            "Epoch 0: train acc 0.000000 test acc 0.040323\n",
            "Epoch 0: train loss 4.199900 test loss 3.867438\n",
            "Epoch 0: train acc 0.000000 test acc 0.046774\n",
            "Epoch 0: train loss 4.117785 test loss 3.902867\n",
            "Epoch 0: train acc 0.000000 test acc 0.034731\n",
            "Epoch 0: train loss 3.653257 test loss 4.129715\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.525000 test loss 4.260159\n",
            "Epoch 0: train acc 0.000000 test acc 0.032796\n",
            "Epoch 0: train loss 4.613205 test loss 4.076576\n",
            "Epoch 0: train acc 0.000000 test acc 0.032473\n",
            "Epoch 0: train loss 4.114930 test loss 4.055618\n",
            "Epoch 0: train acc 0.000000 test acc 0.041075\n",
            "Epoch 0: train loss 4.392090 test loss 4.014399\n",
            "Epoch 0: train acc 0.000000 test acc 0.038280\n",
            "Epoch 0: train loss 4.089307 test loss 4.014769\n",
            "Epoch 0: train acc 0.076923 test acc 0.031075\n",
            "Epoch 0: train loss 3.960015 test loss 4.038354\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 4.593323 test loss 3.910782\n",
            "Epoch 0: train acc 0.000000 test acc 0.028495\n",
            "Epoch 0: train loss 3.677438 test loss 4.277562\n",
            "Epoch 0: train acc 0.038462 test acc 0.029677\n",
            "Epoch 0: train loss 4.154209 test loss 4.217829\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 4.312168 test loss 4.162540\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 4.272285 test loss 4.373529\n",
            "Epoch 0: train acc 0.076923 test acc 0.035161\n",
            "Epoch 0: train loss 4.589531 test loss 4.354695\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 4.849907 test loss 4.061478\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 4.106215 test loss 3.982803\n",
            "Epoch 0: train acc 0.076923 test acc 0.032903\n",
            "Epoch 0: train loss 3.678108 test loss 3.944746\n",
            "Epoch 0: train acc 0.038462 test acc 0.035376\n",
            "Epoch 0: train loss 3.676121 test loss 4.149076\n",
            "Epoch 0: train acc 0.076923 test acc 0.035161\n",
            "Epoch 0: train loss 4.349465 test loss 4.249457\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 4.781894 test loss 4.425508\n",
            "Epoch 0: train acc 0.076923 test acc 0.032473\n",
            "Epoch 0: train loss 4.174658 test loss 4.204603\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.292266 test loss 4.208654\n",
            "Epoch 0: train acc 0.153846 test acc 0.032043\n",
            "Epoch 0: train loss 3.936831 test loss 4.137887\n",
            "Epoch 0: train acc 0.115385 test acc 0.032366\n",
            "Epoch 0: train loss 4.611827 test loss 4.060912\n",
            "Epoch 0: train acc 0.000000 test acc 0.030753\n",
            "Epoch 0: train loss 3.750395 test loss 4.150110\n",
            "Epoch 0: train acc 0.115385 test acc 0.032151\n",
            "Epoch 0: train loss 3.726841 test loss 4.362501\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.227382 test loss 4.478220\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 4.319501 test loss 4.407322\n",
            "Epoch 0: train acc 0.115385 test acc 0.033871\n",
            "Epoch 0: train loss 4.321648 test loss 4.428305\n",
            "Epoch 0: train acc 0.038462 test acc 0.029462\n",
            "Epoch 0: train loss 3.824400 test loss 4.571408\n",
            "Epoch 0: train acc 0.038462 test acc 0.031935\n",
            "Epoch 0: train loss 4.874124 test loss 4.560324\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 4.672236 test loss 4.567509\n",
            "Epoch 0: train acc 0.000000 test acc 0.038280\n",
            "Epoch 0: train loss 5.427817 test loss 4.532357\n",
            "Epoch 0: train acc 0.000000 test acc 0.048925\n",
            "Epoch 0: train loss 3.668658 test loss 4.563563\n",
            "Epoch 0: train acc 0.076923 test acc 0.057312\n",
            "Epoch 0: train loss 4.569372 test loss 4.542433\n",
            "Epoch 0: train acc 0.076923 test acc 0.035376\n",
            "Epoch 0: train loss 4.705513 test loss 4.397237\n",
            "Epoch 0: train acc 0.038462 test acc 0.033656\n",
            "Epoch 0: train loss 3.866188 test loss 4.197681\n",
            "Epoch 0: train acc 0.038462 test acc 0.035161\n",
            "Epoch 0: train loss 4.375163 test loss 4.139016\n",
            "Epoch 0: train acc 0.115385 test acc 0.029892\n",
            "Epoch 0: train loss 4.211036 test loss 4.092207\n",
            "Epoch 0: train acc 0.076923 test acc 0.030000\n",
            "Epoch 0: train loss 3.865916 test loss 4.142570\n",
            "Epoch 0: train acc 0.038462 test acc 0.033871\n",
            "Epoch 0: train loss 4.555042 test loss 4.173005\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 4.740130 test loss 4.124707\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 4.694222 test loss 4.042707\n",
            "Epoch 0: train acc 0.000000 test acc 0.030645\n",
            "Epoch 0: train loss 4.202803 test loss 3.943970\n",
            "Epoch 0: train acc 0.000000 test acc 0.057849\n",
            "Epoch 0: train loss 4.170322 test loss 4.070875\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 3.661927 test loss 4.334695\n",
            "Epoch 0: train acc 0.038462 test acc 0.034839\n",
            "Epoch 0: train loss 4.571733 test loss 4.145505\n",
            "Epoch 0: train acc 0.000000 test acc 0.032796\n",
            "Epoch 0: train loss 3.765409 test loss 4.072060\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 4.187459 test loss 4.036650\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 4.647369 test loss 3.953099\n",
            "Epoch 0: train acc 0.000000 test acc 0.031183\n",
            "Epoch 0: train loss 4.036479 test loss 3.945982\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 3.915355 test loss 3.903726\n",
            "Epoch 0: train acc 0.038462 test acc 0.031398\n",
            "Epoch 0: train loss 4.243688 test loss 4.059682\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 4.252987 test loss 3.937120\n",
            "Epoch 0: train acc 0.076923 test acc 0.038710\n",
            "Epoch 0: train loss 3.716940 test loss 4.243111\n",
            "Epoch 0: train acc 0.038462 test acc 0.034624\n",
            "Epoch 0: train loss 4.394122 test loss 4.009143\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 3.769546 test loss 3.913225\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.203900 test loss 3.972264\n",
            "Epoch 0: train acc 0.038462 test acc 0.030860\n",
            "Epoch 0: train loss 4.107388 test loss 3.917499\n",
            "Epoch 0: train acc 0.000000 test acc 0.030860\n",
            "Epoch 0: train loss 4.120540 test loss 3.818261\n",
            "Epoch 0: train acc 0.038462 test acc 0.045806\n",
            "Epoch 0: train loss 4.379499 test loss 3.916888\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 4.075122 test loss 3.883813\n",
            "Epoch 0: train acc 0.038462 test acc 0.035054\n",
            "Epoch 0: train loss 3.941921 test loss 3.728178\n",
            "Epoch 0: train acc 0.000000 test acc 0.054839\n",
            "Epoch 0: train loss 3.593595 test loss 3.771938\n",
            "Epoch 0: train acc 0.000000 test acc 0.041720\n",
            "Epoch 0: train loss 3.564352 test loss 3.866286\n",
            "Epoch 0: train acc 0.115385 test acc 0.040753\n",
            "Epoch 0: train loss 4.141862 test loss 3.913822\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 3.763165 test loss 4.056594\n",
            "Epoch 0: train acc 0.076923 test acc 0.032258\n",
            "Epoch 0: train loss 4.325532 test loss 3.979323\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 3.806150 test loss 3.941089\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.078115 test loss 3.791854\n",
            "Epoch 0: train acc 0.076923 test acc 0.032043\n",
            "Epoch 0: train loss 3.355089 test loss 3.836957\n",
            "Epoch 0: train acc 0.000000 test acc 0.054839\n",
            "Epoch 0: train loss 3.927641 test loss 3.888709\n",
            "Epoch 0: train acc 0.076923 test acc 0.049785\n",
            "Epoch 0: train loss 3.657381 test loss 3.789277\n",
            "Epoch 0: train acc 0.038462 test acc 0.030645\n",
            "Epoch 0: train loss 4.139273 test loss 3.796411\n",
            "Epoch 0: train acc 0.000000 test acc 0.032366\n",
            "Epoch 0: train loss 3.978105 test loss 4.080356\n",
            "Epoch 0: train acc 0.038462 test acc 0.030645\n",
            "Epoch 0: train loss 3.801031 test loss 4.364708\n",
            "Epoch 0: train acc 0.115385 test acc 0.030538\n",
            "Epoch 0: train loss 4.401347 test loss 4.239693\n",
            "Epoch 0: train acc 0.038462 test acc 0.034731\n",
            "Epoch 0: train loss 4.786500 test loss 4.098716\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.010515 test loss 3.846101\n",
            "Epoch 0: train acc 0.038462 test acc 0.039462\n",
            "Epoch 0: train loss 3.706226 test loss 3.871259\n",
            "Epoch 0: train acc 0.076923 test acc 0.035806\n",
            "Epoch 0: train loss 3.784845 test loss 4.067867\n",
            "Epoch 0: train acc 0.038462 test acc 0.035484\n",
            "Epoch 0: train loss 3.745426 test loss 4.137915\n",
            "Epoch 0: train acc 0.000000 test acc 0.036022\n",
            "Epoch 0: train loss 4.049110 test loss 4.067247\n",
            "Epoch 0: train acc 0.076923 test acc 0.032258\n",
            "Epoch 0: train loss 3.760833 test loss 4.064630\n",
            "Epoch 0: train acc 0.000000 test acc 0.039355\n",
            "Epoch 0: train loss 4.191051 test loss 4.038567\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 3.840694 test loss 4.020542\n",
            "Epoch 0: train acc 0.038462 test acc 0.057957\n",
            "Epoch 0: train loss 3.905913 test loss 4.070324\n",
            "Epoch 0: train acc 0.000000 test acc 0.031505\n",
            "Epoch 0: train loss 4.013311 test loss 4.277929\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 4.059702 test loss 4.128085\n",
            "Epoch 0: train acc 0.076923 test acc 0.035269\n",
            "Epoch 0: train loss 4.049192 test loss 4.053028\n",
            "Epoch 0: train acc 0.000000 test acc 0.057204\n",
            "Epoch 0: train loss 3.724032 test loss 4.203410\n",
            "Epoch 0: train acc 0.115385 test acc 0.039462\n",
            "Epoch 0: train loss 4.768244 test loss 4.077485\n",
            "Epoch 0: train acc 0.076923 test acc 0.032581\n",
            "Epoch 0: train loss 3.672224 test loss 4.136614\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 3.854574 test loss 4.188178\n",
            "Epoch 0: train acc 0.000000 test acc 0.036237\n",
            "Epoch 0: train loss 3.993191 test loss 4.202496\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.428175 test loss 4.188831\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 4.010922 test loss 4.120285\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 5.059322 test loss 4.065737\n",
            "Epoch 0: train acc 0.000000 test acc 0.032366\n",
            "Epoch 0: train loss 4.959955 test loss 4.596181\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.436624 test loss 4.486228\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 4.622095 test loss 4.511864\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 4.214072 test loss 4.358495\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.873915 test loss 4.300314\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 4.226232 test loss 4.133337\n",
            "Epoch 0: train acc 0.000000 test acc 0.036774\n",
            "Epoch 0: train loss 4.333661 test loss 4.171392\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 4.250216 test loss 4.231566\n",
            "Epoch 0: train acc 0.038462 test acc 0.035269\n",
            "Epoch 0: train loss 3.893184 test loss 4.253096\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 4.147262 test loss 4.125947\n",
            "Epoch 0: train acc 0.076923 test acc 0.034946\n",
            "Epoch 0: train loss 4.223973 test loss 4.047733\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 4.337817 test loss 4.014315\n",
            "Epoch 0: train acc 0.000000 test acc 0.030108\n",
            "Epoch 0: train loss 4.529698 test loss 3.986880\n",
            "Epoch 0: train acc 0.076923 test acc 0.034731\n",
            "Epoch 0: train loss 3.912119 test loss 4.076572\n",
            "Epoch 0: train acc 0.000000 test acc 0.036452\n",
            "Epoch 0: train loss 3.980980 test loss 4.099551\n",
            "Epoch 0: train acc 0.076923 test acc 0.034409\n",
            "Epoch 0: train loss 3.959992 test loss 4.133958\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 4.219878 test loss 4.080754\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 3.882475 test loss 4.119542\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 3.669012 test loss 4.080948\n",
            "Epoch 0: train acc 0.038462 test acc 0.030323\n",
            "Epoch 0: train loss 4.118911 test loss 4.048161\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 3.978476 test loss 3.995431\n",
            "Epoch 0: train acc 0.000000 test acc 0.031935\n",
            "Epoch 0: train loss 4.089342 test loss 3.931990\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 4.187063 test loss 4.032962\n",
            "Epoch 0: train acc 0.038462 test acc 0.030860\n",
            "Epoch 0: train loss 3.880083 test loss 4.120950\n",
            "Epoch 0: train acc 0.076923 test acc 0.030645\n",
            "Epoch 0: train loss 4.508008 test loss 3.738028\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 3.734294 test loss 3.870187\n",
            "Epoch 0: train acc 0.000000 test acc 0.036774\n",
            "Epoch 0: train loss 3.779430 test loss 4.182110\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 4.428310 test loss 4.009868\n",
            "Epoch 0: train acc 0.000000 test acc 0.033333\n",
            "Epoch 0: train loss 3.938898 test loss 4.049917\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 4.095411 test loss 3.994178\n",
            "Epoch 0: train acc 0.000000 test acc 0.050753\n",
            "Epoch 0: train loss 3.703643 test loss 4.055950\n",
            "Epoch 0: train acc 0.076923 test acc 0.051290\n",
            "Epoch 0: train loss 3.597564 test loss 4.275592\n",
            "Epoch 0: train acc 0.115385 test acc 0.047419\n",
            "Epoch 0: train loss 4.020697 test loss 4.390147\n",
            "Epoch 0: train acc 0.115385 test acc 0.055484\n",
            "Epoch 0: train loss 4.539332 test loss 4.131836\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 4.158813 test loss 4.104580\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.544929 test loss 4.197087\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.953313 test loss 4.275915\n",
            "Epoch 0: train acc 0.153846 test acc 0.039570\n",
            "Epoch 0: train loss 4.026664 test loss 4.336958\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 4.114577 test loss 4.245514\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 4.196908 test loss 4.099992\n",
            "Epoch 0: train acc 0.000000 test acc 0.039570\n",
            "Epoch 0: train loss 3.835491 test loss 4.135377\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 4.617564 test loss 4.153738\n",
            "Epoch 0: train acc 0.038462 test acc 0.034516\n",
            "Epoch 0: train loss 3.733572 test loss 4.228983\n",
            "Epoch 0: train acc 0.076923 test acc 0.034086\n",
            "Epoch 0: train loss 4.270650 test loss 4.103794\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 4.412431 test loss 4.217505\n",
            "Epoch 0: train acc 0.076923 test acc 0.033548\n",
            "Epoch 0: train loss 4.173887 test loss 4.047585\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 3.730095 test loss 4.001129\n",
            "Epoch 0: train acc 0.076923 test acc 0.033118\n",
            "Epoch 0: train loss 4.803080 test loss 3.796919\n",
            "Epoch 0: train acc 0.000000 test acc 0.032366\n",
            "Epoch 0: train loss 3.673017 test loss 3.749433\n",
            "Epoch 0: train acc 0.000000 test acc 0.032581\n",
            "Epoch 0: train loss 3.949330 test loss 3.964640\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 4.034822 test loss 4.013828\n",
            "Epoch 0: train acc 0.076923 test acc 0.030430\n",
            "Epoch 0: train loss 4.448653 test loss 3.786168\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 3.828923 test loss 3.759255\n",
            "Epoch 0: train acc 0.038462 test acc 0.034624\n",
            "Epoch 0: train loss 3.306050 test loss 4.145219\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 3.972646 test loss 4.283403\n",
            "Epoch 0: train acc 0.038462 test acc 0.035591\n",
            "Epoch 0: train loss 4.651807 test loss 3.969167\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.197713 test loss 3.811103\n",
            "Epoch 0: train acc 0.038462 test acc 0.059355\n",
            "Epoch 0: train loss 3.772848 test loss 3.946644\n",
            "Epoch 0: train acc 0.038462 test acc 0.052688\n",
            "Epoch 0: train loss 3.410534 test loss 4.174522\n",
            "Epoch 0: train acc 0.115385 test acc 0.039892\n",
            "Epoch 0: train loss 4.131775 test loss 4.121740\n",
            "Epoch 0: train acc 0.038462 test acc 0.029892\n",
            "Epoch 0: train loss 3.983262 test loss 4.245035\n",
            "Epoch 0: train acc 0.000000 test acc 0.031935\n",
            "Epoch 0: train loss 4.107090 test loss 4.632185\n",
            "Epoch 0: train acc 0.076923 test acc 0.032258\n",
            "Epoch 0: train loss 4.475177 test loss 4.540986\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 4.121686 test loss 4.426017\n",
            "Epoch 0: train acc 0.076923 test acc 0.031720\n",
            "Epoch 0: train loss 4.371773 test loss 4.227808\n",
            "Epoch 0: train acc 0.038462 test acc 0.031398\n",
            "Epoch 0: train loss 4.698444 test loss 4.226723\n",
            "Epoch 0: train acc 0.000000 test acc 0.031183\n",
            "Epoch 0: train loss 4.012994 test loss 4.289843\n",
            "Epoch 0: train acc 0.115385 test acc 0.031505\n",
            "Epoch 0: train loss 5.341771 test loss 4.219852\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 3.982303 test loss 4.143973\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 4.686228 test loss 3.948328\n",
            "Epoch 0: train acc 0.038462 test acc 0.030000\n",
            "Epoch 0: train loss 3.958384 test loss 3.919856\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 4.137689 test loss 4.090758\n",
            "Epoch 0: train acc 0.038462 test acc 0.048925\n",
            "Epoch 0: train loss 3.896198 test loss 4.237117\n",
            "Epoch 0: train acc 0.000000 test acc 0.042796\n",
            "Epoch 0: train loss 4.482442 test loss 4.306731\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.290859 test loss 4.338317\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.583376 test loss 4.133555\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 4.193285 test loss 4.400365\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 5.047057 test loss 4.306931\n",
            "Epoch 0: train acc 0.000000 test acc 0.031398\n",
            "Epoch 0: train loss 4.396897 test loss 4.492743\n",
            "Epoch 0: train acc 0.038462 test acc 0.029892\n",
            "Epoch 0: train loss 3.451342 test loss 4.658816\n",
            "Epoch 0: train acc 0.076923 test acc 0.031183\n",
            "Epoch 0: train loss 4.295321 test loss 4.467895\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 4.027398 test loss 4.541375\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 5.299307 test loss 4.399673\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 4.195480 test loss 4.273832\n",
            "Epoch 0: train acc 0.000000 test acc 0.039892\n",
            "Epoch 0: train loss 3.975611 test loss 4.188327\n",
            "Epoch 0: train acc 0.000000 test acc 0.041613\n",
            "Epoch 0: train loss 4.100190 test loss 4.162520\n",
            "Epoch 0: train acc 0.038462 test acc 0.058710\n",
            "Epoch 0: train loss 4.982872 test loss 4.307712\n",
            "Epoch 0: train acc 0.038462 test acc 0.052258\n",
            "Epoch 0: train loss 4.242892 test loss 4.291845\n",
            "Epoch 0: train acc 0.076923 test acc 0.052151\n",
            "Epoch 0: train loss 3.919847 test loss 4.210850\n",
            "Epoch 0: train acc 0.000000 test acc 0.047957\n",
            "Epoch 0: train loss 4.261964 test loss 4.073018\n",
            "Epoch 0: train acc 0.000000 test acc 0.032366\n",
            "Epoch 0: train loss 3.886719 test loss 4.172470\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 4.098103 test loss 4.059146\n",
            "Epoch 0: train acc 0.076923 test acc 0.036882\n",
            "Epoch 0: train loss 4.288714 test loss 3.995073\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.792372 test loss 3.955187\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 4.150896 test loss 3.996709\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.317864 test loss 4.064039\n",
            "Epoch 0: train acc 0.000000 test acc 0.030753\n",
            "Epoch 0: train loss 3.891297 test loss 3.983657\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 3.927742 test loss 3.832682\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 3.873081 test loss 3.917201\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 3.391278 test loss 4.090221\n",
            "Epoch 0: train acc 0.076923 test acc 0.032043\n",
            "Epoch 0: train loss 3.704492 test loss 4.131196\n",
            "Epoch 0: train acc 0.000000 test acc 0.031720\n",
            "Epoch 0: train loss 3.965898 test loss 4.178287\n",
            "Epoch 0: train acc 0.000000 test acc 0.032796\n",
            "Epoch 0: train loss 3.996779 test loss 4.083847\n",
            "Epoch 0: train acc 0.000000 test acc 0.044946\n",
            "Epoch 0: train loss 3.941350 test loss 4.060438\n",
            "Epoch 0: train acc 0.000000 test acc 0.054409\n",
            "Epoch 0: train loss 3.898880 test loss 4.009611\n",
            "Epoch 0: train acc 0.000000 test acc 0.047419\n",
            "Epoch 0: train loss 3.659742 test loss 3.972836\n",
            "Epoch 0: train acc 0.076923 test acc 0.055699\n",
            "Epoch 0: train loss 4.071179 test loss 3.994655\n",
            "Epoch 0: train acc 0.115385 test acc 0.035269\n",
            "Epoch 0: train loss 4.204714 test loss 4.012990\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 3.518258 test loss 4.168809\n",
            "Epoch 0: train acc 0.115385 test acc 0.032151\n",
            "Epoch 0: train loss 3.977773 test loss 4.076320\n",
            "Epoch 0: train acc 0.000000 test acc 0.032796\n",
            "Epoch 0: train loss 4.172984 test loss 3.984802\n",
            "Epoch 0: train acc 0.076923 test acc 0.033548\n",
            "Epoch 0: train loss 3.604858 test loss 4.227802\n",
            "Epoch 0: train acc 0.076923 test acc 0.033226\n",
            "Epoch 0: train loss 4.494790 test loss 4.166539\n",
            "Epoch 0: train acc 0.038462 test acc 0.033333\n",
            "Epoch 0: train loss 4.137051 test loss 4.024098\n",
            "Epoch 0: train acc 0.000000 test acc 0.055699\n",
            "Epoch 0: train loss 4.046660 test loss 3.934907\n",
            "Epoch 0: train acc 0.076923 test acc 0.039355\n",
            "Epoch 0: train loss 4.162703 test loss 3.836305\n",
            "Epoch 0: train acc 0.000000 test acc 0.039570\n",
            "Epoch 0: train loss 3.659284 test loss 3.870113\n",
            "Epoch 0: train acc 0.000000 test acc 0.043871\n",
            "Epoch 0: train loss 4.203197 test loss 3.928388\n",
            "Epoch 0: train acc 0.076923 test acc 0.038065\n",
            "Epoch 0: train loss 3.737523 test loss 3.918982\n",
            "Epoch 0: train acc 0.000000 test acc 0.038065\n",
            "Epoch 0: train loss 3.724088 test loss 3.952615\n",
            "Epoch 0: train acc 0.038462 test acc 0.036882\n",
            "Epoch 0: train loss 4.012729 test loss 3.959958\n",
            "Epoch 0: train acc 0.000000 test acc 0.031183\n",
            "Epoch 0: train loss 3.759285 test loss 3.918968\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 4.002721 test loss 3.884886\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 3.959436 test loss 3.760368\n",
            "Epoch 0: train acc 0.038462 test acc 0.031398\n",
            "Epoch 0: train loss 4.112823 test loss 3.690039\n",
            "Epoch 0: train acc 0.000000 test acc 0.036237\n",
            "Epoch 0: train loss 3.643275 test loss 3.927129\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 3.632986 test loss 3.957239\n",
            "Epoch 0: train acc 0.076923 test acc 0.036129\n",
            "Epoch 0: train loss 3.710067 test loss 4.184546\n",
            "Epoch 0: train acc 0.076923 test acc 0.035591\n",
            "Epoch 0: train loss 3.877882 test loss 4.155141\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 3.897709 test loss 4.203285\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 4.638174 test loss 4.102118\n",
            "Epoch 0: train acc 0.000000 test acc 0.030430\n",
            "Epoch 0: train loss 3.908469 test loss 4.175647\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 4.552807 test loss 4.093444\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.970152 test loss 3.896835\n",
            "Epoch 0: train acc 0.038462 test acc 0.030215\n",
            "Epoch 0: train loss 3.729735 test loss 3.844390\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 4.042600 test loss 3.931321\n",
            "Epoch 0: train acc 0.000000 test acc 0.034301\n",
            "Epoch 0: train loss 3.725483 test loss 3.852452\n",
            "Epoch 0: train acc 0.038462 test acc 0.046344\n",
            "Epoch 0: train loss 3.860053 test loss 3.851714\n",
            "Epoch 0: train acc 0.076923 test acc 0.048065\n",
            "Epoch 0: train loss 3.866181 test loss 3.760175\n",
            "Epoch 0: train acc 0.076923 test acc 0.042796\n",
            "Epoch 0: train loss 3.790040 test loss 3.692700\n",
            "Epoch 0: train acc 0.038462 test acc 0.043226\n",
            "Epoch 0: train loss 3.409585 test loss 3.834083\n",
            "Epoch 0: train acc 0.076923 test acc 0.033226\n",
            "Epoch 0: train loss 3.459826 test loss 3.927605\n",
            "Epoch 0: train acc 0.000000 test acc 0.076129\n",
            "Epoch 0: train loss 4.228565 test loss 3.937207\n",
            "Epoch 0: train acc 0.038462 test acc 0.054731\n",
            "Epoch 0: train loss 3.507921 test loss 4.081113\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 3.901831 test loss 4.126626\n",
            "Epoch 0: train acc 0.000000 test acc 0.053656\n",
            "Epoch 0: train loss 3.892888 test loss 4.147400\n",
            "Epoch 0: train acc 0.038462 test acc 0.052151\n",
            "Epoch 0: train loss 4.681185 test loss 4.117562\n",
            "Epoch 0: train acc 0.000000 test acc 0.030000\n",
            "Epoch 0: train loss 4.673447 test loss 3.812165\n",
            "Epoch 0: train acc 0.000000 test acc 0.038280\n",
            "Epoch 0: train loss 3.382981 test loss 4.109114\n",
            "Epoch 0: train acc 0.000000 test acc 0.030753\n",
            "Epoch 0: train loss 3.972918 test loss 4.428701\n",
            "Epoch 0: train acc 0.038462 test acc 0.030753\n",
            "Epoch 0: train loss 4.264126 test loss 4.196175\n",
            "Epoch 0: train acc 0.000000 test acc 0.037742\n",
            "Epoch 0: train loss 4.186996 test loss 4.300328\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 4.844062 test loss 4.201667\n",
            "Epoch 0: train acc 0.038462 test acc 0.035699\n",
            "Epoch 0: train loss 3.831767 test loss 4.098349\n",
            "Epoch 0: train acc 0.038462 test acc 0.032258\n",
            "Epoch 0: train loss 4.313079 test loss 4.087857\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 4.243225 test loss 4.107394\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.871790 test loss 3.973222\n",
            "Epoch 0: train acc 0.000000 test acc 0.034301\n",
            "Epoch 0: train loss 4.392143 test loss 4.036403\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 4.176126 test loss 4.013864\n",
            "Epoch 0: train acc 0.076923 test acc 0.034194\n",
            "Epoch 0: train loss 3.960721 test loss 3.900194\n",
            "Epoch 0: train acc 0.038462 test acc 0.056022\n",
            "Epoch 0: train loss 4.156262 test loss 3.895317\n",
            "Epoch 0: train acc 0.153846 test acc 0.032258\n",
            "Epoch 0: train loss 4.651079 test loss 3.928856\n",
            "Epoch 0: train acc 0.000000 test acc 0.031828\n",
            "Epoch 0: train loss 4.035191 test loss 3.945813\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 3.780953 test loss 4.036264\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.259682 test loss 4.071537\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.342074 test loss 4.154594\n",
            "Epoch 0: train acc 0.038462 test acc 0.038817\n",
            "Epoch 0: train loss 4.412968 test loss 4.172083\n",
            "Epoch 0: train acc 0.038462 test acc 0.033871\n",
            "Epoch 0: train loss 4.450932 test loss 4.051458\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.567541 test loss 3.993695\n",
            "Epoch 0: train acc 0.038462 test acc 0.048925\n",
            "Epoch 0: train loss 3.712496 test loss 4.025573\n",
            "Epoch 0: train acc 0.076923 test acc 0.052151\n",
            "Epoch 0: train loss 4.158484 test loss 4.229344\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 4.363497 test loss 4.192966\n",
            "Epoch 0: train acc 0.038462 test acc 0.047097\n",
            "Epoch 0: train loss 4.208025 test loss 3.967471\n",
            "Epoch 0: train acc 0.076923 test acc 0.053656\n",
            "Epoch 0: train loss 3.706797 test loss 4.392802\n",
            "Epoch 0: train acc 0.153846 test acc 0.029892\n",
            "Epoch 0: train loss 4.174731 test loss 4.130714\n",
            "Epoch 0: train acc 0.115385 test acc 0.030430\n",
            "Epoch 0: train loss 4.780190 test loss 4.147330\n",
            "Epoch 0: train acc 0.000000 test acc 0.031613\n",
            "Epoch 0: train loss 4.389449 test loss 4.134346\n",
            "Epoch 0: train acc 0.000000 test acc 0.030645\n",
            "Epoch 0: train loss 4.299007 test loss 4.081277\n",
            "Epoch 0: train acc 0.000000 test acc 0.034731\n",
            "Epoch 0: train loss 3.757613 test loss 3.993048\n",
            "Epoch 0: train acc 0.038462 test acc 0.035591\n",
            "Epoch 0: train loss 4.355345 test loss 3.870510\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 3.509018 test loss 3.990835\n",
            "Epoch 0: train acc 0.000000 test acc 0.032473\n",
            "Epoch 0: train loss 3.869257 test loss 4.052861\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 4.596482 test loss 3.930243\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 3.676012 test loss 3.934033\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 3.828511 test loss 3.921965\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 3.644588 test loss 4.009007\n",
            "Epoch 0: train acc 0.000000 test acc 0.057527\n",
            "Epoch 0: train loss 3.457771 test loss 4.144670\n",
            "Epoch 0: train acc 0.038462 test acc 0.056022\n",
            "Epoch 0: train loss 4.124969 test loss 4.177635\n",
            "Epoch 0: train acc 0.076923 test acc 0.044946\n",
            "Epoch 0: train loss 3.960134 test loss 4.229694\n",
            "Epoch 0: train acc 0.076923 test acc 0.033226\n",
            "Epoch 0: train loss 4.720815 test loss 4.164509\n",
            "Epoch 0: train acc 0.038462 test acc 0.035699\n",
            "Epoch 0: train loss 4.329683 test loss 4.051480\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 3.843747 test loss 3.944735\n",
            "Epoch 0: train acc 0.038462 test acc 0.057742\n",
            "Epoch 0: train loss 3.937457 test loss 3.989522\n",
            "Epoch 0: train acc 0.076923 test acc 0.056344\n",
            "Epoch 0: train loss 4.293413 test loss 3.965552\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 3.774041 test loss 4.030684\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.841234 test loss 4.160023\n",
            "Epoch 0: train acc 0.000000 test acc 0.038172\n",
            "Epoch 0: train loss 4.068191 test loss 4.120820\n",
            "Epoch 0: train acc 0.038462 test acc 0.040000\n",
            "Epoch 0: train loss 4.180507 test loss 4.122180\n",
            "Epoch 0: train acc 0.076923 test acc 0.031075\n",
            "Epoch 0: train loss 4.176364 test loss 4.127059\n",
            "Epoch 0: train acc 0.076923 test acc 0.030753\n",
            "Epoch 0: train loss 4.107430 test loss 4.005834\n",
            "Epoch 0: train acc 0.000000 test acc 0.030860\n",
            "Epoch 0: train loss 4.127886 test loss 3.989395\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 4.628689 test loss 3.933550\n",
            "Epoch 0: train acc 0.000000 test acc 0.042366\n",
            "Epoch 0: train loss 3.947847 test loss 3.828590\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 4.022724 test loss 3.914813\n",
            "Epoch 0: train acc 0.038462 test acc 0.033871\n",
            "Epoch 0: train loss 3.572811 test loss 4.130060\n",
            "Epoch 0: train acc 0.076923 test acc 0.033118\n",
            "Epoch 0: train loss 4.670646 test loss 3.973962\n",
            "Epoch 0: train acc 0.000000 test acc 0.031075\n",
            "Epoch 0: train loss 4.242157 test loss 4.075987\n",
            "Epoch 0: train acc 0.038462 test acc 0.031290\n",
            "Epoch 0: train loss 4.285657 test loss 3.977962\n",
            "Epoch 0: train acc 0.000000 test acc 0.066344\n",
            "Epoch 0: train loss 3.739792 test loss 4.117369\n",
            "Epoch 0: train acc 0.076923 test acc 0.038817\n",
            "Epoch 0: train loss 3.958619 test loss 4.297130\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 5.095898 test loss 4.138312\n",
            "Epoch 0: train acc 0.000000 test acc 0.031505\n",
            "Epoch 0: train loss 3.913346 test loss 4.031092\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 4.047395 test loss 4.025795\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 4.027146 test loss 4.103533\n",
            "Epoch 0: train acc 0.076923 test acc 0.036882\n",
            "Epoch 0: train loss 4.406815 test loss 4.009287\n",
            "Epoch 0: train acc 0.076923 test acc 0.038817\n",
            "Epoch 0: train loss 3.971422 test loss 4.028927\n",
            "Epoch 0: train acc 0.000000 test acc 0.036344\n",
            "Epoch 0: train loss 3.872084 test loss 4.118633\n",
            "Epoch 0: train acc 0.038462 test acc 0.032151\n",
            "Epoch 0: train loss 4.327696 test loss 4.162047\n",
            "Epoch 0: train acc 0.000000 test acc 0.031828\n",
            "Epoch 0: train loss 4.218631 test loss 4.101793\n",
            "Epoch 0: train acc 0.000000 test acc 0.031398\n",
            "Epoch 0: train loss 3.862846 test loss 4.020150\n",
            "Epoch 0: train acc 0.038462 test acc 0.037097\n",
            "Epoch 0: train loss 4.311876 test loss 3.895028\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 3.750663 test loss 3.771467\n",
            "Epoch 0: train acc 0.038462 test acc 0.058495\n",
            "Epoch 0: train loss 3.514874 test loss 3.730754\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 3.906481 test loss 3.654530\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 3.730191 test loss 3.682852\n",
            "Epoch 0: train acc 0.000000 test acc 0.039032\n",
            "Epoch 0: train loss 3.682003 test loss 3.806513\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 3.729658 test loss 3.927365\n",
            "Epoch 0: train acc 0.038462 test acc 0.032151\n",
            "Epoch 0: train loss 4.501674 test loss 3.839160\n",
            "Epoch 0: train acc 0.038462 test acc 0.037097\n",
            "Epoch 0: train loss 3.786613 test loss 3.710179\n",
            "Epoch 0: train acc 0.000000 test acc 0.062688\n",
            "Epoch 0: train loss 3.975633 test loss 3.601219\n",
            "Epoch 0: train acc 0.000000 test acc 0.058817\n",
            "Epoch 0: train loss 3.510174 test loss 3.628837\n",
            "Epoch 0: train acc 0.038462 test acc 0.056452\n",
            "Epoch 0: train loss 3.548449 test loss 3.682560\n",
            "Epoch 0: train acc 0.076923 test acc 0.053871\n",
            "Epoch 0: train loss 3.813859 test loss 3.712950\n",
            "Epoch 0: train acc 0.000000 test acc 0.036882\n",
            "Epoch 0: train loss 3.770508 test loss 3.767248\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 3.911507 test loss 3.718261\n",
            "Epoch 0: train acc 0.000000 test acc 0.047742\n",
            "Epoch 0: train loss 3.359286 test loss 3.790720\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.869279 test loss 3.903201\n",
            "Epoch 0: train acc 0.153846 test acc 0.036774\n",
            "Epoch 0: train loss 3.660912 test loss 4.019916\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 3.773408 test loss 3.884991\n",
            "Epoch 0: train acc 0.000000 test acc 0.036237\n",
            "Epoch 0: train loss 4.035875 test loss 3.902170\n",
            "Epoch 0: train acc 0.038462 test acc 0.058710\n",
            "Epoch 0: train loss 3.725898 test loss 4.143327\n",
            "Epoch 0: train acc 0.038462 test acc 0.054516\n",
            "Epoch 0: train loss 4.407273 test loss 4.139803\n",
            "Epoch 0: train acc 0.038462 test acc 0.036882\n",
            "Epoch 0: train loss 4.110838 test loss 4.071114\n",
            "Epoch 0: train acc 0.038462 test acc 0.036129\n",
            "Epoch 0: train loss 3.772647 test loss 4.146757\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 4.497082 test loss 4.143637\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 4.211656 test loss 3.954608\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 4.174415 test loss 3.882602\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.066154 test loss 4.003135\n",
            "Epoch 0: train acc 0.000000 test acc 0.033548\n",
            "Epoch 0: train loss 4.138718 test loss 3.917249\n",
            "Epoch 0: train acc 0.038462 test acc 0.035269\n",
            "Epoch 0: train loss 4.074305 test loss 3.856799\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 3.907509 test loss 3.886230\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.982621 test loss 3.970887\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.067204 test loss 3.983903\n",
            "Epoch 0: train acc 0.076923 test acc 0.030968\n",
            "Epoch 0: train loss 4.076959 test loss 3.843599\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.313023 test loss 3.944285\n",
            "Epoch 0: train acc 0.000000 test acc 0.032581\n",
            "Epoch 0: train loss 4.071267 test loss 3.866743\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 4.037373 test loss 3.801853\n",
            "Epoch 0: train acc 0.115385 test acc 0.033118\n",
            "Epoch 0: train loss 3.610843 test loss 3.770477\n",
            "Epoch 0: train acc 0.038462 test acc 0.047634\n",
            "Epoch 0: train loss 3.679315 test loss 3.977144\n",
            "Epoch 0: train acc 0.038462 test acc 0.043118\n",
            "Epoch 0: train loss 4.170942 test loss 3.922701\n",
            "Epoch 0: train acc 0.000000 test acc 0.048710\n",
            "Epoch 0: train loss 3.915726 test loss 3.892000\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.647620 test loss 3.963618\n",
            "Epoch 0: train acc 0.076923 test acc 0.028387\n",
            "Epoch 0: train loss 4.236188 test loss 4.015604\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 4.124165 test loss 3.920227\n",
            "Epoch 0: train acc 0.076923 test acc 0.035591\n",
            "Epoch 0: train loss 3.786930 test loss 3.859626\n",
            "Epoch 0: train acc 0.038462 test acc 0.039677\n",
            "Epoch 0: train loss 3.560358 test loss 3.851361\n",
            "Epoch 0: train acc 0.038462 test acc 0.043548\n",
            "Epoch 0: train loss 3.964156 test loss 4.046081\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 4.353977 test loss 3.765777\n",
            "Epoch 0: train acc 0.000000 test acc 0.040108\n",
            "Epoch 0: train loss 3.771252 test loss 3.883676\n",
            "Epoch 0: train acc 0.038462 test acc 0.036882\n",
            "Epoch 0: train loss 3.676033 test loss 4.085443\n",
            "Epoch 0: train acc 0.038462 test acc 0.036237\n",
            "Epoch 0: train loss 4.364072 test loss 3.982243\n",
            "Epoch 0: train acc 0.038462 test acc 0.031290\n",
            "Epoch 0: train loss 3.697440 test loss 4.099473\n",
            "Epoch 0: train acc 0.000000 test acc 0.036344\n",
            "Epoch 0: train loss 3.601998 test loss 4.318061\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 4.441175 test loss 4.233408\n",
            "Epoch 0: train acc 0.038462 test acc 0.034516\n",
            "Epoch 0: train loss 3.941900 test loss 4.239590\n",
            "Epoch 0: train acc 0.000000 test acc 0.058817\n",
            "Epoch 0: train loss 3.913429 test loss 4.267043\n",
            "Epoch 0: train acc 0.038462 test acc 0.042796\n",
            "Epoch 0: train loss 4.365855 test loss 4.192329\n",
            "Epoch 0: train acc 0.038462 test acc 0.073656\n",
            "Epoch 0: train loss 4.311749 test loss 4.213919\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 4.173714 test loss 4.251987\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 4.102379 test loss 4.273788\n",
            "Epoch 0: train acc 0.153846 test acc 0.033656\n",
            "Epoch 0: train loss 4.663328 test loss 4.007924\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 3.748416 test loss 4.042580\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 4.150928 test loss 4.039993\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 4.363650 test loss 3.872125\n",
            "Epoch 0: train acc 0.076923 test acc 0.034839\n",
            "Epoch 0: train loss 3.436307 test loss 3.888099\n",
            "Epoch 0: train acc 0.115385 test acc 0.033548\n",
            "Epoch 0: train loss 3.736210 test loss 3.925490\n",
            "Epoch 0: train acc 0.000000 test acc 0.050430\n",
            "Epoch 0: train loss 4.367627 test loss 3.934877\n",
            "Epoch 0: train acc 0.000000 test acc 0.062903\n",
            "Epoch 0: train loss 4.372918 test loss 3.970378\n",
            "Epoch 0: train acc 0.038462 test acc 0.033656\n",
            "Epoch 0: train loss 3.953030 test loss 4.024533\n",
            "Epoch 0: train acc 0.038462 test acc 0.029892\n",
            "Epoch 0: train loss 4.395497 test loss 3.914913\n",
            "Epoch 0: train acc 0.000000 test acc 0.040968\n",
            "Epoch 0: train loss 3.904614 test loss 3.953919\n",
            "Epoch 0: train acc 0.076923 test acc 0.055806\n",
            "Epoch 0: train loss 4.083179 test loss 3.946300\n",
            "Epoch 0: train acc 0.076923 test acc 0.055591\n",
            "Epoch 0: train loss 3.783953 test loss 3.964565\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 4.111965 test loss 3.903771\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 4.036874 test loss 3.922713\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 3.861954 test loss 3.862751\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 3.854075 test loss 3.834382\n",
            "Epoch 0: train acc 0.000000 test acc 0.033333\n",
            "Epoch 0: train loss 3.874796 test loss 3.865634\n",
            "Epoch 0: train acc 0.038462 test acc 0.035806\n",
            "Epoch 0: train loss 3.971373 test loss 3.977993\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 4.075349 test loss 3.987422\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.612589 test loss 4.172104\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 4.091529 test loss 4.196829\n",
            "Epoch 0: train acc 0.038462 test acc 0.030430\n",
            "Epoch 0: train loss 4.128205 test loss 4.074513\n",
            "Epoch 0: train acc 0.038462 test acc 0.030538\n",
            "Epoch 0: train loss 4.251175 test loss 4.006789\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 3.973231 test loss 3.899507\n",
            "Epoch 0: train acc 0.076923 test acc 0.033871\n",
            "Epoch 0: train loss 3.626088 test loss 4.197844\n",
            "Epoch 0: train acc 0.115385 test acc 0.032903\n",
            "Epoch 0: train loss 4.146458 test loss 4.336719\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 4.446796 test loss 4.332094\n",
            "Epoch 0: train acc 0.000000 test acc 0.041183\n",
            "Epoch 0: train loss 3.989183 test loss 4.327318\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 4.159089 test loss 4.324094\n",
            "Epoch 0: train acc 0.115385 test acc 0.032473\n",
            "Epoch 0: train loss 4.085805 test loss 4.473456\n",
            "Epoch 0: train acc 0.038462 test acc 0.034516\n",
            "Epoch 0: train loss 4.680324 test loss 4.527748\n",
            "Epoch 0: train acc 0.000000 test acc 0.034516\n",
            "Epoch 0: train loss 5.018775 test loss 4.306146\n",
            "Epoch 0: train acc 0.000000 test acc 0.053441\n",
            "Epoch 0: train loss 4.408282 test loss 4.124515\n",
            "Epoch 0: train acc 0.038462 test acc 0.034731\n",
            "Epoch 0: train loss 3.659026 test loss 4.294680\n",
            "Epoch 0: train acc 0.038462 test acc 0.043871\n",
            "Epoch 0: train loss 4.442184 test loss 4.413012\n",
            "Epoch 0: train acc 0.115385 test acc 0.040645\n",
            "Epoch 0: train loss 4.508581 test loss 4.391569\n",
            "Epoch 0: train acc 0.038462 test acc 0.064194\n",
            "Epoch 0: train loss 4.279109 test loss 4.372387\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 3.899389 test loss 4.322427\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 4.299154 test loss 4.251153\n",
            "Epoch 0: train acc 0.153846 test acc 0.034624\n",
            "Epoch 0: train loss 4.477285 test loss 4.097017\n",
            "Epoch 0: train acc 0.038462 test acc 0.039247\n",
            "Epoch 0: train loss 4.199176 test loss 3.853753\n",
            "Epoch 0: train acc 0.038462 test acc 0.054516\n",
            "Epoch 0: train loss 3.888052 test loss 3.786149\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 3.914517 test loss 3.800483\n",
            "Epoch 0: train acc 0.038462 test acc 0.057634\n",
            "Epoch 0: train loss 3.669103 test loss 3.974208\n",
            "Epoch 0: train acc 0.115385 test acc 0.053011\n",
            "Epoch 0: train loss 4.564723 test loss 3.912233\n",
            "Epoch 0: train acc 0.000000 test acc 0.050968\n",
            "Epoch 0: train loss 4.072054 test loss 3.835900\n",
            "Epoch 0: train acc 0.000000 test acc 0.051935\n",
            "Epoch 0: train loss 4.185348 test loss 3.943351\n",
            "Epoch 0: train acc 0.076923 test acc 0.031720\n",
            "Epoch 0: train loss 3.848575 test loss 4.032605\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 3.420709 test loss 4.157365\n",
            "Epoch 0: train acc 0.153846 test acc 0.038495\n",
            "Epoch 0: train loss 3.972308 test loss 4.212965\n",
            "Epoch 0: train acc 0.038462 test acc 0.039462\n",
            "Epoch 0: train loss 4.602602 test loss 4.182296\n",
            "Epoch 0: train acc 0.038462 test acc 0.041290\n",
            "Epoch 0: train loss 3.786531 test loss 4.158188\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 3.819935 test loss 4.096255\n",
            "Epoch 0: train acc 0.153846 test acc 0.031828\n",
            "Epoch 0: train loss 3.380539 test loss 4.033581\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 3.814620 test loss 4.094663\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 3.437812 test loss 4.286589\n",
            "Epoch 0: train acc 0.153846 test acc 0.031505\n",
            "Epoch 0: train loss 4.373072 test loss 4.426032\n",
            "Epoch 0: train acc 0.076923 test acc 0.030323\n",
            "Epoch 0: train loss 4.967071 test loss 4.207617\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 4.030259 test loss 4.069691\n",
            "Epoch 0: train acc 0.038462 test acc 0.028495\n",
            "Epoch 0: train loss 4.497633 test loss 3.976523\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 4.187938 test loss 4.057318\n",
            "Epoch 0: train acc 0.038462 test acc 0.035591\n",
            "Epoch 0: train loss 3.857292 test loss 4.176666\n",
            "Epoch 0: train acc 0.115385 test acc 0.040323\n",
            "Epoch 0: train loss 4.370481 test loss 4.138566\n",
            "Epoch 0: train acc 0.076923 test acc 0.034194\n",
            "Epoch 0: train loss 4.264234 test loss 4.124421\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 3.907160 test loss 4.037002\n",
            "Epoch 0: train acc 0.115385 test acc 0.031505\n",
            "Epoch 0: train loss 4.180766 test loss 3.975585\n",
            "Epoch 0: train acc 0.038462 test acc 0.031828\n",
            "Epoch 0: train loss 3.594638 test loss 4.048247\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.904925 test loss 4.083462\n",
            "Epoch 0: train acc 0.038462 test acc 0.037419\n",
            "Epoch 0: train loss 3.921200 test loss 4.033815\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 4.279794 test loss 4.005477\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 4.668509 test loss 3.868858\n",
            "Epoch 0: train acc 0.038462 test acc 0.037204\n",
            "Epoch 0: train loss 3.480351 test loss 3.815383\n",
            "Epoch 0: train acc 0.000000 test acc 0.051720\n",
            "Epoch 0: train loss 3.762919 test loss 3.845538\n",
            "Epoch 0: train acc 0.076923 test acc 0.049677\n",
            "Epoch 0: train loss 4.845136 test loss 3.805558\n",
            "Epoch 0: train acc 0.038462 test acc 0.058495\n",
            "Epoch 0: train loss 3.581032 test loss 3.775214\n",
            "Epoch 0: train acc 0.000000 test acc 0.052903\n",
            "Epoch 0: train loss 3.900279 test loss 3.731665\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.603411 test loss 3.705079\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.525586 test loss 3.707132\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 3.646435 test loss 3.836628\n",
            "Epoch 0: train acc 0.038462 test acc 0.035269\n",
            "Epoch 0: train loss 3.919058 test loss 3.786408\n",
            "Epoch 0: train acc 0.038462 test acc 0.036129\n",
            "Epoch 0: train loss 3.582091 test loss 3.825767\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.870462 test loss 3.877026\n",
            "Epoch 0: train acc 0.038462 test acc 0.072043\n",
            "Epoch 0: train loss 3.857177 test loss 3.831695\n",
            "Epoch 0: train acc 0.115385 test acc 0.063118\n",
            "Epoch 0: train loss 3.925137 test loss 3.797371\n",
            "Epoch 0: train acc 0.038462 test acc 0.060968\n",
            "Epoch 0: train loss 4.200211 test loss 3.764822\n",
            "Epoch 0: train acc 0.000000 test acc 0.031505\n",
            "Epoch 0: train loss 3.474040 test loss 3.775571\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 3.464074 test loss 3.761577\n",
            "Epoch 0: train acc 0.076923 test acc 0.031828\n",
            "Epoch 0: train loss 3.911626 test loss 3.769610\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.630790 test loss 3.924421\n",
            "Epoch 0: train acc 0.038462 test acc 0.035914\n",
            "Epoch 0: train loss 3.830169 test loss 3.907547\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 3.797734 test loss 3.808836\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 4.123604 test loss 3.622665\n",
            "Epoch 0: train acc 0.038462 test acc 0.057634\n",
            "Epoch 0: train loss 3.776695 test loss 3.639616\n",
            "Epoch 0: train acc 0.076923 test acc 0.055161\n",
            "Epoch 0: train loss 3.429028 test loss 3.819698\n",
            "Epoch 0: train acc 0.038462 test acc 0.060753\n",
            "Epoch 0: train loss 3.850883 test loss 3.911886\n",
            "Epoch 0: train acc 0.115385 test acc 0.036989\n",
            "Epoch 0: train loss 3.582159 test loss 4.039199\n",
            "Epoch 0: train acc 0.038462 test acc 0.036559\n",
            "Epoch 0: train loss 3.596940 test loss 4.295583\n",
            "Epoch 0: train acc 0.038462 test acc 0.035914\n",
            "Epoch 0: train loss 4.047067 test loss 4.414115\n",
            "Epoch 0: train acc 0.000000 test acc 0.035914\n",
            "Epoch 0: train loss 4.438853 test loss 4.223005\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.526034 test loss 3.926134\n",
            "Epoch 0: train acc 0.038462 test acc 0.045914\n",
            "Epoch 0: train loss 3.661587 test loss 3.846836\n",
            "Epoch 0: train acc 0.076923 test acc 0.056667\n",
            "Epoch 0: train loss 4.123100 test loss 3.851245\n",
            "Epoch 0: train acc 0.038462 test acc 0.051398\n",
            "Epoch 0: train loss 3.579921 test loss 4.129471\n",
            "Epoch 0: train acc 0.000000 test acc 0.033118\n",
            "Epoch 0: train loss 4.121529 test loss 4.239192\n",
            "Epoch 0: train acc 0.076923 test acc 0.033118\n",
            "Epoch 0: train loss 4.729711 test loss 3.944259\n",
            "Epoch 0: train acc 0.000000 test acc 0.054731\n",
            "Epoch 0: train loss 4.120922 test loss 3.988590\n",
            "Epoch 0: train acc 0.038462 test acc 0.058817\n",
            "Epoch 0: train loss 4.165930 test loss 4.109673\n",
            "Epoch 0: train acc 0.038462 test acc 0.047097\n",
            "Epoch 0: train loss 4.158714 test loss 4.246260\n",
            "Epoch 0: train acc 0.076923 test acc 0.029677\n",
            "Epoch 0: train loss 5.219837 test loss 4.040302\n",
            "Epoch 0: train acc 0.000000 test acc 0.051505\n",
            "Epoch 0: train loss 3.699626 test loss 4.057062\n",
            "Epoch 0: train acc 0.038462 test acc 0.054086\n",
            "Epoch 0: train loss 4.132505 test loss 3.967575\n",
            "Epoch 0: train acc 0.000000 test acc 0.032151\n",
            "Epoch 0: train loss 3.789022 test loss 4.300044\n",
            "Epoch 0: train acc 0.076923 test acc 0.031613\n",
            "Epoch 0: train loss 3.864290 test loss 4.224152\n",
            "Epoch 0: train acc 0.038462 test acc 0.032151\n",
            "Epoch 0: train loss 3.794981 test loss 4.263329\n",
            "Epoch 0: train acc 0.038462 test acc 0.034624\n",
            "Epoch 0: train loss 4.865686 test loss 4.003808\n",
            "Epoch 0: train acc 0.000000 test acc 0.036882\n",
            "Epoch 0: train loss 4.414118 test loss 3.706948\n",
            "Epoch 0: train acc 0.000000 test acc 0.061935\n",
            "Epoch 0: train loss 3.517639 test loss 4.003514\n",
            "Epoch 0: train acc 0.115385 test acc 0.035054\n",
            "Epoch 0: train loss 4.137681 test loss 4.286883\n",
            "Epoch 0: train acc 0.000000 test acc 0.039247\n",
            "Epoch 0: train loss 4.760314 test loss 4.182138\n",
            "Epoch 0: train acc 0.076923 test acc 0.035806\n",
            "Epoch 0: train loss 4.447455 test loss 3.930583\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 3.965648 test loss 4.072999\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.949138 test loss 4.423137\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 4.563666 test loss 4.315355\n",
            "Epoch 0: train acc 0.038462 test acc 0.034624\n",
            "Epoch 0: train loss 3.799340 test loss 4.409230\n",
            "Epoch 0: train acc 0.038462 test acc 0.047957\n",
            "Epoch 0: train loss 4.193478 test loss 4.524311\n",
            "Epoch 0: train acc 0.038462 test acc 0.043548\n",
            "Epoch 0: train loss 4.526846 test loss 4.498707\n",
            "Epoch 0: train acc 0.076923 test acc 0.035269\n",
            "Epoch 0: train loss 4.870617 test loss 4.342714\n",
            "Epoch 0: train acc 0.038462 test acc 0.035269\n",
            "Epoch 0: train loss 4.347998 test loss 4.282778\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 4.668611 test loss 4.194032\n",
            "Epoch 0: train acc 0.000000 test acc 0.032473\n",
            "Epoch 0: train loss 4.228013 test loss 4.079792\n",
            "Epoch 0: train acc 0.038462 test acc 0.058817\n",
            "Epoch 0: train loss 4.229363 test loss 3.977386\n",
            "Epoch 0: train acc 0.000000 test acc 0.049570\n",
            "Epoch 0: train loss 3.723651 test loss 3.903213\n",
            "Epoch 0: train acc 0.076923 test acc 0.061183\n",
            "Epoch 0: train loss 4.306681 test loss 4.059517\n",
            "Epoch 0: train acc 0.076923 test acc 0.030538\n",
            "Epoch 0: train loss 4.160496 test loss 3.938559\n",
            "Epoch 0: train acc 0.000000 test acc 0.057419\n",
            "Epoch 0: train loss 3.507115 test loss 4.112390\n",
            "Epoch 0: train acc 0.076923 test acc 0.031828\n",
            "Epoch 0: train loss 3.893220 test loss 4.147674\n",
            "Epoch 0: train acc 0.000000 test acc 0.030538\n",
            "Epoch 0: train loss 3.878103 test loss 4.167361\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 3.935559 test loss 4.121407\n",
            "Epoch 0: train acc 0.076923 test acc 0.081828\n",
            "Epoch 0: train loss 3.968992 test loss 4.260783\n",
            "Epoch 0: train acc 0.000000 test acc 0.039355\n",
            "Epoch 0: train loss 5.017193 test loss 4.038076\n",
            "Epoch 0: train acc 0.076923 test acc 0.037527\n",
            "Epoch 0: train loss 4.355082 test loss 3.832020\n",
            "Epoch 0: train acc 0.115385 test acc 0.038925\n",
            "Epoch 0: train loss 3.589795 test loss 3.857146\n",
            "Epoch 0: train acc 0.076923 test acc 0.034194\n",
            "Epoch 0: train loss 3.686054 test loss 3.967369\n",
            "Epoch 0: train acc 0.000000 test acc 0.033333\n",
            "Epoch 0: train loss 4.046110 test loss 3.952886\n",
            "Epoch 0: train acc 0.076923 test acc 0.033548\n",
            "Epoch 0: train loss 3.678796 test loss 4.039701\n",
            "Epoch 0: train acc 0.076923 test acc 0.036989\n",
            "Epoch 0: train loss 3.939294 test loss 4.076001\n",
            "Epoch 0: train acc 0.115385 test acc 0.040323\n",
            "Epoch 0: train loss 3.689824 test loss 4.014285\n",
            "Epoch 0: train acc 0.038462 test acc 0.042688\n",
            "Epoch 0: train loss 4.129339 test loss 3.989906\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 3.913031 test loss 3.940207\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 4.556802 test loss 3.934868\n",
            "Epoch 0: train acc 0.076923 test acc 0.039247\n",
            "Epoch 0: train loss 3.678363 test loss 3.959676\n",
            "Epoch 0: train acc 0.038462 test acc 0.038817\n",
            "Epoch 0: train loss 3.997870 test loss 4.017704\n",
            "Epoch 0: train acc 0.038462 test acc 0.034946\n",
            "Epoch 0: train loss 4.249758 test loss 3.918957\n",
            "Epoch 0: train acc 0.000000 test acc 0.037312\n",
            "Epoch 0: train loss 3.812234 test loss 3.950448\n",
            "Epoch 0: train acc 0.076923 test acc 0.047419\n",
            "Epoch 0: train loss 3.593873 test loss 4.131014\n",
            "Epoch 0: train acc 0.038462 test acc 0.050753\n",
            "Epoch 0: train loss 4.092993 test loss 4.198667\n",
            "Epoch 0: train acc 0.153846 test acc 0.051290\n",
            "Epoch 0: train loss 4.756250 test loss 4.040274\n",
            "Epoch 0: train acc 0.076923 test acc 0.056129\n",
            "Epoch 0: train loss 3.978349 test loss 3.856922\n",
            "Epoch 0: train acc 0.153846 test acc 0.040215\n",
            "Epoch 0: train loss 4.099860 test loss 3.877398\n",
            "Epoch 0: train acc 0.000000 test acc 0.031505\n",
            "Epoch 0: train loss 4.121012 test loss 3.896407\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 3.862071 test loss 3.805291\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 3.811680 test loss 3.832309\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.845721 test loss 3.963535\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 4.187169 test loss 3.784842\n",
            "Epoch 0: train acc 0.000000 test acc 0.041075\n",
            "Epoch 0: train loss 3.766934 test loss 3.699519\n",
            "Epoch 0: train acc 0.038462 test acc 0.035161\n",
            "Epoch 0: train loss 3.697621 test loss 3.688529\n",
            "Epoch 0: train acc 0.076923 test acc 0.060323\n",
            "Epoch 0: train loss 3.506969 test loss 3.761992\n",
            "Epoch 0: train acc 0.038462 test acc 0.058280\n",
            "Epoch 0: train loss 3.822022 test loss 3.868345\n",
            "Epoch 0: train acc 0.038462 test acc 0.059677\n",
            "Epoch 0: train loss 4.222302 test loss 3.821213\n",
            "Epoch 0: train acc 0.000000 test acc 0.064194\n",
            "Epoch 0: train loss 3.547067 test loss 3.832807\n",
            "Epoch 0: train acc 0.192308 test acc 0.036237\n",
            "Epoch 0: train loss 3.734888 test loss 3.737939\n",
            "Epoch 0: train acc 0.076923 test acc 0.055806\n",
            "Epoch 0: train loss 3.423203 test loss 3.774997\n",
            "Epoch 0: train acc 0.038462 test acc 0.035484\n",
            "Epoch 0: train loss 3.620486 test loss 3.737840\n",
            "Epoch 0: train acc 0.038462 test acc 0.037527\n",
            "Epoch 0: train loss 3.580645 test loss 3.760375\n",
            "Epoch 0: train acc 0.038462 test acc 0.039140\n",
            "Epoch 0: train loss 3.888589 test loss 3.746230\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 3.837630 test loss 3.741384\n",
            "Epoch 0: train acc 0.115385 test acc 0.035161\n",
            "Epoch 0: train loss 3.689383 test loss 3.715207\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 3.682969 test loss 3.690691\n",
            "Epoch 0: train acc 0.000000 test acc 0.052903\n",
            "Epoch 0: train loss 3.321880 test loss 3.902401\n",
            "Epoch 0: train acc 0.076923 test acc 0.063333\n",
            "Epoch 0: train loss 3.799478 test loss 4.059442\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 3.717044 test loss 4.011030\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 4.323597 test loss 3.925728\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 3.909858 test loss 3.947676\n",
            "Epoch 0: train acc 0.076923 test acc 0.034946\n",
            "Epoch 0: train loss 3.926111 test loss 3.778614\n",
            "Epoch 0: train acc 0.038462 test acc 0.030968\n",
            "Epoch 0: train loss 3.645332 test loss 3.768383\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 3.578100 test loss 3.804837\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 3.856579 test loss 3.823070\n",
            "Epoch 0: train acc 0.000000 test acc 0.046129\n",
            "Epoch 0: train loss 3.887448 test loss 3.833138\n",
            "Epoch 0: train acc 0.038462 test acc 0.029570\n",
            "Epoch 0: train loss 4.123959 test loss 3.818534\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 4.263781 test loss 3.716780\n",
            "Epoch 0: train acc 0.000000 test acc 0.053656\n",
            "Epoch 0: train loss 3.622394 test loss 3.787403\n",
            "Epoch 0: train acc 0.076923 test acc 0.048495\n",
            "Epoch 0: train loss 3.979632 test loss 3.834685\n",
            "Epoch 0: train acc 0.076923 test acc 0.056344\n",
            "Epoch 0: train loss 4.089620 test loss 3.892389\n",
            "Epoch 0: train acc 0.076923 test acc 0.052688\n",
            "Epoch 0: train loss 3.735442 test loss 3.991915\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 4.119393 test loss 3.838070\n",
            "Epoch 0: train acc 0.076923 test acc 0.034301\n",
            "Epoch 0: train loss 3.718379 test loss 3.796480\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.766591 test loss 3.882785\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 3.577820 test loss 3.938895\n",
            "Epoch 0: train acc 0.000000 test acc 0.037742\n",
            "Epoch 0: train loss 3.883817 test loss 3.928828\n",
            "Epoch 0: train acc 0.115385 test acc 0.033978\n",
            "Epoch 0: train loss 3.474894 test loss 3.806111\n",
            "Epoch 0: train acc 0.000000 test acc 0.036344\n",
            "Epoch 0: train loss 3.704119 test loss 3.829654\n",
            "Epoch 0: train acc 0.038462 test acc 0.036667\n",
            "Epoch 0: train loss 3.881807 test loss 3.799022\n",
            "Epoch 0: train acc 0.076923 test acc 0.052258\n",
            "Epoch 0: train loss 3.803221 test loss 3.759601\n",
            "Epoch 0: train acc 0.000000 test acc 0.037419\n",
            "Epoch 0: train loss 3.885082 test loss 3.751410\n",
            "Epoch 0: train acc 0.115385 test acc 0.046667\n",
            "Epoch 0: train loss 3.673262 test loss 3.773045\n",
            "Epoch 0: train acc 0.038462 test acc 0.050323\n",
            "Epoch 0: train loss 3.680550 test loss 3.716272\n",
            "Epoch 0: train acc 0.076923 test acc 0.054301\n",
            "Epoch 0: train loss 3.702122 test loss 3.789669\n",
            "Epoch 0: train acc 0.038462 test acc 0.033333\n",
            "Epoch 0: train loss 3.852040 test loss 3.928387\n",
            "Epoch 0: train acc 0.000000 test acc 0.030968\n",
            "Epoch 0: train loss 3.388191 test loss 4.201458\n",
            "Epoch 0: train acc 0.115385 test acc 0.030323\n",
            "Epoch 0: train loss 4.184600 test loss 4.175561\n",
            "Epoch 0: train acc 0.038462 test acc 0.033548\n",
            "Epoch 0: train loss 4.347873 test loss 4.206357\n",
            "Epoch 0: train acc 0.000000 test acc 0.052796\n",
            "Epoch 0: train loss 4.099731 test loss 4.286900\n",
            "Epoch 0: train acc 0.038462 test acc 0.034946\n",
            "Epoch 0: train loss 4.046367 test loss 4.318236\n",
            "Epoch 0: train acc 0.000000 test acc 0.036022\n",
            "Epoch 0: train loss 4.788690 test loss 4.164946\n",
            "Epoch 0: train acc 0.000000 test acc 0.034301\n",
            "Epoch 0: train loss 4.605238 test loss 4.004545\n",
            "Epoch 0: train acc 0.000000 test acc 0.057957\n",
            "Epoch 0: train loss 3.847542 test loss 3.998545\n",
            "Epoch 0: train acc 0.038462 test acc 0.061398\n",
            "Epoch 0: train loss 3.556940 test loss 4.122288\n",
            "Epoch 0: train acc 0.076923 test acc 0.057634\n",
            "Epoch 0: train loss 4.317812 test loss 4.192453\n",
            "Epoch 0: train acc 0.076923 test acc 0.055269\n",
            "Epoch 0: train loss 4.508530 test loss 4.145978\n",
            "Epoch 0: train acc 0.076923 test acc 0.056452\n",
            "Epoch 0: train loss 4.547266 test loss 4.030555\n",
            "Epoch 0: train acc 0.115385 test acc 0.039032\n",
            "Epoch 0: train loss 4.021504 test loss 3.938456\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.466922 test loss 3.898151\n",
            "Epoch 0: train acc 0.076923 test acc 0.037312\n",
            "Epoch 0: train loss 3.562107 test loss 3.953459\n",
            "Epoch 0: train acc 0.076923 test acc 0.034301\n",
            "Epoch 0: train loss 4.063419 test loss 3.831564\n",
            "Epoch 0: train acc 0.000000 test acc 0.055806\n",
            "Epoch 0: train loss 3.793765 test loss 3.739497\n",
            "Epoch 0: train acc 0.115385 test acc 0.059892\n",
            "Epoch 0: train loss 3.935133 test loss 3.798552\n",
            "Epoch 0: train acc 0.115385 test acc 0.041935\n",
            "Epoch 0: train loss 4.027932 test loss 3.840325\n",
            "Epoch 0: train acc 0.038462 test acc 0.038817\n",
            "Epoch 0: train loss 3.398744 test loss 3.994260\n",
            "Epoch 0: train acc 0.038462 test acc 0.035806\n",
            "Epoch 0: train loss 4.149403 test loss 3.997435\n",
            "Epoch 0: train acc 0.000000 test acc 0.037742\n",
            "Epoch 0: train loss 3.935849 test loss 3.902103\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 3.520030 test loss 3.893753\n",
            "Epoch 0: train acc 0.076923 test acc 0.033871\n",
            "Epoch 0: train loss 4.128571 test loss 3.853559\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.468442 test loss 3.756995\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 3.937185 test loss 3.738992\n",
            "Epoch 0: train acc 0.000000 test acc 0.057097\n",
            "Epoch 0: train loss 3.392326 test loss 3.830492\n",
            "Epoch 0: train acc 0.076923 test acc 0.053118\n",
            "Epoch 0: train loss 3.396016 test loss 3.947413\n",
            "Epoch 0: train acc 0.076923 test acc 0.066559\n",
            "Epoch 0: train loss 3.637107 test loss 4.070385\n",
            "Epoch 0: train acc 0.038462 test acc 0.062258\n",
            "Epoch 0: train loss 4.530969 test loss 4.132463\n",
            "Epoch 0: train acc 0.076923 test acc 0.060108\n",
            "Epoch 0: train loss 4.358787 test loss 4.068816\n",
            "Epoch 0: train acc 0.038462 test acc 0.059570\n",
            "Epoch 0: train loss 4.308818 test loss 3.966975\n",
            "Epoch 0: train acc 0.076923 test acc 0.041290\n",
            "Epoch 0: train loss 4.687892 test loss 3.847219\n",
            "Epoch 0: train acc 0.000000 test acc 0.051935\n",
            "Epoch 0: train loss 3.494780 test loss 3.808071\n",
            "Epoch 0: train acc 0.076923 test acc 0.048925\n",
            "Epoch 0: train loss 3.579333 test loss 3.825822\n",
            "Epoch 0: train acc 0.076923 test acc 0.056559\n",
            "Epoch 0: train loss 3.781132 test loss 3.986597\n",
            "Epoch 0: train acc 0.076923 test acc 0.050538\n",
            "Epoch 0: train loss 3.925652 test loss 4.099837\n",
            "Epoch 0: train acc 0.076923 test acc 0.054516\n",
            "Epoch 0: train loss 4.541188 test loss 4.122131\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 3.908259 test loss 4.003316\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 3.638153 test loss 3.946473\n",
            "Epoch 0: train acc 0.000000 test acc 0.039032\n",
            "Epoch 0: train loss 4.276776 test loss 3.891347\n",
            "Epoch 0: train acc 0.038462 test acc 0.034839\n",
            "Epoch 0: train loss 4.372689 test loss 3.808103\n",
            "Epoch 0: train acc 0.000000 test acc 0.034086\n",
            "Epoch 0: train loss 3.938612 test loss 3.718980\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 3.854571 test loss 3.721618\n",
            "Epoch 0: train acc 0.115385 test acc 0.032473\n",
            "Epoch 0: train loss 3.735977 test loss 3.776574\n",
            "Epoch 0: train acc 0.038462 test acc 0.033871\n",
            "Epoch 0: train loss 4.150463 test loss 3.840336\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 3.878990 test loss 3.763892\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 3.763379 test loss 3.761371\n",
            "Epoch 0: train acc 0.115385 test acc 0.033978\n",
            "Epoch 0: train loss 4.195073 test loss 3.748990\n",
            "Epoch 0: train acc 0.038462 test acc 0.046129\n",
            "Epoch 0: train loss 3.592279 test loss 3.727738\n",
            "Epoch 0: train acc 0.000000 test acc 0.045054\n",
            "Epoch 0: train loss 3.561516 test loss 3.734092\n",
            "Epoch 0: train acc 0.153846 test acc 0.036882\n",
            "Epoch 0: train loss 3.764326 test loss 3.776651\n",
            "Epoch 0: train acc 0.115385 test acc 0.053871\n",
            "Epoch 0: train loss 3.637856 test loss 3.883774\n",
            "Epoch 0: train acc 0.076923 test acc 0.047957\n",
            "Epoch 0: train loss 3.756159 test loss 3.846833\n",
            "Epoch 0: train acc 0.038462 test acc 0.050860\n",
            "Epoch 0: train loss 3.773797 test loss 3.792022\n",
            "Epoch 0: train acc 0.000000 test acc 0.053441\n",
            "Epoch 0: train loss 3.424347 test loss 3.845046\n",
            "Epoch 0: train acc 0.269231 test acc 0.032258\n",
            "Epoch 0: train loss 3.607634 test loss 3.900310\n",
            "Epoch 0: train acc 0.000000 test acc 0.050215\n",
            "Epoch 0: train loss 3.674185 test loss 4.004346\n",
            "Epoch 0: train acc 0.038462 test acc 0.049570\n",
            "Epoch 0: train loss 4.265985 test loss 3.832350\n",
            "Epoch 0: train acc 0.000000 test acc 0.064839\n",
            "Epoch 0: train loss 3.673092 test loss 3.780714\n",
            "Epoch 0: train acc 0.076923 test acc 0.037634\n",
            "Epoch 0: train loss 3.722565 test loss 3.799674\n",
            "Epoch 0: train acc 0.000000 test acc 0.033548\n",
            "Epoch 0: train loss 3.859959 test loss 3.701021\n",
            "Epoch 0: train acc 0.038462 test acc 0.036237\n",
            "Epoch 0: train loss 3.957063 test loss 3.667906\n",
            "Epoch 0: train acc 0.000000 test acc 0.048495\n",
            "Epoch 0: train loss 3.737811 test loss 3.690215\n",
            "Epoch 0: train acc 0.000000 test acc 0.050323\n",
            "Epoch 0: train loss 4.045870 test loss 3.646621\n",
            "Epoch 0: train acc 0.000000 test acc 0.060000\n",
            "Epoch 0: train loss 3.703958 test loss 3.761373\n",
            "Epoch 0: train acc 0.038462 test acc 0.062581\n",
            "Epoch 0: train loss 3.736634 test loss 3.890956\n",
            "Epoch 0: train acc 0.076923 test acc 0.035806\n",
            "Epoch 0: train loss 3.958016 test loss 3.951595\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 4.199509 test loss 3.921119\n",
            "Epoch 0: train acc 0.000000 test acc 0.049677\n",
            "Epoch 0: train loss 3.786919 test loss 3.874362\n",
            "Epoch 0: train acc 0.076923 test acc 0.050968\n",
            "Epoch 0: train loss 3.770831 test loss 3.983054\n",
            "Epoch 0: train acc 0.038462 test acc 0.045054\n",
            "Epoch 0: train loss 3.993931 test loss 4.103239\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 3.885756 test loss 4.250139\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 4.664718 test loss 4.023449\n",
            "Epoch 0: train acc 0.000000 test acc 0.034409\n",
            "Epoch 0: train loss 4.164250 test loss 3.989536\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 4.032243 test loss 4.203303\n",
            "Epoch 0: train acc 0.038462 test acc 0.038817\n",
            "Epoch 0: train loss 4.263432 test loss 4.056368\n",
            "Epoch 0: train acc 0.038462 test acc 0.041720\n",
            "Epoch 0: train loss 3.885629 test loss 4.048024\n",
            "Epoch 0: train acc 0.038462 test acc 0.033871\n",
            "Epoch 0: train loss 3.439735 test loss 4.129685\n",
            "Epoch 0: train acc 0.115385 test acc 0.031720\n",
            "Epoch 0: train loss 4.142372 test loss 4.148430\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 4.030421 test loss 4.237881\n",
            "Epoch 0: train acc 0.076923 test acc 0.035161\n",
            "Epoch 0: train loss 4.013619 test loss 4.461169\n",
            "Epoch 0: train acc 0.076923 test acc 0.037097\n",
            "Epoch 0: train loss 4.922974 test loss 4.545635\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.941481 test loss 4.492875\n",
            "Epoch 0: train acc 0.038462 test acc 0.034731\n",
            "Epoch 0: train loss 4.151222 test loss 4.425558\n",
            "Epoch 0: train acc 0.076923 test acc 0.032581\n",
            "Epoch 0: train loss 4.197686 test loss 4.298468\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 4.021743 test loss 4.282457\n",
            "Epoch 0: train acc 0.038462 test acc 0.034731\n",
            "Epoch 0: train loss 3.844133 test loss 4.249659\n",
            "Epoch 0: train acc 0.000000 test acc 0.034409\n",
            "Epoch 0: train loss 3.804052 test loss 4.277122\n",
            "Epoch 0: train acc 0.038462 test acc 0.049032\n",
            "Epoch 0: train loss 3.637367 test loss 4.439511\n",
            "Epoch 0: train acc 0.000000 test acc 0.047634\n",
            "Epoch 0: train loss 4.466964 test loss 4.473740\n",
            "Epoch 0: train acc 0.000000 test acc 0.056774\n",
            "Epoch 0: train loss 5.227292 test loss 4.313898\n",
            "Epoch 0: train acc 0.076923 test acc 0.056774\n",
            "Epoch 0: train loss 3.948574 test loss 4.189712\n",
            "Epoch 0: train acc 0.038462 test acc 0.059677\n",
            "Epoch 0: train loss 4.038189 test loss 4.064427\n",
            "Epoch 0: train acc 0.076923 test acc 0.036882\n",
            "Epoch 0: train loss 3.850496 test loss 4.079473\n",
            "Epoch 0: train acc 0.000000 test acc 0.037957\n",
            "Epoch 0: train loss 3.433741 test loss 4.253242\n",
            "Epoch 0: train acc 0.038462 test acc 0.038065\n",
            "Epoch 0: train loss 3.990647 test loss 4.270442\n",
            "Epoch 0: train acc 0.038462 test acc 0.039462\n",
            "Epoch 0: train loss 4.268393 test loss 4.060259\n",
            "Epoch 0: train acc 0.038462 test acc 0.033656\n",
            "Epoch 0: train loss 4.279809 test loss 3.872871\n",
            "Epoch 0: train acc 0.000000 test acc 0.040968\n",
            "Epoch 0: train loss 4.243563 test loss 3.802415\n",
            "Epoch 0: train acc 0.153846 test acc 0.040323\n",
            "Epoch 0: train loss 3.665529 test loss 3.850867\n",
            "Epoch 0: train acc 0.076923 test acc 0.041290\n",
            "Epoch 0: train loss 3.894279 test loss 3.909399\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 3.840736 test loss 4.027183\n",
            "Epoch 0: train acc 0.076923 test acc 0.060000\n",
            "Epoch 0: train loss 4.258038 test loss 4.215658\n",
            "Epoch 0: train acc 0.038462 test acc 0.048925\n",
            "Epoch 0: train loss 3.975913 test loss 4.240364\n",
            "Epoch 0: train acc 0.000000 test acc 0.047634\n",
            "Epoch 0: train loss 4.982045 test loss 3.962584\n",
            "Epoch 0: train acc 0.038462 test acc 0.055054\n",
            "Epoch 0: train loss 3.750237 test loss 4.001267\n",
            "Epoch 0: train acc 0.192308 test acc 0.034516\n",
            "Epoch 0: train loss 3.536974 test loss 4.063277\n",
            "Epoch 0: train acc 0.076923 test acc 0.034194\n",
            "Epoch 0: train loss 4.101497 test loss 3.983861\n",
            "Epoch 0: train acc 0.038462 test acc 0.039032\n",
            "Epoch 0: train loss 3.875338 test loss 4.104486\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 3.952251 test loss 3.889326\n",
            "Epoch 0: train acc 0.038462 test acc 0.040538\n",
            "Epoch 0: train loss 4.318884 test loss 3.689752\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 3.876888 test loss 3.702233\n",
            "Epoch 0: train acc 0.038462 test acc 0.041720\n",
            "Epoch 0: train loss 3.991304 test loss 3.853754\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 3.577770 test loss 4.120069\n",
            "Epoch 0: train acc 0.038462 test acc 0.033226\n",
            "Epoch 0: train loss 4.106596 test loss 4.124840\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 3.879239 test loss 4.180705\n",
            "Epoch 0: train acc 0.076923 test acc 0.031720\n",
            "Epoch 0: train loss 4.756437 test loss 3.912675\n",
            "Epoch 0: train acc 0.000000 test acc 0.034516\n",
            "Epoch 0: train loss 3.821517 test loss 3.894865\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 4.022946 test loss 3.893704\n",
            "Epoch 0: train acc 0.038462 test acc 0.045699\n",
            "Epoch 0: train loss 4.102639 test loss 3.978609\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 3.795199 test loss 4.060889\n",
            "Epoch 0: train acc 0.000000 test acc 0.032043\n",
            "Epoch 0: train loss 3.780976 test loss 4.109682\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 3.931555 test loss 4.068633\n",
            "Epoch 0: train acc 0.076923 test acc 0.072903\n",
            "Epoch 0: train loss 4.238447 test loss 3.956681\n",
            "Epoch 0: train acc 0.115385 test acc 0.052258\n",
            "Epoch 0: train loss 4.014452 test loss 3.825565\n",
            "Epoch 0: train acc 0.000000 test acc 0.095054\n",
            "Epoch 0: train loss 3.661698 test loss 3.764473\n",
            "Epoch 0: train acc 0.192308 test acc 0.040215\n",
            "Epoch 0: train loss 4.017688 test loss 3.731726\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 3.962447 test loss 3.815774\n",
            "Epoch 0: train acc 0.076923 test acc 0.032473\n",
            "Epoch 0: train loss 3.675633 test loss 3.976851\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 3.823513 test loss 3.930572\n",
            "Epoch 0: train acc 0.000000 test acc 0.035054\n",
            "Epoch 0: train loss 3.650069 test loss 3.929469\n",
            "Epoch 0: train acc 0.000000 test acc 0.040645\n",
            "Epoch 0: train loss 3.436892 test loss 4.116879\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.180011 test loss 4.176207\n",
            "Epoch 0: train acc 0.076923 test acc 0.037849\n",
            "Epoch 0: train loss 4.224223 test loss 4.051370\n",
            "Epoch 0: train acc 0.076923 test acc 0.033656\n",
            "Epoch 0: train loss 3.863849 test loss 3.891862\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 4.254045 test loss 3.727593\n",
            "Epoch 0: train acc 0.000000 test acc 0.065054\n",
            "Epoch 0: train loss 3.942215 test loss 3.729020\n",
            "Epoch 0: train acc 0.000000 test acc 0.051828\n",
            "Epoch 0: train loss 3.422975 test loss 3.951715\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 4.324307 test loss 4.010937\n",
            "Epoch 0: train acc 0.038462 test acc 0.030645\n",
            "Epoch 0: train loss 3.967942 test loss 4.084213\n",
            "Epoch 0: train acc 0.038462 test acc 0.038495\n",
            "Epoch 0: train loss 4.400511 test loss 4.130403\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 3.835756 test loss 4.093981\n",
            "Epoch 0: train acc 0.038462 test acc 0.036344\n",
            "Epoch 0: train loss 4.449767 test loss 3.978863\n",
            "Epoch 0: train acc 0.038462 test acc 0.039355\n",
            "Epoch 0: train loss 4.090357 test loss 4.022791\n",
            "Epoch 0: train acc 0.038462 test acc 0.035376\n",
            "Epoch 0: train loss 3.561476 test loss 4.022766\n",
            "Epoch 0: train acc 0.000000 test acc 0.039570\n",
            "Epoch 0: train loss 3.703373 test loss 4.099122\n",
            "Epoch 0: train acc 0.000000 test acc 0.040108\n",
            "Epoch 0: train loss 4.127929 test loss 4.058416\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 4.029458 test loss 4.097222\n",
            "Epoch 0: train acc 0.076923 test acc 0.032473\n",
            "Epoch 0: train loss 3.854754 test loss 4.024577\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 3.677443 test loss 4.084902\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 3.908430 test loss 4.189022\n",
            "Epoch 0: train acc 0.038462 test acc 0.046774\n",
            "Epoch 0: train loss 4.825747 test loss 4.091940\n",
            "Epoch 0: train acc 0.038462 test acc 0.046667\n",
            "Epoch 0: train loss 3.764932 test loss 4.029179\n",
            "Epoch 0: train acc 0.115385 test acc 0.048172\n",
            "Epoch 0: train loss 3.929096 test loss 4.041583\n",
            "Epoch 0: train acc 0.038462 test acc 0.050430\n",
            "Epoch 0: train loss 4.435530 test loss 4.045477\n",
            "Epoch 0: train acc 0.038462 test acc 0.033333\n",
            "Epoch 0: train loss 4.110258 test loss 3.982873\n",
            "Epoch 0: train acc 0.000000 test acc 0.040000\n",
            "Epoch 0: train loss 4.278948 test loss 3.932528\n",
            "Epoch 0: train acc 0.038462 test acc 0.038817\n",
            "Epoch 0: train loss 3.961025 test loss 3.868403\n",
            "Epoch 0: train acc 0.038462 test acc 0.038172\n",
            "Epoch 0: train loss 3.927623 test loss 3.901790\n",
            "Epoch 0: train acc 0.038462 test acc 0.035269\n",
            "Epoch 0: train loss 4.249820 test loss 3.854535\n",
            "Epoch 0: train acc 0.000000 test acc 0.043656\n",
            "Epoch 0: train loss 3.714802 test loss 4.047210\n",
            "Epoch 0: train acc 0.076923 test acc 0.037849\n",
            "Epoch 0: train loss 3.868550 test loss 4.310879\n",
            "Epoch 0: train acc 0.000000 test acc 0.045914\n",
            "Epoch 0: train loss 4.507699 test loss 4.092673\n",
            "Epoch 0: train acc 0.038462 test acc 0.071183\n",
            "Epoch 0: train loss 4.133675 test loss 3.862563\n",
            "Epoch 0: train acc 0.115385 test acc 0.034409\n",
            "Epoch 0: train loss 3.896385 test loss 3.916097\n",
            "Epoch 0: train acc 0.000000 test acc 0.032258\n",
            "Epoch 0: train loss 3.573444 test loss 4.354155\n",
            "Epoch 0: train acc 0.038462 test acc 0.031935\n",
            "Epoch 0: train loss 4.161933 test loss 4.470004\n",
            "Epoch 0: train acc 0.115385 test acc 0.033118\n",
            "Epoch 0: train loss 4.144500 test loss 4.069556\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.048488 test loss 3.988786\n",
            "Epoch 0: train acc 0.000000 test acc 0.031720\n",
            "Epoch 0: train loss 4.034817 test loss 4.062854\n",
            "Epoch 0: train acc 0.115385 test acc 0.035161\n",
            "Epoch 0: train loss 3.587028 test loss 4.226013\n",
            "Epoch 0: train acc 0.076923 test acc 0.052366\n",
            "Epoch 0: train loss 4.255822 test loss 4.407164\n",
            "Epoch 0: train acc 0.076923 test acc 0.033978\n",
            "Epoch 0: train loss 5.276764 test loss 4.075092\n",
            "Epoch 0: train acc 0.038462 test acc 0.054301\n",
            "Epoch 0: train loss 3.709700 test loss 4.047085\n",
            "Epoch 0: train acc 0.000000 test acc 0.065484\n",
            "Epoch 0: train loss 3.702064 test loss 4.250203\n",
            "Epoch 0: train acc 0.038462 test acc 0.036989\n",
            "Epoch 0: train loss 4.545922 test loss 4.264658\n",
            "Epoch 0: train acc 0.000000 test acc 0.050323\n",
            "Epoch 0: train loss 4.203406 test loss 4.216213\n",
            "Epoch 0: train acc 0.000000 test acc 0.034409\n",
            "Epoch 0: train loss 4.306782 test loss 4.107768\n",
            "Epoch 0: train acc 0.000000 test acc 0.058602\n",
            "Epoch 0: train loss 4.242951 test loss 4.076910\n",
            "Epoch 0: train acc 0.038462 test acc 0.058817\n",
            "Epoch 0: train loss 4.192742 test loss 4.152404\n",
            "Epoch 0: train acc 0.076923 test acc 0.059032\n",
            "Epoch 0: train loss 4.416715 test loss 4.218057\n",
            "Epoch 0: train acc 0.000000 test acc 0.070108\n",
            "Epoch 0: train loss 4.446834 test loss 4.154200\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 4.350021 test loss 4.221500\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 5.043099 test loss 3.995271\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 3.716381 test loss 3.904264\n",
            "Epoch 0: train acc 0.038462 test acc 0.036882\n",
            "Epoch 0: train loss 4.009060 test loss 3.944735\n",
            "Epoch 0: train acc 0.153846 test acc 0.031183\n",
            "Epoch 0: train loss 4.182126 test loss 4.010148\n",
            "Epoch 0: train acc 0.038462 test acc 0.034731\n",
            "Epoch 0: train loss 4.255835 test loss 4.117442\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 4.156608 test loss 4.193334\n",
            "Epoch 0: train acc 0.000000 test acc 0.033333\n",
            "Epoch 0: train loss 4.115622 test loss 4.184510\n",
            "Epoch 0: train acc 0.076923 test acc 0.033871\n",
            "Epoch 0: train loss 4.200954 test loss 4.019483\n",
            "Epoch 0: train acc 0.000000 test acc 0.046774\n",
            "Epoch 0: train loss 3.701961 test loss 4.036480\n",
            "Epoch 0: train acc 0.115385 test acc 0.033333\n",
            "Epoch 0: train loss 3.558605 test loss 4.113832\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 4.579504 test loss 4.170371\n",
            "Epoch 0: train acc 0.000000 test acc 0.036774\n",
            "Epoch 0: train loss 3.943156 test loss 4.215375\n",
            "Epoch 0: train acc 0.076923 test acc 0.030968\n",
            "Epoch 0: train loss 3.592642 test loss 4.120213\n",
            "Epoch 0: train acc 0.000000 test acc 0.064624\n",
            "Epoch 0: train loss 4.388731 test loss 4.151491\n",
            "Epoch 0: train acc 0.000000 test acc 0.053333\n",
            "Epoch 0: train loss 4.434030 test loss 4.054315\n",
            "Epoch 0: train acc 0.076923 test acc 0.062043\n",
            "Epoch 0: train loss 3.310374 test loss 4.159710\n",
            "Epoch 0: train acc 0.115385 test acc 0.058817\n",
            "Epoch 0: train loss 4.185480 test loss 4.175163\n",
            "Epoch 0: train acc 0.038462 test acc 0.038387\n",
            "Epoch 0: train loss 3.656651 test loss 4.069808\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.297222 test loss 4.064778\n",
            "Epoch 0: train acc 0.000000 test acc 0.038710\n",
            "Epoch 0: train loss 4.055177 test loss 3.979108\n",
            "Epoch 0: train acc 0.038462 test acc 0.037419\n",
            "Epoch 0: train loss 3.766483 test loss 3.979138\n",
            "Epoch 0: train acc 0.000000 test acc 0.041290\n",
            "Epoch 0: train loss 3.949778 test loss 4.142449\n",
            "Epoch 0: train acc 0.076923 test acc 0.047312\n",
            "Epoch 0: train loss 4.371329 test loss 4.111920\n",
            "Epoch 0: train acc 0.038462 test acc 0.050968\n",
            "Epoch 0: train loss 4.513243 test loss 3.999992\n",
            "Epoch 0: train acc 0.000000 test acc 0.054731\n",
            "Epoch 0: train loss 3.783298 test loss 3.954795\n",
            "Epoch 0: train acc 0.038462 test acc 0.039032\n",
            "Epoch 0: train loss 3.841095 test loss 3.768445\n",
            "Epoch 0: train acc 0.000000 test acc 0.045054\n",
            "Epoch 0: train loss 4.198053 test loss 3.756207\n",
            "Epoch 0: train acc 0.038462 test acc 0.038280\n",
            "Epoch 0: train loss 3.709046 test loss 3.798588\n",
            "Epoch 0: train acc 0.038462 test acc 0.031183\n",
            "Epoch 0: train loss 3.950583 test loss 3.850010\n",
            "Epoch 0: train acc 0.000000 test acc 0.028710\n",
            "Epoch 0: train loss 3.492295 test loss 3.925977\n",
            "Epoch 0: train acc 0.000000 test acc 0.044839\n",
            "Epoch 0: train loss 4.004013 test loss 3.893642\n",
            "Epoch 0: train acc 0.076923 test acc 0.055914\n",
            "Epoch 0: train loss 3.901828 test loss 3.781954\n",
            "Epoch 0: train acc 0.115385 test acc 0.053011\n",
            "Epoch 0: train loss 3.455244 test loss 3.739918\n",
            "Epoch 0: train acc 0.076923 test acc 0.056882\n",
            "Epoch 0: train loss 4.070223 test loss 3.742520\n",
            "Epoch 0: train acc 0.153846 test acc 0.045699\n",
            "Epoch 0: train loss 3.824261 test loss 3.708233\n",
            "Epoch 0: train acc 0.038462 test acc 0.048602\n",
            "Epoch 0: train loss 3.725917 test loss 3.707698\n",
            "Epoch 0: train acc 0.038462 test acc 0.036989\n",
            "Epoch 0: train loss 3.687476 test loss 3.668616\n",
            "Epoch 0: train acc 0.000000 test acc 0.037419\n",
            "Epoch 0: train loss 3.719396 test loss 3.674224\n",
            "Epoch 0: train acc 0.115385 test acc 0.038817\n",
            "Epoch 0: train loss 3.519395 test loss 3.746492\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 3.682070 test loss 3.757653\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 3.559645 test loss 3.759161\n",
            "Epoch 0: train acc 0.076923 test acc 0.033763\n",
            "Epoch 0: train loss 3.736585 test loss 3.733858\n",
            "Epoch 0: train acc 0.000000 test acc 0.041183\n",
            "Epoch 0: train loss 3.915477 test loss 3.684826\n",
            "Epoch 0: train acc 0.153846 test acc 0.032903\n",
            "Epoch 0: train loss 3.638830 test loss 3.631655\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.664886 test loss 3.658900\n",
            "Epoch 0: train acc 0.000000 test acc 0.036344\n",
            "Epoch 0: train loss 3.920781 test loss 3.739988\n",
            "Epoch 0: train acc 0.115385 test acc 0.035054\n",
            "Epoch 0: train loss 3.625034 test loss 3.902006\n",
            "Epoch 0: train acc 0.000000 test acc 0.039892\n",
            "Epoch 0: train loss 4.113524 test loss 3.829571\n",
            "Epoch 0: train acc 0.038462 test acc 0.054516\n",
            "Epoch 0: train loss 4.515768 test loss 3.606478\n",
            "Epoch 0: train acc 0.000000 test acc 0.037097\n",
            "Epoch 0: train loss 3.645797 test loss 3.683703\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.591172 test loss 3.896372\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 3.979033 test loss 3.870593\n",
            "Epoch 0: train acc 0.000000 test acc 0.065699\n",
            "Epoch 0: train loss 3.656408 test loss 3.953099\n",
            "Epoch 0: train acc 0.000000 test acc 0.054731\n",
            "Epoch 0: train loss 4.054677 test loss 3.971050\n",
            "Epoch 0: train acc 0.000000 test acc 0.059785\n",
            "Epoch 0: train loss 3.568112 test loss 3.989638\n",
            "Epoch 0: train acc 0.000000 test acc 0.065269\n",
            "Epoch 0: train loss 3.948136 test loss 3.956148\n",
            "Epoch 0: train acc 0.115385 test acc 0.039785\n",
            "Epoch 0: train loss 3.598261 test loss 3.888392\n",
            "Epoch 0: train acc 0.076923 test acc 0.039462\n",
            "Epoch 0: train loss 4.262593 test loss 4.004515\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 3.842500 test loss 4.050625\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 4.071249 test loss 3.992475\n",
            "Epoch 0: train acc 0.076923 test acc 0.034409\n",
            "Epoch 0: train loss 3.799547 test loss 3.937456\n",
            "Epoch 0: train acc 0.076923 test acc 0.034946\n",
            "Epoch 0: train loss 4.046187 test loss 3.993971\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 4.169193 test loss 3.949116\n",
            "Epoch 0: train acc 0.000000 test acc 0.032688\n",
            "Epoch 0: train loss 3.716642 test loss 3.782466\n",
            "Epoch 0: train acc 0.192308 test acc 0.032688\n",
            "Epoch 0: train loss 4.087996 test loss 3.621007\n",
            "Epoch 0: train acc 0.076923 test acc 0.037097\n",
            "Epoch 0: train loss 3.637851 test loss 3.706668\n",
            "Epoch 0: train acc 0.076923 test acc 0.034624\n",
            "Epoch 0: train loss 3.601079 test loss 3.791379\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 4.134217 test loss 3.746408\n",
            "Epoch 0: train acc 0.038462 test acc 0.057849\n",
            "Epoch 0: train loss 3.550564 test loss 3.746136\n",
            "Epoch 0: train acc 0.076923 test acc 0.076452\n",
            "Epoch 0: train loss 3.604642 test loss 3.756320\n",
            "Epoch 0: train acc 0.115385 test acc 0.062043\n",
            "Epoch 0: train loss 3.445635 test loss 3.763581\n",
            "Epoch 0: train acc 0.115385 test acc 0.059570\n",
            "Epoch 0: train loss 3.524064 test loss 3.702536\n",
            "Epoch 0: train acc 0.076923 test acc 0.058280\n",
            "Epoch 0: train loss 3.640435 test loss 3.680424\n",
            "Epoch 0: train acc 0.038462 test acc 0.059140\n",
            "Epoch 0: train loss 3.597519 test loss 3.741088\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 3.443763 test loss 3.875176\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 3.812693 test loss 3.898958\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 3.738958 test loss 3.913521\n",
            "Epoch 0: train acc 0.038462 test acc 0.035484\n",
            "Epoch 0: train loss 4.105149 test loss 3.927797\n",
            "Epoch 0: train acc 0.115385 test acc 0.032151\n",
            "Epoch 0: train loss 4.818521 test loss 3.751935\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 3.423128 test loss 3.765827\n",
            "Epoch 0: train acc 0.000000 test acc 0.036022\n",
            "Epoch 0: train loss 3.489163 test loss 3.892804\n",
            "Epoch 0: train acc 0.000000 test acc 0.040538\n",
            "Epoch 0: train loss 4.336375 test loss 3.891303\n",
            "Epoch 0: train acc 0.038462 test acc 0.033441\n",
            "Epoch 0: train loss 3.821743 test loss 3.850798\n",
            "Epoch 0: train acc 0.076923 test acc 0.033763\n",
            "Epoch 0: train loss 4.195983 test loss 3.746582\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 3.704853 test loss 3.761196\n",
            "Epoch 0: train acc 0.038462 test acc 0.034946\n",
            "Epoch 0: train loss 3.965137 test loss 3.766260\n",
            "Epoch 0: train acc 0.000000 test acc 0.052043\n",
            "Epoch 0: train loss 3.671816 test loss 3.828676\n",
            "Epoch 0: train acc 0.076923 test acc 0.078817\n",
            "Epoch 0: train loss 3.662416 test loss 3.862277\n",
            "Epoch 0: train acc 0.038462 test acc 0.081828\n",
            "Epoch 0: train loss 3.771699 test loss 3.840940\n",
            "Epoch 0: train acc 0.153846 test acc 0.050430\n",
            "Epoch 0: train loss 3.874042 test loss 3.831946\n",
            "Epoch 0: train acc 0.076923 test acc 0.037204\n",
            "Epoch 0: train loss 4.231069 test loss 3.782081\n",
            "Epoch 0: train acc 0.000000 test acc 0.034946\n",
            "Epoch 0: train loss 3.599959 test loss 3.791943\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.447637 test loss 3.875664\n",
            "Epoch 0: train acc 0.076923 test acc 0.032581\n",
            "Epoch 0: train loss 4.047188 test loss 3.889640\n",
            "Epoch 0: train acc 0.000000 test acc 0.040215\n",
            "Epoch 0: train loss 3.881034 test loss 3.922318\n",
            "Epoch 0: train acc 0.038462 test acc 0.040753\n",
            "Epoch 0: train loss 3.894167 test loss 3.855722\n",
            "Epoch 0: train acc 0.038462 test acc 0.058280\n",
            "Epoch 0: train loss 3.960677 test loss 3.745265\n",
            "Epoch 0: train acc 0.076923 test acc 0.055806\n",
            "Epoch 0: train loss 3.968212 test loss 3.718181\n",
            "Epoch 0: train acc 0.115385 test acc 0.040538\n",
            "Epoch 0: train loss 3.828891 test loss 3.785201\n",
            "Epoch 0: train acc 0.076923 test acc 0.038065\n",
            "Epoch 0: train loss 4.011819 test loss 3.838905\n",
            "Epoch 0: train acc 0.076923 test acc 0.034839\n",
            "Epoch 0: train loss 3.460613 test loss 3.853070\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 3.902877 test loss 3.814696\n",
            "Epoch 0: train acc 0.038462 test acc 0.035161\n",
            "Epoch 0: train loss 3.897023 test loss 3.661689\n",
            "Epoch 0: train acc 0.038462 test acc 0.035054\n",
            "Epoch 0: train loss 3.633301 test loss 3.592436\n",
            "Epoch 0: train acc 0.076923 test acc 0.048065\n",
            "Epoch 0: train loss 3.505386 test loss 3.624703\n",
            "Epoch 0: train acc 0.076923 test acc 0.065376\n",
            "Epoch 0: train loss 3.521480 test loss 3.705450\n",
            "Epoch 0: train acc 0.076923 test acc 0.057849\n",
            "Epoch 0: train loss 3.362338 test loss 3.889755\n",
            "Epoch 0: train acc 0.000000 test acc 0.041505\n",
            "Epoch 0: train loss 4.098210 test loss 3.858302\n",
            "Epoch 0: train acc 0.038462 test acc 0.057849\n",
            "Epoch 0: train loss 4.335222 test loss 3.731927\n",
            "Epoch 0: train acc 0.038462 test acc 0.040215\n",
            "Epoch 0: train loss 3.626455 test loss 3.575652\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.379290 test loss 3.541652\n",
            "Epoch 0: train acc 0.076923 test acc 0.038925\n",
            "Epoch 0: train loss 3.677545 test loss 3.542980\n",
            "Epoch 0: train acc 0.115385 test acc 0.034301\n",
            "Epoch 0: train loss 3.488387 test loss 3.593292\n",
            "Epoch 0: train acc 0.000000 test acc 0.050430\n",
            "Epoch 0: train loss 3.177924 test loss 3.867781\n",
            "Epoch 0: train acc 0.076923 test acc 0.036774\n",
            "Epoch 0: train loss 3.945665 test loss 4.045116\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 3.726052 test loss 4.010190\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.709106 test loss 3.956815\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.048594 test loss 3.926900\n",
            "Epoch 0: train acc 0.076923 test acc 0.052903\n",
            "Epoch 0: train loss 3.513032 test loss 3.961201\n",
            "Epoch 0: train acc 0.076923 test acc 0.052258\n",
            "Epoch 0: train loss 4.159284 test loss 3.843811\n",
            "Epoch 0: train acc 0.038462 test acc 0.036774\n",
            "Epoch 0: train loss 3.925632 test loss 3.781567\n",
            "Epoch 0: train acc 0.076923 test acc 0.033763\n",
            "Epoch 0: train loss 3.753431 test loss 3.729147\n",
            "Epoch 0: train acc 0.038462 test acc 0.032796\n",
            "Epoch 0: train loss 3.578290 test loss 3.840954\n",
            "Epoch 0: train acc 0.115385 test acc 0.034194\n",
            "Epoch 0: train loss 3.510436 test loss 4.021172\n",
            "Epoch 0: train acc 0.000000 test acc 0.035161\n",
            "Epoch 0: train loss 3.765334 test loss 4.055834\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 4.338936 test loss 3.927362\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.696571 test loss 3.797667\n",
            "Epoch 0: train acc 0.076923 test acc 0.037204\n",
            "Epoch 0: train loss 3.719249 test loss 3.741092\n",
            "Epoch 0: train acc 0.038462 test acc 0.041613\n",
            "Epoch 0: train loss 3.582698 test loss 3.857947\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.443693 test loss 4.031007\n",
            "Epoch 0: train acc 0.076923 test acc 0.037204\n",
            "Epoch 0: train loss 4.283652 test loss 3.828424\n",
            "Epoch 0: train acc 0.000000 test acc 0.060000\n",
            "Epoch 0: train loss 3.826231 test loss 3.746244\n",
            "Epoch 0: train acc 0.038462 test acc 0.058172\n",
            "Epoch 0: train loss 3.651922 test loss 3.875702\n",
            "Epoch 0: train acc 0.115385 test acc 0.077849\n",
            "Epoch 0: train loss 3.878565 test loss 3.929884\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 3.506808 test loss 3.967471\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 4.179296 test loss 3.860460\n",
            "Epoch 0: train acc 0.000000 test acc 0.041828\n",
            "Epoch 0: train loss 3.779732 test loss 3.794533\n",
            "Epoch 0: train acc 0.000000 test acc 0.058817\n",
            "Epoch 0: train loss 3.536015 test loss 3.840673\n",
            "Epoch 0: train acc 0.076923 test acc 0.060430\n",
            "Epoch 0: train loss 4.007648 test loss 3.887694\n",
            "Epoch 0: train acc 0.038462 test acc 0.060538\n",
            "Epoch 0: train loss 4.128419 test loss 3.828797\n",
            "Epoch 0: train acc 0.038462 test acc 0.061183\n",
            "Epoch 0: train loss 3.659914 test loss 3.820102\n",
            "Epoch 0: train acc 0.115385 test acc 0.062043\n",
            "Epoch 0: train loss 3.779163 test loss 3.828559\n",
            "Epoch 0: train acc 0.038462 test acc 0.054301\n",
            "Epoch 0: train loss 3.889987 test loss 3.801000\n",
            "Epoch 0: train acc 0.000000 test acc 0.041075\n",
            "Epoch 0: train loss 3.722666 test loss 3.821278\n",
            "Epoch 0: train acc 0.038462 test acc 0.041505\n",
            "Epoch 0: train loss 3.959599 test loss 3.681363\n",
            "Epoch 0: train acc 0.038462 test acc 0.047957\n",
            "Epoch 0: train loss 3.993686 test loss 3.633032\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.789970 test loss 3.727917\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 3.871056 test loss 3.850252\n",
            "Epoch 0: train acc 0.000000 test acc 0.036774\n",
            "Epoch 0: train loss 3.968560 test loss 3.851021\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 3.931513 test loss 3.761652\n",
            "Epoch 0: train acc 0.038462 test acc 0.040968\n",
            "Epoch 0: train loss 3.472493 test loss 3.830959\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.830848 test loss 3.889525\n",
            "Epoch 0: train acc 0.038462 test acc 0.049247\n",
            "Epoch 0: train loss 3.682667 test loss 3.838874\n",
            "Epoch 0: train acc 0.076923 test acc 0.056022\n",
            "Epoch 0: train loss 4.565119 test loss 3.778340\n",
            "Epoch 0: train acc 0.038462 test acc 0.059140\n",
            "Epoch 0: train loss 3.753305 test loss 3.752985\n",
            "Epoch 0: train acc 0.076923 test acc 0.032366\n",
            "Epoch 0: train loss 3.886833 test loss 3.723366\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 3.395956 test loss 3.845540\n",
            "Epoch 0: train acc 0.000000 test acc 0.035376\n",
            "Epoch 0: train loss 3.764517 test loss 3.896900\n",
            "Epoch 0: train acc 0.000000 test acc 0.035591\n",
            "Epoch 0: train loss 3.492681 test loss 3.876299\n",
            "Epoch 0: train acc 0.000000 test acc 0.035269\n",
            "Epoch 0: train loss 4.069990 test loss 3.805031\n",
            "Epoch 0: train acc 0.038462 test acc 0.053763\n",
            "Epoch 0: train loss 3.923983 test loss 3.822287\n",
            "Epoch 0: train acc 0.076923 test acc 0.034624\n",
            "Epoch 0: train loss 3.674196 test loss 3.901846\n",
            "Epoch 0: train acc 0.076923 test acc 0.034516\n",
            "Epoch 0: train loss 3.757332 test loss 4.060268\n",
            "Epoch 0: train acc 0.038462 test acc 0.032043\n",
            "Epoch 0: train loss 3.682786 test loss 4.237457\n",
            "Epoch 0: train acc 0.000000 test acc 0.039355\n",
            "Epoch 0: train loss 4.152689 test loss 4.102528\n",
            "Epoch 0: train acc 0.038462 test acc 0.059570\n",
            "Epoch 0: train loss 4.087594 test loss 4.037015\n",
            "Epoch 0: train acc 0.038462 test acc 0.053226\n",
            "Epoch 0: train loss 4.011691 test loss 4.213500\n",
            "Epoch 0: train acc 0.076923 test acc 0.032473\n",
            "Epoch 0: train loss 3.696223 test loss 4.276279\n",
            "Epoch 0: train acc 0.038462 test acc 0.032366\n",
            "Epoch 0: train loss 3.854522 test loss 4.047209\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.011363 test loss 3.683461\n",
            "Epoch 0: train acc 0.000000 test acc 0.037204\n",
            "Epoch 0: train loss 3.636585 test loss 3.635849\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.810830 test loss 3.799700\n",
            "Epoch 0: train acc 0.000000 test acc 0.038280\n",
            "Epoch 0: train loss 3.693984 test loss 3.921197\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 3.496276 test loss 4.013254\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 4.018110 test loss 3.943854\n",
            "Epoch 0: train acc 0.076923 test acc 0.053011\n",
            "Epoch 0: train loss 4.296605 test loss 3.889408\n",
            "Epoch 0: train acc 0.038462 test acc 0.050000\n",
            "Epoch 0: train loss 3.503518 test loss 3.902113\n",
            "Epoch 0: train acc 0.115385 test acc 0.059355\n",
            "Epoch 0: train loss 4.022426 test loss 3.963118\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 3.868242 test loss 3.831399\n",
            "Epoch 0: train acc 0.038462 test acc 0.032688\n",
            "Epoch 0: train loss 4.344976 test loss 3.762198\n",
            "Epoch 0: train acc 0.000000 test acc 0.052688\n",
            "Epoch 0: train loss 3.337913 test loss 4.040665\n",
            "Epoch 0: train acc 0.038462 test acc 0.044516\n",
            "Epoch 0: train loss 3.795671 test loss 4.181447\n",
            "Epoch 0: train acc 0.153846 test acc 0.068172\n",
            "Epoch 0: train loss 4.415873 test loss 4.176526\n",
            "Epoch 0: train acc 0.076923 test acc 0.036129\n",
            "Epoch 0: train loss 5.103776 test loss 3.884445\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 4.170395 test loss 3.742555\n",
            "Epoch 0: train acc 0.076923 test acc 0.037849\n",
            "Epoch 0: train loss 3.587291 test loss 3.893005\n",
            "Epoch 0: train acc 0.000000 test acc 0.031613\n",
            "Epoch 0: train loss 3.635468 test loss 4.025346\n",
            "Epoch 0: train acc 0.000000 test acc 0.031398\n",
            "Epoch 0: train loss 4.231500 test loss 4.038023\n",
            "Epoch 0: train acc 0.000000 test acc 0.052473\n",
            "Epoch 0: train loss 3.920559 test loss 4.093213\n",
            "Epoch 0: train acc 0.038462 test acc 0.053441\n",
            "Epoch 0: train loss 4.372833 test loss 4.020993\n",
            "Epoch 0: train acc 0.076923 test acc 0.058495\n",
            "Epoch 0: train loss 4.019041 test loss 3.982186\n",
            "Epoch 0: train acc 0.076923 test acc 0.060538\n",
            "Epoch 0: train loss 4.168557 test loss 4.101496\n",
            "Epoch 0: train acc 0.000000 test acc 0.059032\n",
            "Epoch 0: train loss 4.310141 test loss 4.153893\n",
            "Epoch 0: train acc 0.038462 test acc 0.036559\n",
            "Epoch 0: train loss 4.659024 test loss 3.931542\n",
            "Epoch 0: train acc 0.038462 test acc 0.036344\n",
            "Epoch 0: train loss 3.711564 test loss 3.838249\n",
            "Epoch 0: train acc 0.038462 test acc 0.036452\n",
            "Epoch 0: train loss 3.693309 test loss 3.863454\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 3.410253 test loss 3.953511\n",
            "Epoch 0: train acc 0.000000 test acc 0.042473\n",
            "Epoch 0: train loss 4.022706 test loss 4.062415\n",
            "Epoch 0: train acc 0.038462 test acc 0.054946\n",
            "Epoch 0: train loss 3.980016 test loss 3.980570\n",
            "Epoch 0: train acc 0.038462 test acc 0.036022\n",
            "Epoch 0: train loss 3.652480 test loss 3.864578\n",
            "Epoch 0: train acc 0.038462 test acc 0.036882\n",
            "Epoch 0: train loss 3.597828 test loss 3.841061\n",
            "Epoch 0: train acc 0.115385 test acc 0.055161\n",
            "Epoch 0: train loss 3.946136 test loss 3.806851\n",
            "Epoch 0: train acc 0.038462 test acc 0.058925\n",
            "Epoch 0: train loss 3.637915 test loss 3.949434\n",
            "Epoch 0: train acc 0.115385 test acc 0.058280\n",
            "Epoch 0: train loss 3.665206 test loss 3.970159\n",
            "Epoch 0: train acc 0.038462 test acc 0.062043\n",
            "Epoch 0: train loss 3.986792 test loss 3.927072\n",
            "Epoch 0: train acc 0.038462 test acc 0.054516\n",
            "Epoch 0: train loss 3.717314 test loss 3.941415\n",
            "Epoch 0: train acc 0.115385 test acc 0.046667\n",
            "Epoch 0: train loss 3.857691 test loss 3.997729\n",
            "Epoch 0: train acc 0.038462 test acc 0.059247\n",
            "Epoch 0: train loss 4.364579 test loss 3.905507\n",
            "Epoch 0: train acc 0.000000 test acc 0.061613\n",
            "Epoch 0: train loss 3.545371 test loss 3.823188\n",
            "Epoch 0: train acc 0.076923 test acc 0.058925\n",
            "Epoch 0: train loss 3.550788 test loss 3.724255\n",
            "Epoch 0: train acc 0.000000 test acc 0.033441\n",
            "Epoch 0: train loss 3.624223 test loss 3.692662\n",
            "Epoch 0: train acc 0.000000 test acc 0.036667\n",
            "Epoch 0: train loss 3.411034 test loss 3.726509\n",
            "Epoch 0: train acc 0.076923 test acc 0.041828\n",
            "Epoch 0: train loss 3.798003 test loss 3.707083\n",
            "Epoch 0: train acc 0.076923 test acc 0.043763\n",
            "Epoch 0: train loss 3.998675 test loss 3.711796\n",
            "Epoch 0: train acc 0.038462 test acc 0.032903\n",
            "Epoch 0: train loss 3.814636 test loss 3.701229\n",
            "Epoch 0: train acc 0.000000 test acc 0.045591\n",
            "Epoch 0: train loss 3.640054 test loss 3.749491\n",
            "Epoch 0: train acc 0.038462 test acc 0.037312\n",
            "Epoch 0: train loss 4.051578 test loss 3.760011\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 3.708966 test loss 3.771777\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 3.528529 test loss 3.763591\n",
            "Epoch 0: train acc 0.000000 test acc 0.033871\n",
            "Epoch 0: train loss 3.892666 test loss 3.788200\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 3.533393 test loss 3.795331\n",
            "Epoch 0: train acc 0.076923 test acc 0.036774\n",
            "Epoch 0: train loss 3.627032 test loss 3.741993\n",
            "Epoch 0: train acc 0.038462 test acc 0.031720\n",
            "Epoch 0: train loss 4.290979 test loss 3.676490\n",
            "Epoch 0: train acc 0.000000 test acc 0.045269\n",
            "Epoch 0: train loss 3.786416 test loss 3.604833\n",
            "Epoch 0: train acc 0.038462 test acc 0.059032\n",
            "Epoch 0: train loss 3.674799 test loss 3.591461\n",
            "Epoch 0: train acc 0.115385 test acc 0.057742\n",
            "Epoch 0: train loss 3.496857 test loss 3.749007\n",
            "Epoch 0: train acc 0.076923 test acc 0.053226\n",
            "Epoch 0: train loss 3.941488 test loss 3.698669\n",
            "Epoch 0: train acc 0.038462 test acc 0.060108\n",
            "Epoch 0: train loss 3.710457 test loss 3.590965\n",
            "Epoch 0: train acc 0.153846 test acc 0.040968\n",
            "Epoch 0: train loss 3.442664 test loss 3.600859\n",
            "Epoch 0: train acc 0.076923 test acc 0.039462\n",
            "Epoch 0: train loss 3.731804 test loss 3.673743\n",
            "Epoch 0: train acc 0.000000 test acc 0.062366\n",
            "Epoch 0: train loss 3.736357 test loss 3.789613\n",
            "Epoch 0: train acc 0.115385 test acc 0.039355\n",
            "Epoch 0: train loss 3.804038 test loss 3.754514\n",
            "Epoch 0: train acc 0.000000 test acc 0.052366\n",
            "Epoch 0: train loss 3.824637 test loss 3.670420\n",
            "Epoch 0: train acc 0.115385 test acc 0.059462\n",
            "Epoch 0: train loss 3.226253 test loss 3.691481\n",
            "Epoch 0: train acc 0.038462 test acc 0.055591\n",
            "Epoch 0: train loss 3.766038 test loss 3.705370\n",
            "Epoch 0: train acc 0.153846 test acc 0.035161\n",
            "Epoch 0: train loss 3.737664 test loss 3.667747\n",
            "Epoch 0: train acc 0.000000 test acc 0.054409\n",
            "Epoch 0: train loss 3.297693 test loss 3.984829\n",
            "Epoch 0: train acc 0.115385 test acc 0.031828\n",
            "Epoch 0: train loss 4.138832 test loss 3.943539\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 3.774587 test loss 3.838364\n",
            "Epoch 0: train acc 0.038462 test acc 0.056882\n",
            "Epoch 0: train loss 4.146300 test loss 3.765190\n",
            "Epoch 0: train acc 0.076923 test acc 0.049140\n",
            "Epoch 0: train loss 3.816305 test loss 3.691032\n",
            "Epoch 0: train acc 0.076923 test acc 0.054516\n",
            "Epoch 0: train loss 3.692215 test loss 3.961859\n",
            "Epoch 0: train acc 0.115385 test acc 0.030000\n",
            "Epoch 0: train loss 4.233576 test loss 3.849920\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 4.134976 test loss 3.702800\n",
            "Epoch 0: train acc 0.000000 test acc 0.035376\n",
            "Epoch 0: train loss 3.663289 test loss 3.744171\n",
            "Epoch 0: train acc 0.038462 test acc 0.053118\n",
            "Epoch 0: train loss 3.637833 test loss 3.887876\n",
            "Epoch 0: train acc 0.038462 test acc 0.032473\n",
            "Epoch 0: train loss 4.715783 test loss 3.862971\n",
            "Epoch 0: train acc 0.000000 test acc 0.047849\n",
            "Epoch 0: train loss 4.078265 test loss 3.754765\n",
            "Epoch 0: train acc 0.076923 test acc 0.060753\n",
            "Epoch 0: train loss 4.033416 test loss 3.711428\n",
            "Epoch 0: train acc 0.038462 test acc 0.063548\n",
            "Epoch 0: train loss 3.745620 test loss 3.781652\n",
            "Epoch 0: train acc 0.000000 test acc 0.035376\n",
            "Epoch 0: train loss 3.817721 test loss 3.775528\n",
            "Epoch 0: train acc 0.038462 test acc 0.030430\n",
            "Epoch 0: train loss 4.104692 test loss 3.599644\n",
            "Epoch 0: train acc 0.038462 test acc 0.035806\n",
            "Epoch 0: train loss 3.374469 test loss 3.608572\n",
            "Epoch 0: train acc 0.076923 test acc 0.037634\n",
            "Epoch 0: train loss 3.348561 test loss 3.733692\n",
            "Epoch 0: train acc 0.038462 test acc 0.043871\n",
            "Epoch 0: train loss 3.705004 test loss 3.849359\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 3.687683 test loss 3.906270\n",
            "Epoch 0: train acc 0.000000 test acc 0.034301\n",
            "Epoch 0: train loss 4.205403 test loss 3.759943\n",
            "Epoch 0: train acc 0.038462 test acc 0.039032\n",
            "Epoch 0: train loss 3.631907 test loss 3.640708\n",
            "Epoch 0: train acc 0.038462 test acc 0.044194\n",
            "Epoch 0: train loss 3.611891 test loss 3.586165\n",
            "Epoch 0: train acc 0.076923 test acc 0.034194\n",
            "Epoch 0: train loss 3.439746 test loss 3.655893\n",
            "Epoch 0: train acc 0.038462 test acc 0.034301\n",
            "Epoch 0: train loss 3.715646 test loss 3.654013\n",
            "Epoch 0: train acc 0.076923 test acc 0.039140\n",
            "Epoch 0: train loss 3.554122 test loss 3.696833\n",
            "Epoch 0: train acc 0.115385 test acc 0.057742\n",
            "Epoch 0: train loss 4.207392 test loss 3.686071\n",
            "Epoch 0: train acc 0.038462 test acc 0.047742\n",
            "Epoch 0: train loss 3.508889 test loss 3.779542\n",
            "Epoch 0: train acc 0.038462 test acc 0.055699\n",
            "Epoch 0: train loss 3.712811 test loss 3.775003\n",
            "Epoch 0: train acc 0.076923 test acc 0.051075\n",
            "Epoch 0: train loss 4.198107 test loss 3.715316\n",
            "Epoch 0: train acc 0.076923 test acc 0.036237\n",
            "Epoch 0: train loss 3.813711 test loss 3.712778\n",
            "Epoch 0: train acc 0.038462 test acc 0.035914\n",
            "Epoch 0: train loss 4.022806 test loss 3.690697\n",
            "Epoch 0: train acc 0.000000 test acc 0.035484\n",
            "Epoch 0: train loss 3.456031 test loss 3.840017\n",
            "Epoch 0: train acc 0.153846 test acc 0.033118\n",
            "Epoch 0: train loss 4.106867 test loss 3.681593\n",
            "Epoch 0: train acc 0.000000 test acc 0.041613\n",
            "Epoch 0: train loss 3.249601 test loss 3.732960\n",
            "Epoch 0: train acc 0.115385 test acc 0.035806\n",
            "Epoch 0: train loss 4.151222 test loss 3.822869\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.018352 test loss 3.820828\n",
            "Epoch 0: train acc 0.000000 test acc 0.034194\n",
            "Epoch 0: train loss 3.517019 test loss 3.788543\n",
            "Epoch 0: train acc 0.076923 test acc 0.044409\n",
            "Epoch 0: train loss 3.982747 test loss 3.858023\n",
            "Epoch 0: train acc 0.115385 test acc 0.043441\n",
            "Epoch 0: train loss 4.363026 test loss 3.798927\n",
            "Epoch 0: train acc 0.038462 test acc 0.035161\n",
            "Epoch 0: train loss 3.989478 test loss 3.722253\n",
            "Epoch 0: train acc 0.038462 test acc 0.040968\n",
            "Epoch 0: train loss 3.878245 test loss 3.627571\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 3.422530 test loss 3.615889\n",
            "Epoch 0: train acc 0.076923 test acc 0.033011\n",
            "Epoch 0: train loss 3.504642 test loss 3.601978\n",
            "Epoch 0: train acc 0.038462 test acc 0.053548\n",
            "Epoch 0: train loss 3.586196 test loss 3.670012\n",
            "Epoch 0: train acc 0.000000 test acc 0.054086\n",
            "Epoch 0: train loss 3.710903 test loss 3.809379\n",
            "Epoch 0: train acc 0.076923 test acc 0.049462\n",
            "Epoch 0: train loss 3.983275 test loss 3.776765\n",
            "Epoch 0: train acc 0.038462 test acc 0.056989\n",
            "Epoch 0: train loss 3.940039 test loss 3.635994\n",
            "Epoch 0: train acc 0.038462 test acc 0.055914\n",
            "Epoch 0: train loss 3.435326 test loss 3.580435\n",
            "Epoch 0: train acc 0.076923 test acc 0.061935\n",
            "Epoch 0: train loss 3.696197 test loss 3.580628\n",
            "Epoch 0: train acc 0.076923 test acc 0.048495\n",
            "Epoch 0: train loss 3.916281 test loss 3.510493\n",
            "Epoch 0: train acc 0.000000 test acc 0.048925\n",
            "Epoch 0: train loss 3.691095 test loss 3.517131\n",
            "Epoch 0: train acc 0.000000 test acc 0.051613\n",
            "Epoch 0: train loss 3.339503 test loss 3.702366\n",
            "Epoch 0: train acc 0.076923 test acc 0.033118\n",
            "Epoch 0: train loss 3.917922 test loss 3.815423\n",
            "Epoch 0: train acc 0.000000 test acc 0.033656\n",
            "Epoch 0: train loss 3.831022 test loss 3.824084\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 4.232103 test loss 3.626208\n",
            "Epoch 0: train acc 0.000000 test acc 0.034409\n",
            "Epoch 0: train loss 3.447537 test loss 3.558772\n",
            "Epoch 0: train acc 0.000000 test acc 0.055806\n",
            "Epoch 0: train loss 3.895781 test loss 3.607597\n",
            "Epoch 0: train acc 0.038462 test acc 0.037419\n",
            "Epoch 0: train loss 3.391047 test loss 3.850163\n",
            "Epoch 0: train acc 0.038462 test acc 0.040108\n",
            "Epoch 0: train loss 4.069426 test loss 3.885572\n",
            "Epoch 0: train acc 0.038462 test acc 0.042688\n",
            "Epoch 0: train loss 3.883852 test loss 3.851089\n",
            "Epoch 0: train acc 0.038462 test acc 0.034086\n",
            "Epoch 0: train loss 4.389702 test loss 3.796817\n",
            "Epoch 0: train acc 0.076923 test acc 0.059785\n",
            "Epoch 0: train loss 3.885893 test loss 3.716172\n",
            "Epoch 0: train acc 0.000000 test acc 0.059462\n",
            "Epoch 0: train loss 3.609058 test loss 3.728433\n",
            "Epoch 0: train acc 0.076923 test acc 0.062151\n",
            "Epoch 0: train loss 3.844396 test loss 3.786508\n",
            "Epoch 0: train acc 0.038462 test acc 0.039785\n",
            "Epoch 0: train loss 3.613062 test loss 3.866577\n",
            "Epoch 0: train acc 0.076923 test acc 0.035806\n",
            "Epoch 0: train loss 4.034201 test loss 3.692907\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 3.661047 test loss 3.548600\n",
            "Epoch 0: train acc 0.038462 test acc 0.057204\n",
            "Epoch 0: train loss 3.365369 test loss 3.640715\n",
            "Epoch 0: train acc 0.000000 test acc 0.051505\n",
            "Epoch 0: train loss 3.820535 test loss 3.788177\n",
            "Epoch 0: train acc 0.038462 test acc 0.034194\n",
            "Epoch 0: train loss 3.896599 test loss 3.891923\n",
            "Epoch 0: train acc 0.000000 test acc 0.038172\n",
            "Epoch 0: train loss 4.213936 test loss 3.841801\n",
            "Epoch 0: train acc 0.038462 test acc 0.046237\n",
            "Epoch 0: train loss 3.792415 test loss 3.726449\n",
            "Epoch 0: train acc 0.115385 test acc 0.039247\n",
            "Epoch 0: train loss 4.033593 test loss 3.679025\n",
            "Epoch 0: train acc 0.076923 test acc 0.054839\n",
            "Epoch 0: train loss 3.867039 test loss 3.794969\n",
            "Epoch 0: train acc 0.000000 test acc 0.032581\n",
            "Epoch 0: train loss 3.718063 test loss 3.822190\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.695344 test loss 3.837345\n",
            "Epoch 0: train acc 0.115385 test acc 0.036022\n",
            "Epoch 0: train loss 4.187592 test loss 3.771928\n",
            "Epoch 0: train acc 0.076923 test acc 0.036022\n",
            "Epoch 0: train loss 3.794404 test loss 3.721328\n",
            "Epoch 0: train acc 0.038462 test acc 0.054086\n",
            "Epoch 0: train loss 3.950988 test loss 3.699159\n",
            "Epoch 0: train acc 0.000000 test acc 0.060538\n",
            "Epoch 0: train loss 3.723391 test loss 3.653659\n",
            "Epoch 0: train acc 0.038462 test acc 0.050968\n",
            "Epoch 0: train loss 3.537374 test loss 3.644260\n",
            "Epoch 0: train acc 0.076923 test acc 0.054409\n",
            "Epoch 0: train loss 3.551428 test loss 3.677250\n",
            "Epoch 0: train acc 0.115385 test acc 0.049462\n",
            "Epoch 0: train loss 3.657095 test loss 3.778175\n",
            "Epoch 0: train acc 0.115385 test acc 0.058817\n",
            "Epoch 0: train loss 4.096725 test loss 3.827890\n",
            "Epoch 0: train acc 0.000000 test acc 0.053871\n",
            "Epoch 0: train loss 3.783992 test loss 3.847557\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 3.522180 test loss 3.883692\n",
            "Epoch 0: train acc 0.076923 test acc 0.040968\n",
            "Epoch 0: train loss 4.076102 test loss 3.838882\n",
            "Epoch 0: train acc 0.000000 test acc 0.033226\n",
            "Epoch 0: train loss 4.057947 test loss 3.713335\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 3.687603 test loss 3.709959\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 4.300951 test loss 3.612006\n",
            "Epoch 0: train acc 0.000000 test acc 0.036774\n",
            "Epoch 0: train loss 3.537822 test loss 3.753554\n",
            "Epoch 0: train acc 0.076923 test acc 0.042043\n",
            "Epoch 0: train loss 4.072255 test loss 3.803595\n",
            "Epoch 0: train acc 0.000000 test acc 0.039355\n",
            "Epoch 0: train loss 3.660684 test loss 3.809762\n",
            "Epoch 0: train acc 0.000000 test acc 0.037312\n",
            "Epoch 0: train loss 4.003475 test loss 3.717990\n",
            "Epoch 0: train acc 0.000000 test acc 0.056882\n",
            "Epoch 0: train loss 3.598401 test loss 3.685312\n",
            "Epoch 0: train acc 0.153846 test acc 0.075699\n",
            "Epoch 0: train loss 3.942038 test loss 3.755136\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 3.715869 test loss 3.812663\n",
            "Epoch 0: train acc 0.038462 test acc 0.044516\n",
            "Epoch 0: train loss 3.785121 test loss 3.858174\n",
            "Epoch 0: train acc 0.115385 test acc 0.032043\n",
            "Epoch 0: train loss 3.705872 test loss 3.877366\n",
            "Epoch 0: train acc 0.115385 test acc 0.033226\n",
            "Epoch 0: train loss 3.569413 test loss 3.828249\n",
            "Epoch 0: train acc 0.076923 test acc 0.034301\n",
            "Epoch 0: train loss 3.817241 test loss 3.733607\n",
            "Epoch 0: train acc 0.000000 test acc 0.032473\n",
            "Epoch 0: train loss 3.837031 test loss 3.594776\n",
            "Epoch 0: train acc 0.038462 test acc 0.058172\n",
            "Epoch 0: train loss 3.826995 test loss 3.628955\n",
            "Epoch 0: train acc 0.076923 test acc 0.053548\n",
            "Epoch 0: train loss 3.464827 test loss 3.948315\n",
            "Epoch 0: train acc 0.038462 test acc 0.058710\n",
            "Epoch 0: train loss 3.838128 test loss 4.196547\n",
            "Epoch 0: train acc 0.038462 test acc 0.031075\n",
            "Epoch 0: train loss 4.585846 test loss 3.828455\n",
            "Epoch 0: train acc 0.038462 test acc 0.046989\n",
            "Epoch 0: train loss 4.500975 test loss 3.717459\n",
            "Epoch 0: train acc 0.038462 test acc 0.038065\n",
            "Epoch 0: train loss 3.703100 test loss 3.895002\n",
            "Epoch 0: train acc 0.000000 test acc 0.031828\n",
            "Epoch 0: train loss 4.039950 test loss 3.959142\n",
            "Epoch 0: train acc 0.038462 test acc 0.034946\n",
            "Epoch 0: train loss 3.944656 test loss 3.977991\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 4.431522 test loss 3.967486\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 4.347669 test loss 3.936967\n",
            "Epoch 0: train acc 0.115385 test acc 0.035054\n",
            "Epoch 0: train loss 3.700235 test loss 3.912799\n",
            "Epoch 0: train acc 0.000000 test acc 0.036129\n",
            "Epoch 0: train loss 4.456371 test loss 3.910945\n",
            "Epoch 0: train acc 0.038462 test acc 0.060108\n",
            "Epoch 0: train loss 3.914390 test loss 3.889408\n",
            "Epoch 0: train acc 0.038462 test acc 0.052903\n",
            "Epoch 0: train loss 4.023974 test loss 3.903724\n",
            "Epoch 0: train acc 0.000000 test acc 0.065269\n",
            "Epoch 0: train loss 3.843123 test loss 3.884253\n",
            "Epoch 0: train acc 0.038462 test acc 0.050645\n",
            "Epoch 0: train loss 4.040421 test loss 3.993445\n",
            "Epoch 0: train acc 0.038462 test acc 0.035484\n",
            "Epoch 0: train loss 3.946377 test loss 3.799653\n",
            "Epoch 0: train acc 0.038462 test acc 0.035806\n",
            "Epoch 0: train loss 4.185340 test loss 3.736681\n",
            "Epoch 0: train acc 0.000000 test acc 0.041935\n",
            "Epoch 0: train loss 3.696735 test loss 3.794623\n",
            "Epoch 0: train acc 0.038462 test acc 0.032581\n",
            "Epoch 0: train loss 4.018857 test loss 3.776169\n",
            "Epoch 0: train acc 0.000000 test acc 0.042366\n",
            "Epoch 0: train loss 3.594418 test loss 3.733048\n",
            "Epoch 0: train acc 0.038462 test acc 0.035914\n",
            "Epoch 0: train loss 3.677348 test loss 3.707653\n",
            "Epoch 0: train acc 0.038462 test acc 0.061290\n",
            "Epoch 0: train loss 3.767226 test loss 3.716161\n",
            "Epoch 0: train acc 0.115385 test acc 0.064946\n",
            "Epoch 0: train loss 3.762797 test loss 3.791726\n",
            "Epoch 0: train acc 0.038462 test acc 0.038495\n",
            "Epoch 0: train loss 3.357096 test loss 3.989067\n",
            "Epoch 0: train acc 0.038462 test acc 0.034409\n",
            "Epoch 0: train loss 4.334878 test loss 3.979167\n",
            "Epoch 0: train acc 0.038462 test acc 0.031290\n",
            "Epoch 0: train loss 4.352880 test loss 3.775728\n",
            "Epoch 0: train acc 0.000000 test acc 0.037957\n",
            "Epoch 0: train loss 3.397309 test loss 3.751574\n",
            "Epoch 0: train acc 0.153846 test acc 0.031613\n",
            "Epoch 0: train loss 4.074026 test loss 3.725005\n",
            "Epoch 0: train acc 0.000000 test acc 0.042473\n",
            "Epoch 0: train loss 3.336600 test loss 3.771289\n",
            "Epoch 0: train acc 0.000000 test acc 0.036989\n",
            "Epoch 0: train loss 4.185978 test loss 3.688950\n",
            "Epoch 0: train acc 0.076923 test acc 0.060860\n",
            "Epoch 0: train loss 3.444218 test loss 3.610079\n",
            "Epoch 0: train acc 0.000000 test acc 0.065699\n",
            "Epoch 0: train loss 3.360059 test loss 3.654270\n",
            "Epoch 0: train acc 0.038462 test acc 0.061720\n",
            "Epoch 0: train loss 3.562685 test loss 3.711187\n",
            "Epoch 0: train acc 0.038462 test acc 0.032366\n",
            "Epoch 0: train loss 3.697682 test loss 3.679648\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 3.495957 test loss 3.631568\n",
            "Epoch 0: train acc 0.000000 test acc 0.049247\n",
            "Epoch 0: train loss 3.832788 test loss 3.607446\n",
            "Epoch 0: train acc 0.038462 test acc 0.061290\n",
            "Epoch 0: train loss 3.597810 test loss 3.613171\n",
            "Epoch 0: train acc 0.038462 test acc 0.065269\n",
            "Epoch 0: train loss 3.461529 test loss 3.704144\n",
            "Epoch 0: train acc 0.076923 test acc 0.039462\n",
            "Epoch 0: train loss 3.314868 test loss 3.695862\n",
            "Epoch 0: train acc 0.076923 test acc 0.039785\n",
            "Epoch 0: train loss 3.991029 test loss 3.613732\n",
            "Epoch 0: train acc 0.038462 test acc 0.059785\n",
            "Epoch 0: train loss 3.525319 test loss 3.630672\n",
            "Epoch 0: train acc 0.115385 test acc 0.060538\n",
            "Epoch 0: train loss 3.699816 test loss 3.716944\n",
            "Epoch 0: train acc 0.076923 test acc 0.061935\n",
            "Epoch 0: train loss 3.721509 test loss 3.733252\n",
            "Epoch 0: train acc 0.038462 test acc 0.066559\n",
            "Epoch 0: train loss 4.203598 test loss 3.632732\n",
            "Epoch 0: train acc 0.076923 test acc 0.061183\n",
            "Epoch 0: train loss 3.871256 test loss 3.574234\n",
            "Epoch 0: train acc 0.000000 test acc 0.046882\n",
            "Epoch 0: train loss 3.517348 test loss 3.724337\n",
            "Epoch 0: train acc 0.038462 test acc 0.058602\n",
            "Epoch 0: train loss 3.661831 test loss 3.913771\n",
            "Epoch 0: train acc 0.076923 test acc 0.048065\n",
            "Epoch 0: train loss 4.048578 test loss 3.862290\n",
            "Epoch 0: train acc 0.038462 test acc 0.054839\n",
            "Epoch 0: train loss 4.605973 test loss 3.620939\n",
            "Epoch 0: train acc 0.038462 test acc 0.047419\n",
            "Epoch 0: train loss 3.498299 test loss 3.683205\n",
            "Epoch 0: train acc 0.000000 test acc 0.034839\n",
            "Epoch 0: train loss 3.882756 test loss 3.675643\n",
            "Epoch 0: train acc 0.038462 test acc 0.040753\n",
            "Epoch 0: train loss 3.264681 test loss 3.755509\n",
            "Epoch 0: train acc 0.115385 test acc 0.058495\n",
            "Epoch 0: train loss 3.576329 test loss 3.910350\n",
            "Epoch 0: train acc 0.076923 test acc 0.037419\n",
            "Epoch 0: train loss 3.752580 test loss 3.909415\n",
            "Epoch 0: train acc 0.038462 test acc 0.042796\n",
            "Epoch 0: train loss 3.970314 test loss 3.821082\n",
            "Epoch 0: train acc 0.038462 test acc 0.054516\n",
            "Epoch 0: train loss 3.552257 test loss 3.835099\n",
            "Epoch 0: train acc 0.192308 test acc 0.041183\n",
            "Epoch 0: train loss 3.549920 test loss 3.921966\n",
            "Epoch 0: train acc 0.076923 test acc 0.038172\n",
            "Epoch 0: train loss 3.891468 test loss 3.855564\n",
            "Epoch 0: train acc 0.038462 test acc 0.039462\n",
            "Epoch 0: train loss 4.122437 test loss 3.713492\n",
            "Epoch 0: train acc 0.038462 test acc 0.060753\n",
            "Epoch 0: train loss 3.742453 test loss 3.666990\n",
            "Epoch 0: train acc 0.076923 test acc 0.050430\n",
            "Epoch 0: train loss 3.053319 test loss 3.690200\n",
            "Epoch 0: train acc 0.076923 test acc 0.056344\n",
            "Epoch 0: train loss 3.837556 test loss 3.736971\n",
            "Epoch 0: train acc 0.038462 test acc 0.059140\n",
            "Epoch 0: train loss 3.764768 test loss 3.753138\n",
            "Epoch 0: train acc 0.038462 test acc 0.043871\n",
            "Epoch 0: train loss 3.822861 test loss 3.673297\n",
            "Epoch 0: train acc 0.076923 test acc 0.040215\n",
            "Epoch 0: train loss 3.585499 test loss 3.603820\n",
            "Epoch 0: train acc 0.038462 test acc 0.073118\n",
            "Epoch 0: train loss 3.641155 test loss 3.583878\n",
            "Epoch 0: train acc 0.115385 test acc 0.059355\n",
            "Epoch 0: train loss 3.777547 test loss 3.507905\n",
            "Epoch 0: train acc 0.038462 test acc 0.071613\n",
            "Epoch 0: train loss 3.408585 test loss 3.639046\n",
            "Epoch 0: train acc 0.115385 test acc 0.060215\n",
            "Epoch 0: train loss 4.005330 test loss 3.663325\n",
            "Epoch 0: train acc 0.076923 test acc 0.056667\n",
            "Epoch 0: train loss 3.727196 test loss 3.718967\n",
            "Epoch 0: train acc 0.038462 test acc 0.056022\n",
            "Epoch 0: train loss 3.754464 test loss 3.836646\n",
            "Epoch 0: train acc 0.000000 test acc 0.060430\n",
            "Epoch 0: train loss 3.737849 test loss 3.733823\n",
            "Epoch 0: train acc 0.115385 test acc 0.060000\n",
            "Epoch 0: train loss 3.716906 test loss 3.630573\n",
            "Epoch 0: train acc 0.038462 test acc 0.052366\n",
            "Epoch 0: train loss 3.761008 test loss 3.700060\n",
            "Epoch 0: train acc 0.000000 test acc 0.028172\n",
            "Epoch 0: train loss 3.848454 test loss 3.786657\n",
            "Epoch 0: train acc 0.076923 test acc 0.029785\n",
            "Epoch 0: train loss 3.803826 test loss 3.787288\n",
            "Epoch 0: train acc 0.076923 test acc 0.033763\n",
            "Epoch 0: train loss 3.808738 test loss 3.700008\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 3.833104 test loss 3.684083\n",
            "Epoch 0: train acc 0.000000 test acc 0.033763\n",
            "Epoch 0: train loss 3.378801 test loss 3.911081\n",
            "Epoch 0: train acc 0.076923 test acc 0.033441\n",
            "Epoch 0: train loss 3.850643 test loss 3.919947\n",
            "Epoch 0: train acc 0.038462 test acc 0.050645\n",
            "Epoch 0: train loss 4.101811 test loss 3.683298\n",
            "Epoch 0: train acc 0.000000 test acc 0.038065\n",
            "Epoch 0: train loss 3.852755 test loss 3.517729\n",
            "Epoch 0: train acc 0.000000 test acc 0.060323\n",
            "Epoch 0: train loss 3.589964 test loss 3.612780\n",
            "Epoch 0: train acc 0.076923 test acc 0.059785\n",
            "Epoch 0: train loss 3.668693 test loss 3.704702\n",
            "Epoch 0: train acc 0.076923 test acc 0.057204\n",
            "Epoch 0: train loss 3.965483 test loss 3.643893\n",
            "Epoch 0: train acc 0.038462 test acc 0.057204\n",
            "Epoch 0: train loss 3.661414 test loss 3.670964\n",
            "Epoch 0: train acc 0.038462 test acc 0.040645\n",
            "Epoch 0: train loss 3.427119 test loss 3.779354\n",
            "Epoch 0: train acc 0.038462 test acc 0.033978\n",
            "Epoch 0: train loss 4.002557 test loss 3.794174\n",
            "Epoch 0: train acc 0.038462 test acc 0.036559\n",
            "Epoch 0: train loss 3.571072 test loss 3.891392\n",
            "Epoch 0: train acc 0.038462 test acc 0.035054\n",
            "Epoch 0: train loss 4.363273 test loss 3.937510\n",
            "Epoch 0: train acc 0.076923 test acc 0.030753\n",
            "Epoch 0: train loss 3.877645 test loss 3.638285\n",
            "Epoch 0: train acc 0.038462 test acc 0.063118\n",
            "Epoch 0: train loss 3.592491 test loss 3.800309\n",
            "Epoch 0: train acc 0.076923 test acc 0.058602\n",
            "Epoch 0: train loss 4.137227 test loss 3.874731\n",
            "Epoch 0: train acc 0.038462 test acc 0.056344\n",
            "Epoch 0: train loss 4.100659 test loss 3.656506\n",
            "Epoch 0: train acc 0.153846 test acc 0.058817\n",
            "Epoch 0: train loss 3.599938 test loss 3.651042\n",
            "Epoch 0: train acc 0.076923 test acc 0.068172\n",
            "Epoch 0: train loss 3.663616 test loss 3.861860\n",
            "Epoch 0: train acc 0.000000 test acc 0.033978\n",
            "Epoch 0: train loss 3.879461 test loss 3.953544\n",
            "Epoch 0: train acc 0.076923 test acc 0.034839\n",
            "Epoch 0: train loss 4.075028 test loss 3.945222\n",
            "Epoch 0: train acc 0.000000 test acc 0.033011\n",
            "Epoch 0: train loss 3.450792 test loss 4.083774\n",
            "Epoch 0: train acc 0.153846 test acc 0.032903\n",
            "Epoch 0: train loss 4.044105 test loss 3.737933\n",
            "Epoch 0: train acc 0.000000 test acc 0.064086\n",
            "Epoch 0: train loss 3.637473 test loss 3.921807\n",
            "Epoch 0: train acc 0.038462 test acc 0.061075\n",
            "Epoch 0: train loss 4.032396 test loss 3.955463\n",
            "Epoch 0: train acc 0.076923 test acc 0.058280\n",
            "Epoch 0: train loss 4.288097 test loss 3.773824\n",
            "Epoch 0: train acc 0.038462 test acc 0.052796\n",
            "Epoch 0: train loss 3.924575 test loss 3.774217\n",
            "Epoch 0: train acc 0.038462 test acc 0.052473\n",
            "Epoch 0: train loss 3.671299 test loss 3.966646\n",
            "Epoch 0: train acc 0.115385 test acc 0.051720\n",
            "Epoch 0: train loss 4.339119 test loss 3.950012\n",
            "Epoch 0: train acc 0.038462 test acc 0.035914\n",
            "Epoch 0: train loss 3.842990 test loss 3.901449\n",
            "Epoch 0: train acc 0.000000 test acc 0.037419\n",
            "Epoch 0: train loss 3.627431 test loss 4.007549\n",
            "Epoch 0: train acc 0.038462 test acc 0.030753\n",
            "Epoch 0: train loss 4.003034 test loss 3.942164\n",
            "Epoch 0: train acc 0.000000 test acc 0.039677\n",
            "Epoch 0: train loss 4.114360 test loss 3.847142\n",
            "Epoch 0: train acc 0.000000 test acc 0.034624\n",
            "Epoch 0: train loss 3.732148 test loss 3.940063\n",
            "Epoch 0: train acc 0.000000 test acc 0.032366\n",
            "Epoch 0: train loss 4.639451 test loss 3.846432\n",
            "Epoch 0: train acc 0.000000 test acc 0.035914\n",
            "Epoch 0: train loss 3.962985 test loss 3.707882\n",
            "Epoch 0: train acc 0.038462 test acc 0.034516\n",
            "Epoch 0: train loss 3.265461 test loss 3.924193\n",
            "Epoch 0: train acc 0.000000 test acc 0.035699\n",
            "Epoch 0: train loss 3.608559 test loss 3.918065\n",
            "Epoch 0: train acc 0.038462 test acc 0.056667\n",
            "Epoch 0: train loss 4.157153 test loss 3.830812\n",
            "Epoch 0: train acc 0.115385 test acc 0.070323\n",
            "Epoch 0: train loss 3.729842 test loss 3.856608\n",
            "Epoch 0: train acc 0.192308 test acc 0.056452\n",
            "Epoch 0: train loss 3.811338 test loss 3.787392\n",
            "Epoch 0: train acc 0.076923 test acc 0.061075\n",
            "Epoch 0: train loss 3.675329 test loss 3.883119\n",
            "Epoch 0: train acc 0.000000 test acc 0.052366\n",
            "Epoch 0: train loss 3.874545 test loss 3.868021\n",
            "Epoch 0: train acc 0.115385 test acc 0.052366\n",
            "Epoch 0: train loss 3.841899 test loss 3.740961\n",
            "Epoch 0: train acc 0.038462 test acc 0.063226\n",
            "Epoch 0: train loss 3.848322 test loss 3.831894\n",
            "Epoch 0: train acc 0.000000 test acc 0.055484\n",
            "Epoch 0: train loss 3.781807 test loss 3.977970\n",
            "Epoch 0: train acc 0.076923 test acc 0.034946\n",
            "Epoch 0: train loss 4.136789 test loss 3.853561\n",
            "Epoch 0: train acc 0.038462 test acc 0.035161\n",
            "Epoch 0: train loss 4.359879 test loss 3.914693\n",
            "Epoch 0: train acc 0.000000 test acc 0.037634\n",
            "Epoch 0: train loss 3.908735 test loss 3.800669\n",
            "Epoch 0: train acc 0.076923 test acc 0.032688\n",
            "Epoch 0: train loss 3.716710 test loss 3.756229\n",
            "Epoch 0: train acc 0.038462 test acc 0.061505\n",
            "Epoch 0: train loss 3.682087 test loss 3.854257\n",
            "Epoch 0: train acc 0.038462 test acc 0.057097\n",
            "Epoch 0: train loss 3.634917 test loss 3.953647\n",
            "Epoch 0: train acc 0.038462 test acc 0.060108\n",
            "Epoch 0: train loss 3.751551 test loss 4.069516\n",
            "Epoch 0: train acc 0.000000 test acc 0.039032\n",
            "Epoch 0: train loss 4.116714 test loss 4.064007\n",
            "Epoch 0: train acc 0.000000 test acc 0.050108\n",
            "Epoch 0: train loss 3.890508 test loss 4.012576\n",
            "Epoch 0: train acc 0.076923 test acc 0.038710\n",
            "Epoch 0: train loss 4.238662 test loss 3.865425\n",
            "Epoch 0: train acc 0.000000 test acc 0.040860\n",
            "Epoch 0: train loss 4.226577 test loss 3.814050\n",
            "Epoch 0: train acc 0.076923 test acc 0.046237\n",
            "Epoch 0: train loss 3.943085 test loss 3.905609\n",
            "Epoch 0: train acc 0.000000 test acc 0.028387\n",
            "Epoch 0: train loss 3.887527 test loss 3.849648\n",
            "Epoch 0: train acc 0.038462 test acc 0.028495\n",
            "Epoch 0: train loss 3.933713 test loss 3.734316\n",
            "Epoch 0: train acc 0.000000 test acc 0.081935\n",
            "Epoch 0: train loss 3.485150 test loss 3.882499\n",
            "Epoch 0: train acc 0.076923 test acc 0.062473\n",
            "Epoch 0: train loss 3.985090 test loss 3.929019\n",
            "Epoch 0: train acc 0.000000 test acc 0.038280\n",
            "Epoch 0: train loss 4.289206 test loss 3.875366\n",
            "Epoch 0: train acc 0.038462 test acc 0.036129\n",
            "Epoch 0: train loss 4.026769 test loss 3.748735\n",
            "Epoch 0: train acc 0.076923 test acc 0.035591\n",
            "Epoch 0: train loss 3.876193 test loss 3.779071\n",
            "Epoch 0: train acc 0.000000 test acc 0.032903\n",
            "Epoch 0: train loss 3.931299 test loss 3.818762\n",
            "Epoch 0: train acc 0.038462 test acc 0.033011\n",
            "Epoch 0: train loss 4.104999 test loss 3.824171\n",
            "Epoch 0: train acc 0.038462 test acc 0.031613\n",
            "Epoch 0: train loss 3.588922 test loss 3.924693\n",
            "Epoch 0: train acc 0.000000 test acc 0.035806\n",
            "Epoch 0: train loss 3.488619 test loss 4.062025\n",
            "Epoch 0: train acc 0.076923 test acc 0.038710\n",
            "Epoch 0: train loss 4.618458 test loss 4.055214\n",
            "Epoch 0: train acc 0.115385 test acc 0.033441\n",
            "Epoch 0: train loss 3.707010 test loss 4.043605\n",
            "Epoch 0: train acc 0.000000 test acc 0.039570\n",
            "Epoch 0: train loss 3.644523 test loss 4.031989\n",
            "Epoch 0: train acc 0.076923 test acc 0.041505\n",
            "Epoch 0: train loss 3.941694 test loss 3.916440\n",
            "Epoch 0: train acc 0.000000 test acc 0.066559\n",
            "Epoch 0: train loss 3.729143 test loss 3.852030\n",
            "Epoch 0: train acc 0.038462 test acc 0.045484\n",
            "Epoch 0: train loss 4.012580 test loss 3.752152\n",
            "Epoch 0: train acc 0.000000 test acc 0.036559\n",
            "Epoch 0: train loss 3.402349 test loss 3.709460\n",
            "Epoch 0: train acc 0.038462 test acc 0.033118\n",
            "Epoch 0: train loss 3.516518 test loss 3.722357\n",
            "Epoch 0: train acc 0.076923 test acc 0.062043\n",
            "Epoch 0: train loss 4.027737 test loss 3.713036\n",
            "Epoch 0: train acc 0.000000 test acc 0.050645\n",
            "Epoch 0: train loss 4.282875 test loss 3.645501\n",
            "Epoch 0: train acc 0.038462 test acc 0.048065\n",
            "Epoch 0: train loss 3.880593 test loss 3.624667\n",
            "Epoch 0: train acc 0.038462 test acc 0.057742\n",
            "Epoch 0: train loss 3.281025 test loss 3.716172\n",
            "Epoch 0: train acc 0.038462 test acc 0.033763\n",
            "Epoch 0: train loss 3.477952 test loss 3.767934\n",
            "Epoch 0: train acc 0.038462 test acc 0.033656\n",
            "Epoch 0: train loss 3.359390 test loss 3.692302\n",
            "Epoch 0: train acc 0.038462 test acc 0.063656\n",
            "Epoch 0: train loss 3.939764 test loss 3.683154\n",
            "Epoch 0: train acc 0.038462 test acc 0.061828\n",
            "Epoch 0: train loss 3.706982 test loss 3.658862\n",
            "Epoch 0: train acc 0.038462 test acc 0.040860\n",
            "Epoch 0: train loss 3.685126 test loss 3.723507\n",
            "Epoch 0: train acc 0.038462 test acc 0.036022\n",
            "Epoch 0: train loss 3.937042 test loss 3.746241\n",
            "Epoch 0: train acc 0.038462 test acc 0.036022\n",
            "Epoch 0: train loss 3.651943 test loss 3.701971\n",
            "Epoch 0: train acc 0.000000 test acc 0.039570\n",
            "Epoch 0: train loss 3.420754 test loss 3.694888\n",
            "Epoch 0: train acc 0.076923 test acc 0.035484\n",
            "Epoch 0: train loss 3.531135 test loss 3.738320\n",
            "Epoch 0: train acc 0.153846 test acc 0.035699\n",
            "Epoch 0: train loss 3.760518 test loss 3.748962\n",
            "Epoch 0: train acc 0.000000 test acc 0.058710\n",
            "Epoch 0: train loss 3.745293 test loss 3.756976\n",
            "Epoch 0: train acc 0.153846 test acc 0.072581\n",
            "Epoch 0: train loss 4.052960 test loss 3.710357\n",
            "Epoch 0: train acc 0.038462 test acc 0.057419\n",
            "Epoch 0: train loss 3.602220 test loss 3.789811\n",
            "Epoch 0: train acc 0.038462 test acc 0.066129\n",
            "Epoch 0: train loss 3.679328 test loss 3.920114\n",
            "Epoch 0: train acc 0.076923 test acc 0.056452\n",
            "Epoch 0: train loss 4.800163 test loss 3.803204\n",
            "Epoch 0: train acc 0.000000 test acc 0.055806\n",
            "Epoch 0: train loss 3.633638 test loss 3.781042\n",
            "Epoch 0: train acc 0.076923 test acc 0.032796\n",
            "Epoch 0: train loss 4.072307 test loss 3.661770\n",
            "Epoch 0: train acc 0.038462 test acc 0.039570\n",
            "Epoch 0: train loss 3.868820 test loss 3.739909\n",
            "Epoch 0: train acc 0.000000 test acc 0.038817\n",
            "Epoch 1: train loss 4.180569 test loss 3.716221\n",
            "Epoch 1: train acc 0.000000 test acc 0.033441\n",
            "Epoch 1: train loss 3.722910 test loss 3.739120\n",
            "Epoch 1: train acc 0.038462 test acc 0.053333\n",
            "Epoch 1: train loss 3.588816 test loss 3.765916\n",
            "Epoch 1: train acc 0.076923 test acc 0.073333\n",
            "Epoch 1: train loss 3.802766 test loss 3.830696\n",
            "Epoch 1: train acc 0.038462 test acc 0.052473\n",
            "Epoch 1: train loss 3.683280 test loss 3.856987\n",
            "Epoch 1: train acc 0.115385 test acc 0.054086\n",
            "Epoch 1: train loss 4.171534 test loss 3.767492\n",
            "Epoch 1: train acc 0.038462 test acc 0.053656\n",
            "Epoch 1: train loss 4.105597 test loss 3.707926\n",
            "Epoch 1: train acc 0.076923 test acc 0.034409\n",
            "Epoch 1: train loss 3.528899 test loss 3.750496\n",
            "Epoch 1: train acc 0.000000 test acc 0.041828\n",
            "Epoch 1: train loss 3.526798 test loss 3.797916\n",
            "Epoch 1: train acc 0.038462 test acc 0.052796\n",
            "Epoch 1: train loss 3.502797 test loss 3.968481\n",
            "Epoch 1: train acc 0.038462 test acc 0.061828\n",
            "Epoch 1: train loss 4.041725 test loss 4.050931\n",
            "Epoch 1: train acc 0.038462 test acc 0.038387\n",
            "Epoch 1: train loss 4.296088 test loss 3.895082\n",
            "Epoch 1: train acc 0.038462 test acc 0.049462\n",
            "Epoch 1: train loss 3.922451 test loss 3.791167\n",
            "Epoch 1: train acc 0.038462 test acc 0.045591\n",
            "Epoch 1: train loss 4.018476 test loss 3.706094\n",
            "Epoch 1: train acc 0.038462 test acc 0.033978\n",
            "Epoch 1: train loss 3.831775 test loss 3.656444\n",
            "Epoch 1: train acc 0.000000 test acc 0.055484\n",
            "Epoch 1: train loss 3.529038 test loss 3.716168\n",
            "Epoch 1: train acc 0.115385 test acc 0.057634\n",
            "Epoch 1: train loss 3.968418 test loss 3.783747\n",
            "Epoch 1: train acc 0.000000 test acc 0.061720\n",
            "Epoch 1: train loss 3.799829 test loss 3.775226\n",
            "Epoch 1: train acc 0.038462 test acc 0.060000\n",
            "Epoch 1: train loss 3.765601 test loss 3.699901\n",
            "Epoch 1: train acc 0.076923 test acc 0.077634\n",
            "Epoch 1: train loss 3.844059 test loss 3.606621\n",
            "Epoch 1: train acc 0.038462 test acc 0.055699\n",
            "Epoch 1: train loss 3.683640 test loss 3.574774\n",
            "Epoch 1: train acc 0.000000 test acc 0.086989\n",
            "Epoch 1: train loss 3.624202 test loss 3.657565\n",
            "Epoch 1: train acc 0.038462 test acc 0.071398\n",
            "Epoch 1: train loss 3.393023 test loss 3.849661\n",
            "Epoch 1: train acc 0.115385 test acc 0.044731\n",
            "Epoch 1: train loss 3.530391 test loss 3.887712\n",
            "Epoch 1: train acc 0.076923 test acc 0.031613\n",
            "Epoch 1: train loss 3.759572 test loss 3.821659\n",
            "Epoch 1: train acc 0.000000 test acc 0.043656\n",
            "Epoch 1: train loss 3.653747 test loss 3.823396\n",
            "Epoch 1: train acc 0.000000 test acc 0.041075\n",
            "Epoch 1: train loss 3.682195 test loss 3.733603\n",
            "Epoch 1: train acc 0.000000 test acc 0.050108\n",
            "Epoch 1: train loss 3.807492 test loss 3.643505\n",
            "Epoch 1: train acc 0.038462 test acc 0.034731\n",
            "Epoch 1: train loss 3.785243 test loss 3.720008\n",
            "Epoch 1: train acc 0.038462 test acc 0.036989\n",
            "Epoch 1: train loss 3.770865 test loss 3.794782\n",
            "Epoch 1: train acc 0.000000 test acc 0.035484\n",
            "Epoch 1: train loss 3.742630 test loss 3.795388\n",
            "Epoch 1: train acc 0.076923 test acc 0.035484\n",
            "Epoch 1: train loss 3.783060 test loss 3.730541\n",
            "Epoch 1: train acc 0.000000 test acc 0.030860\n",
            "Epoch 1: train loss 3.912936 test loss 3.753090\n",
            "Epoch 1: train acc 0.000000 test acc 0.034624\n",
            "Epoch 1: train loss 3.693090 test loss 3.860929\n",
            "Epoch 1: train acc 0.000000 test acc 0.048495\n",
            "Epoch 1: train loss 3.588702 test loss 3.938086\n",
            "Epoch 1: train acc 0.000000 test acc 0.030000\n",
            "Epoch 1: train loss 3.770998 test loss 3.927853\n",
            "Epoch 1: train acc 0.076923 test acc 0.030860\n",
            "Epoch 1: train loss 3.810514 test loss 3.786907\n",
            "Epoch 1: train acc 0.076923 test acc 0.032151\n",
            "Epoch 1: train loss 3.578866 test loss 3.731397\n",
            "Epoch 1: train acc 0.000000 test acc 0.057312\n",
            "Epoch 1: train loss 3.505966 test loss 3.816865\n",
            "Epoch 1: train acc 0.076923 test acc 0.064946\n",
            "Epoch 1: train loss 3.779131 test loss 3.752021\n",
            "Epoch 1: train acc 0.115385 test acc 0.065914\n",
            "Epoch 1: train loss 3.699596 test loss 3.704763\n",
            "Epoch 1: train acc 0.038462 test acc 0.060753\n",
            "Epoch 1: train loss 3.624126 test loss 3.785218\n",
            "Epoch 1: train acc 0.115385 test acc 0.061720\n",
            "Epoch 1: train loss 3.701715 test loss 3.818134\n",
            "Epoch 1: train acc 0.230769 test acc 0.083548\n",
            "Epoch 1: train loss 3.614414 test loss 3.915688\n",
            "Epoch 1: train acc 0.000000 test acc 0.059032\n",
            "Epoch 1: train loss 3.983556 test loss 3.911633\n",
            "Epoch 1: train acc 0.038462 test acc 0.059032\n",
            "Epoch 1: train loss 3.433942 test loss 3.939989\n",
            "Epoch 1: train acc 0.076923 test acc 0.067097\n",
            "Epoch 1: train loss 3.971012 test loss 3.911395\n",
            "Epoch 1: train acc 0.038462 test acc 0.065591\n",
            "Epoch 1: train loss 3.517291 test loss 3.866570\n",
            "Epoch 1: train acc 0.076923 test acc 0.068710\n",
            "Epoch 1: train loss 4.012199 test loss 3.783686\n",
            "Epoch 1: train acc 0.038462 test acc 0.064409\n",
            "Epoch 1: train loss 4.117537 test loss 3.689068\n",
            "Epoch 1: train acc 0.038462 test acc 0.061183\n",
            "Epoch 1: train loss 3.435999 test loss 3.688796\n",
            "Epoch 1: train acc 0.115385 test acc 0.037849\n",
            "Epoch 1: train loss 3.783006 test loss 3.710338\n",
            "Epoch 1: train acc 0.000000 test acc 0.033763\n",
            "Epoch 1: train loss 3.612978 test loss 3.814297\n",
            "Epoch 1: train acc 0.038462 test acc 0.038495\n",
            "Epoch 1: train loss 3.739419 test loss 3.822349\n",
            "Epoch 1: train acc 0.038462 test acc 0.034086\n",
            "Epoch 1: train loss 3.994650 test loss 3.681691\n",
            "Epoch 1: train acc 0.038462 test acc 0.033011\n",
            "Epoch 1: train loss 3.594412 test loss 3.711887\n",
            "Epoch 1: train acc 0.038462 test acc 0.032903\n",
            "Epoch 1: train loss 3.936344 test loss 3.761698\n",
            "Epoch 1: train acc 0.000000 test acc 0.029570\n",
            "Epoch 1: train loss 3.898128 test loss 3.786185\n",
            "Epoch 1: train acc 0.000000 test acc 0.055054\n",
            "Epoch 1: train loss 4.037297 test loss 3.813418\n",
            "Epoch 1: train acc 0.000000 test acc 0.074301\n",
            "Epoch 1: train loss 3.525981 test loss 3.793612\n",
            "Epoch 1: train acc 0.153846 test acc 0.086344\n",
            "Epoch 1: train loss 3.895689 test loss 3.704645\n",
            "Epoch 1: train acc 0.038462 test acc 0.080753\n",
            "Epoch 1: train loss 3.705501 test loss 3.618955\n",
            "Epoch 1: train acc 0.038462 test acc 0.068065\n",
            "Epoch 1: train loss 3.553648 test loss 3.612019\n",
            "Epoch 1: train acc 0.038462 test acc 0.042366\n",
            "Epoch 1: train loss 3.402013 test loss 3.619850\n",
            "Epoch 1: train acc 0.038462 test acc 0.058925\n",
            "Epoch 1: train loss 3.577449 test loss 3.630775\n",
            "Epoch 1: train acc 0.000000 test acc 0.064839\n",
            "Epoch 1: train loss 3.482029 test loss 3.648031\n",
            "Epoch 1: train acc 0.076923 test acc 0.055161\n",
            "Epoch 1: train loss 3.435638 test loss 3.610176\n",
            "Epoch 1: train acc 0.115385 test acc 0.049247\n",
            "Epoch 1: train loss 3.314623 test loss 3.651846\n",
            "Epoch 1: train acc 0.000000 test acc 0.043226\n",
            "Epoch 1: train loss 3.840496 test loss 3.665022\n",
            "Epoch 1: train acc 0.000000 test acc 0.037849\n",
            "Epoch 1: train loss 3.588934 test loss 3.714339\n",
            "Epoch 1: train acc 0.038462 test acc 0.035806\n",
            "Epoch 1: train loss 3.579380 test loss 3.728121\n",
            "Epoch 1: train acc 0.000000 test acc 0.035161\n",
            "Epoch 1: train loss 4.078183 test loss 3.675837\n",
            "Epoch 1: train acc 0.000000 test acc 0.034194\n",
            "Epoch 1: train loss 3.291565 test loss 3.745022\n",
            "Epoch 1: train acc 0.115385 test acc 0.036774\n",
            "Epoch 1: train loss 4.501686 test loss 3.746057\n",
            "Epoch 1: train acc 0.076923 test acc 0.032903\n",
            "Epoch 1: train loss 3.681795 test loss 3.692026\n",
            "Epoch 1: train acc 0.000000 test acc 0.032581\n",
            "Epoch 1: train loss 3.910945 test loss 3.594984\n",
            "Epoch 1: train acc 0.000000 test acc 0.050215\n",
            "Epoch 1: train loss 3.554572 test loss 3.576058\n",
            "Epoch 1: train acc 0.076923 test acc 0.039892\n",
            "Epoch 1: train loss 3.642819 test loss 3.649136\n",
            "Epoch 1: train acc 0.000000 test acc 0.053333\n",
            "Epoch 1: train loss 3.809009 test loss 3.640755\n",
            "Epoch 1: train acc 0.000000 test acc 0.079140\n",
            "Epoch 1: train loss 3.724732 test loss 3.637058\n",
            "Epoch 1: train acc 0.076923 test acc 0.053441\n",
            "Epoch 1: train loss 3.391604 test loss 3.706575\n",
            "Epoch 1: train acc 0.076923 test acc 0.049462\n",
            "Epoch 1: train loss 3.515313 test loss 3.818892\n",
            "Epoch 1: train acc 0.038462 test acc 0.035054\n",
            "Epoch 1: train loss 3.650804 test loss 3.925728\n",
            "Epoch 1: train acc 0.076923 test acc 0.036344\n",
            "Epoch 1: train loss 3.650382 test loss 3.979776\n",
            "Epoch 1: train acc 0.038462 test acc 0.047097\n",
            "Epoch 1: train loss 3.941377 test loss 3.951783\n",
            "Epoch 1: train acc 0.000000 test acc 0.041075\n",
            "Epoch 1: train loss 3.942252 test loss 3.942447\n",
            "Epoch 1: train acc 0.000000 test acc 0.039677\n",
            "Epoch 1: train loss 3.496742 test loss 3.931231\n",
            "Epoch 1: train acc 0.076923 test acc 0.033763\n",
            "Epoch 1: train loss 4.237239 test loss 3.837712\n",
            "Epoch 1: train acc 0.000000 test acc 0.037849\n",
            "Epoch 1: train loss 3.841241 test loss 3.856772\n",
            "Epoch 1: train acc 0.000000 test acc 0.044086\n",
            "Epoch 1: train loss 3.452216 test loss 3.801795\n",
            "Epoch 1: train acc 0.038462 test acc 0.045161\n",
            "Epoch 1: train loss 3.406542 test loss 3.791557\n",
            "Epoch 1: train acc 0.038462 test acc 0.040860\n",
            "Epoch 1: train loss 4.030014 test loss 3.818116\n",
            "Epoch 1: train acc 0.076923 test acc 0.034731\n",
            "Epoch 1: train loss 3.639055 test loss 3.787452\n",
            "Epoch 1: train acc 0.000000 test acc 0.033333\n",
            "Epoch 1: train loss 3.508619 test loss 3.763895\n",
            "Epoch 1: train acc 0.076923 test acc 0.056774\n",
            "Epoch 1: train loss 3.800943 test loss 3.742492\n",
            "Epoch 1: train acc 0.038462 test acc 0.073011\n",
            "Epoch 1: train loss 4.057619 test loss 3.676720\n",
            "Epoch 1: train acc 0.038462 test acc 0.062258\n",
            "Epoch 1: train loss 3.534900 test loss 3.690413\n",
            "Epoch 1: train acc 0.115385 test acc 0.053441\n",
            "Epoch 1: train loss 3.506156 test loss 3.690751\n",
            "Epoch 1: train acc 0.038462 test acc 0.034946\n",
            "Epoch 1: train loss 3.687809 test loss 3.766426\n",
            "Epoch 1: train acc 0.000000 test acc 0.031398\n",
            "Epoch 1: train loss 3.975957 test loss 3.734226\n",
            "Epoch 1: train acc 0.038462 test acc 0.030538\n",
            "Epoch 1: train loss 3.928128 test loss 3.585370\n",
            "Epoch 1: train acc 0.000000 test acc 0.033441\n",
            "Epoch 1: train loss 3.217779 test loss 3.688179\n",
            "Epoch 1: train acc 0.038462 test acc 0.033656\n",
            "Epoch 1: train loss 3.614032 test loss 3.845271\n",
            "Epoch 1: train acc 0.076923 test acc 0.033978\n",
            "Epoch 1: train loss 4.129364 test loss 3.896083\n",
            "Epoch 1: train acc 0.000000 test acc 0.035054\n",
            "Epoch 1: train loss 3.479061 test loss 3.946198\n",
            "Epoch 1: train acc 0.038462 test acc 0.035914\n",
            "Epoch 1: train loss 3.701931 test loss 3.981151\n",
            "Epoch 1: train acc 0.038462 test acc 0.035591\n",
            "Epoch 1: train loss 3.724288 test loss 4.048638\n",
            "Epoch 1: train acc 0.076923 test acc 0.031183\n",
            "Epoch 1: train loss 4.006760 test loss 3.959577\n",
            "Epoch 1: train acc 0.000000 test acc 0.059785\n",
            "Epoch 1: train loss 3.911483 test loss 3.945852\n",
            "Epoch 1: train acc 0.000000 test acc 0.054516\n",
            "Epoch 1: train loss 3.976457 test loss 3.907393\n",
            "Epoch 1: train acc 0.076923 test acc 0.056989\n",
            "Epoch 1: train loss 3.571134 test loss 3.920630\n",
            "Epoch 1: train acc 0.076923 test acc 0.052473\n",
            "Epoch 1: train loss 3.976473 test loss 3.927176\n",
            "Epoch 1: train acc 0.076923 test acc 0.031828\n",
            "Epoch 1: train loss 4.407804 test loss 3.693549\n",
            "Epoch 1: train acc 0.038462 test acc 0.064194\n",
            "Epoch 1: train loss 3.550013 test loss 3.674785\n",
            "Epoch 1: train acc 0.076923 test acc 0.036237\n",
            "Epoch 1: train loss 3.309034 test loss 3.739724\n",
            "Epoch 1: train acc 0.076923 test acc 0.063441\n",
            "Epoch 1: train loss 4.263640 test loss 3.692212\n",
            "Epoch 1: train acc 0.000000 test acc 0.056022\n",
            "Epoch 1: train loss 3.871290 test loss 3.825214\n",
            "Epoch 1: train acc 0.000000 test acc 0.041935\n",
            "Epoch 1: train loss 4.194458 test loss 3.927305\n",
            "Epoch 1: train acc 0.038462 test acc 0.033656\n",
            "Epoch 1: train loss 4.106784 test loss 3.970773\n",
            "Epoch 1: train acc 0.038462 test acc 0.041398\n",
            "Epoch 1: train loss 3.672331 test loss 4.009246\n",
            "Epoch 1: train acc 0.076923 test acc 0.035914\n",
            "Epoch 1: train loss 4.720103 test loss 3.812566\n",
            "Epoch 1: train acc 0.038462 test acc 0.038495\n",
            "Epoch 1: train loss 3.634982 test loss 3.764729\n",
            "Epoch 1: train acc 0.038462 test acc 0.051290\n",
            "Epoch 1: train loss 3.789360 test loss 3.910582\n",
            "Epoch 1: train acc 0.038462 test acc 0.038495\n",
            "Epoch 1: train loss 3.749356 test loss 3.929856\n",
            "Epoch 1: train acc 0.000000 test acc 0.038710\n",
            "Epoch 1: train loss 4.037750 test loss 3.761207\n",
            "Epoch 1: train acc 0.038462 test acc 0.031720\n",
            "Epoch 1: train loss 3.338594 test loss 3.764866\n",
            "Epoch 1: train acc 0.076923 test acc 0.032688\n",
            "Epoch 1: train loss 3.735177 test loss 3.888096\n",
            "Epoch 1: train acc 0.076923 test acc 0.030538\n",
            "Epoch 1: train loss 4.301796 test loss 3.819506\n",
            "Epoch 1: train acc 0.000000 test acc 0.033548\n",
            "Epoch 1: train loss 4.068668 test loss 3.673106\n",
            "Epoch 1: train acc 0.000000 test acc 0.067742\n",
            "Epoch 1: train loss 3.542366 test loss 3.715062\n",
            "Epoch 1: train acc 0.115385 test acc 0.052366\n",
            "Epoch 1: train loss 3.591200 test loss 3.844539\n",
            "Epoch 1: train acc 0.076923 test acc 0.057097\n",
            "Epoch 1: train loss 3.721198 test loss 3.900712\n",
            "Epoch 1: train acc 0.076923 test acc 0.042473\n",
            "Epoch 1: train loss 3.922601 test loss 3.722151\n",
            "Epoch 1: train acc 0.000000 test acc 0.046667\n",
            "Epoch 1: train loss 4.022103 test loss 3.557156\n",
            "Epoch 1: train acc 0.038462 test acc 0.053871\n",
            "Epoch 1: train loss 3.650905 test loss 3.670924\n",
            "Epoch 1: train acc 0.038462 test acc 0.037634\n",
            "Epoch 1: train loss 3.691396 test loss 3.819829\n",
            "Epoch 1: train acc 0.076923 test acc 0.028925\n",
            "Epoch 1: train loss 3.737624 test loss 3.850909\n",
            "Epoch 1: train acc 0.000000 test acc 0.033118\n",
            "Epoch 1: train loss 3.088418 test loss 4.041770\n",
            "Epoch 1: train acc 0.153846 test acc 0.033118\n",
            "Epoch 1: train loss 4.205188 test loss 3.994378\n",
            "Epoch 1: train acc 0.038462 test acc 0.034194\n",
            "Epoch 1: train loss 3.746345 test loss 3.962634\n",
            "Epoch 1: train acc 0.153846 test acc 0.033441\n",
            "Epoch 1: train loss 3.985615 test loss 3.878085\n",
            "Epoch 1: train acc 0.038462 test acc 0.046774\n",
            "Epoch 1: train loss 3.789615 test loss 3.838681\n",
            "Epoch 1: train acc 0.000000 test acc 0.039677\n",
            "Epoch 1: train loss 4.144465 test loss 4.044834\n",
            "Epoch 1: train acc 0.000000 test acc 0.033871\n",
            "Epoch 1: train loss 4.187899 test loss 4.039127\n",
            "Epoch 1: train acc 0.076923 test acc 0.037204\n",
            "Epoch 1: train loss 4.143266 test loss 3.856556\n",
            "Epoch 1: train acc 0.000000 test acc 0.059140\n",
            "Epoch 1: train loss 4.084255 test loss 3.999431\n",
            "Epoch 1: train acc 0.038462 test acc 0.029892\n",
            "Epoch 1: train loss 3.881564 test loss 4.065354\n",
            "Epoch 1: train acc 0.038462 test acc 0.029032\n",
            "Epoch 1: train loss 4.047277 test loss 3.871881\n",
            "Epoch 1: train acc 0.038462 test acc 0.040968\n",
            "Epoch 1: train loss 3.836243 test loss 3.648561\n",
            "Epoch 1: train acc 0.038462 test acc 0.041398\n",
            "Epoch 1: train loss 3.604259 test loss 3.725424\n",
            "Epoch 1: train acc 0.038462 test acc 0.058602\n",
            "Epoch 1: train loss 3.802915 test loss 3.640967\n",
            "Epoch 1: train acc 0.000000 test acc 0.088710\n",
            "Epoch 1: train loss 3.674448 test loss 3.639653\n",
            "Epoch 1: train acc 0.038462 test acc 0.059462\n",
            "Epoch 1: train loss 3.786172 test loss 3.725840\n",
            "Epoch 1: train acc 0.115385 test acc 0.054946\n",
            "Epoch 1: train loss 3.236084 test loss 3.898613\n",
            "Epoch 1: train acc 0.153846 test acc 0.050323\n",
            "Epoch 1: train loss 3.623019 test loss 4.105523\n",
            "Epoch 1: train acc 0.115385 test acc 0.043871\n",
            "Epoch 1: train loss 3.996366 test loss 3.910957\n",
            "Epoch 1: train acc 0.000000 test acc 0.040108\n",
            "Epoch 1: train loss 3.998468 test loss 3.780393\n",
            "Epoch 1: train acc 0.038462 test acc 0.044194\n",
            "Epoch 1: train loss 3.806925 test loss 3.722494\n",
            "Epoch 1: train acc 0.000000 test acc 0.042581\n",
            "Epoch 1: train loss 3.570210 test loss 3.976592\n",
            "Epoch 1: train acc 0.000000 test acc 0.058172\n",
            "Epoch 1: train loss 3.903190 test loss 4.259637\n",
            "Epoch 1: train acc 0.153846 test acc 0.055699\n",
            "Epoch 1: train loss 4.108687 test loss 4.207946\n",
            "Epoch 1: train acc 0.076923 test acc 0.050860\n",
            "Epoch 1: train loss 4.828629 test loss 3.877986\n",
            "Epoch 1: train acc 0.000000 test acc 0.047204\n",
            "Epoch 1: train loss 4.162718 test loss 3.873357\n",
            "Epoch 1: train acc 0.000000 test acc 0.039785\n",
            "Epoch 1: train loss 3.726178 test loss 4.181281\n",
            "Epoch 1: train acc 0.000000 test acc 0.030430\n",
            "Epoch 1: train loss 4.204510 test loss 4.122795\n",
            "Epoch 1: train acc 0.000000 test acc 0.030000\n",
            "Epoch 1: train loss 4.392098 test loss 3.828684\n",
            "Epoch 1: train acc 0.000000 test acc 0.033978\n",
            "Epoch 1: train loss 3.908630 test loss 3.858387\n",
            "Epoch 1: train acc 0.000000 test acc 0.036882\n",
            "Epoch 1: train loss 3.855589 test loss 4.058750\n",
            "Epoch 1: train acc 0.038462 test acc 0.034086\n",
            "Epoch 1: train loss 4.214514 test loss 4.032362\n",
            "Epoch 1: train acc 0.000000 test acc 0.057849\n",
            "Epoch 1: train loss 4.287618 test loss 3.890980\n",
            "Epoch 1: train acc 0.000000 test acc 0.060000\n",
            "Epoch 1: train loss 4.379713 test loss 3.886039\n",
            "Epoch 1: train acc 0.038462 test acc 0.050860\n",
            "Epoch 1: train loss 3.857628 test loss 3.876697\n",
            "Epoch 1: train acc 0.076923 test acc 0.035806\n",
            "Epoch 1: train loss 3.599586 test loss 3.810905\n",
            "Epoch 1: train acc 0.038462 test acc 0.035161\n",
            "Epoch 1: train loss 3.816744 test loss 3.915842\n",
            "Epoch 1: train acc 0.000000 test acc 0.030323\n",
            "Epoch 1: train loss 3.629901 test loss 4.124716\n",
            "Epoch 1: train acc 0.038462 test acc 0.033118\n",
            "Epoch 1: train loss 3.878854 test loss 3.994341\n",
            "Epoch 1: train acc 0.000000 test acc 0.034301\n",
            "Epoch 1: train loss 4.174449 test loss 3.952645\n",
            "Epoch 1: train acc 0.000000 test acc 0.046667\n",
            "Epoch 1: train loss 4.054765 test loss 4.060750\n",
            "Epoch 1: train acc 0.000000 test acc 0.050000\n",
            "Epoch 1: train loss 4.116670 test loss 4.092974\n",
            "Epoch 1: train acc 0.076923 test acc 0.076559\n",
            "Epoch 1: train loss 3.523352 test loss 4.015861\n",
            "Epoch 1: train acc 0.115385 test acc 0.078172\n",
            "Epoch 1: train loss 3.955692 test loss 3.892225\n",
            "Epoch 1: train acc 0.076923 test acc 0.060968\n",
            "Epoch 1: train loss 3.693976 test loss 3.858640\n",
            "Epoch 1: train acc 0.153846 test acc 0.050323\n",
            "Epoch 1: train loss 4.365169 test loss 3.825844\n",
            "Epoch 1: train acc 0.000000 test acc 0.060753\n",
            "Epoch 1: train loss 4.532001 test loss 3.887142\n",
            "Epoch 1: train acc 0.038462 test acc 0.059677\n",
            "Epoch 1: train loss 3.755013 test loss 3.948173\n",
            "Epoch 1: train acc 0.076923 test acc 0.032366\n",
            "Epoch 1: train loss 3.976825 test loss 3.991482\n",
            "Epoch 1: train acc 0.000000 test acc 0.049355\n",
            "Epoch 1: train loss 3.904195 test loss 4.059563\n",
            "Epoch 1: train acc 0.038462 test acc 0.058817\n",
            "Epoch 1: train loss 4.350002 test loss 4.068462\n",
            "Epoch 1: train acc 0.038462 test acc 0.070968\n",
            "Epoch 1: train loss 3.719513 test loss 4.097520\n",
            "Epoch 1: train acc 0.115385 test acc 0.055269\n",
            "Epoch 1: train loss 4.173288 test loss 3.926862\n",
            "Epoch 1: train acc 0.115385 test acc 0.068065\n",
            "Epoch 1: train loss 4.447672 test loss 3.854680\n",
            "Epoch 1: train acc 0.000000 test acc 0.054731\n",
            "Epoch 1: train loss 3.630276 test loss 3.984132\n",
            "Epoch 1: train acc 0.076923 test acc 0.032903\n",
            "Epoch 1: train loss 3.791931 test loss 3.808906\n",
            "Epoch 1: train acc 0.076923 test acc 0.040000\n",
            "Epoch 1: train loss 3.791212 test loss 3.625496\n",
            "Epoch 1: train acc 0.038462 test acc 0.056344\n",
            "Epoch 1: train loss 3.301306 test loss 3.647476\n",
            "Epoch 1: train acc 0.038462 test acc 0.077957\n",
            "Epoch 1: train loss 3.849039 test loss 3.718992\n",
            "Epoch 1: train acc 0.115385 test acc 0.065376\n",
            "Epoch 1: train loss 3.437023 test loss 3.853640\n",
            "Epoch 1: train acc 0.153846 test acc 0.063871\n",
            "Epoch 1: train loss 4.250907 test loss 3.906657\n",
            "Epoch 1: train acc 0.038462 test acc 0.062688\n",
            "Epoch 1: train loss 4.184397 test loss 3.921308\n",
            "Epoch 1: train acc 0.038462 test acc 0.052258\n",
            "Epoch 1: train loss 3.689924 test loss 3.857278\n",
            "Epoch 1: train acc 0.076923 test acc 0.056559\n",
            "Epoch 1: train loss 3.725312 test loss 3.879045\n",
            "Epoch 1: train acc 0.076923 test acc 0.063118\n",
            "Epoch 1: train loss 3.703190 test loss 3.888748\n",
            "Epoch 1: train acc 0.000000 test acc 0.049032\n",
            "Epoch 1: train loss 3.888162 test loss 3.798513\n",
            "Epoch 1: train acc 0.038462 test acc 0.034301\n",
            "Epoch 1: train loss 3.744983 test loss 3.723622\n",
            "Epoch 1: train acc 0.000000 test acc 0.069570\n",
            "Epoch 1: train loss 3.425850 test loss 3.842106\n",
            "Epoch 1: train acc 0.153846 test acc 0.042151\n",
            "Epoch 1: train loss 4.106728 test loss 3.897374\n",
            "Epoch 1: train acc 0.000000 test acc 0.033548\n",
            "Epoch 1: train loss 3.907500 test loss 3.793368\n",
            "Epoch 1: train acc 0.076923 test acc 0.034301\n",
            "Epoch 1: train loss 3.572093 test loss 3.758646\n",
            "Epoch 1: train acc 0.115385 test acc 0.052688\n",
            "Epoch 1: train loss 3.830127 test loss 3.722839\n",
            "Epoch 1: train acc 0.000000 test acc 0.034516\n",
            "Epoch 1: train loss 3.954733 test loss 3.784379\n",
            "Epoch 1: train acc 0.000000 test acc 0.040430\n",
            "Epoch 1: train loss 3.967757 test loss 3.850105\n",
            "Epoch 1: train acc 0.000000 test acc 0.037312\n",
            "Epoch 1: train loss 4.145118 test loss 3.726483\n",
            "Epoch 1: train acc 0.000000 test acc 0.053656\n",
            "Epoch 1: train loss 3.282349 test loss 3.729065\n",
            "Epoch 1: train acc 0.000000 test acc 0.035376\n",
            "Epoch 1: train loss 3.651299 test loss 3.772871\n",
            "Epoch 1: train acc 0.076923 test acc 0.037957\n",
            "Epoch 1: train loss 3.990208 test loss 3.776364\n",
            "Epoch 1: train acc 0.000000 test acc 0.042258\n",
            "Epoch 1: train loss 3.578701 test loss 3.735166\n",
            "Epoch 1: train acc 0.000000 test acc 0.048602\n",
            "Epoch 1: train loss 3.897890 test loss 3.704685\n",
            "Epoch 1: train acc 0.000000 test acc 0.044194\n",
            "Epoch 1: train loss 3.753814 test loss 3.697947\n",
            "Epoch 1: train acc 0.000000 test acc 0.065699\n",
            "Epoch 1: train loss 3.442976 test loss 3.684393\n",
            "Epoch 1: train acc 0.076923 test acc 0.063548\n",
            "Epoch 1: train loss 3.960417 test loss 3.673822\n",
            "Epoch 1: train acc 0.038462 test acc 0.059570\n",
            "Epoch 1: train loss 3.569664 test loss 3.764671\n",
            "Epoch 1: train acc 0.038462 test acc 0.041828\n",
            "Epoch 1: train loss 3.825508 test loss 3.736981\n",
            "Epoch 1: train acc 0.038462 test acc 0.062473\n",
            "Epoch 1: train loss 3.559082 test loss 3.697931\n",
            "Epoch 1: train acc 0.038462 test acc 0.060430\n",
            "Epoch 1: train loss 3.758306 test loss 3.754403\n",
            "Epoch 1: train acc 0.000000 test acc 0.046667\n",
            "Epoch 1: train loss 3.928058 test loss 3.676954\n",
            "Epoch 1: train acc 0.000000 test acc 0.049570\n",
            "Epoch 1: train loss 3.751954 test loss 3.662650\n",
            "Epoch 1: train acc 0.076923 test acc 0.070000\n",
            "Epoch 1: train loss 3.594232 test loss 3.786616\n",
            "Epoch 1: train acc 0.000000 test acc 0.033656\n",
            "Epoch 1: train loss 3.753306 test loss 3.874151\n",
            "Epoch 1: train acc 0.000000 test acc 0.033871\n",
            "Epoch 1: train loss 4.075549 test loss 3.792648\n",
            "Epoch 1: train acc 0.076923 test acc 0.048602\n",
            "Epoch 1: train loss 3.765921 test loss 3.734505\n",
            "Epoch 1: train acc 0.038462 test acc 0.033333\n",
            "Epoch 1: train loss 3.438462 test loss 3.708079\n",
            "Epoch 1: train acc 0.038462 test acc 0.033118\n",
            "Epoch 1: train loss 3.799264 test loss 3.701419\n",
            "Epoch 1: train acc 0.000000 test acc 0.046237\n",
            "Epoch 1: train loss 3.824896 test loss 3.755863\n",
            "Epoch 1: train acc 0.038462 test acc 0.042581\n",
            "Epoch 1: train loss 3.655772 test loss 3.823147\n",
            "Epoch 1: train acc 0.115385 test acc 0.039570\n",
            "Epoch 1: train loss 3.848400 test loss 3.751089\n",
            "Epoch 1: train acc 0.076923 test acc 0.039462\n",
            "Epoch 1: train loss 3.540900 test loss 3.680702\n",
            "Epoch 1: train acc 0.076923 test acc 0.065054\n",
            "Epoch 1: train loss 3.668780 test loss 3.679465\n",
            "Epoch 1: train acc 0.076923 test acc 0.056129\n",
            "Epoch 1: train loss 3.741176 test loss 3.671203\n",
            "Epoch 1: train acc 0.115385 test acc 0.054516\n",
            "Epoch 1: train loss 3.493446 test loss 3.667263\n",
            "Epoch 1: train acc 0.153846 test acc 0.050645\n",
            "Epoch 1: train loss 3.921230 test loss 3.614506\n",
            "Epoch 1: train acc 0.076923 test acc 0.053656\n",
            "Epoch 1: train loss 3.769160 test loss 3.577156\n",
            "Epoch 1: train acc 0.038462 test acc 0.074301\n",
            "Epoch 1: train loss 3.482785 test loss 3.584643\n",
            "Epoch 1: train acc 0.076923 test acc 0.071183\n",
            "Epoch 1: train loss 3.525679 test loss 3.634106\n",
            "Epoch 1: train acc 0.076923 test acc 0.071505\n",
            "Epoch 1: train loss 3.637755 test loss 3.697753\n",
            "Epoch 1: train acc 0.000000 test acc 0.053441\n",
            "Epoch 1: train loss 3.570284 test loss 3.724612\n",
            "Epoch 1: train acc 0.076923 test acc 0.055699\n",
            "Epoch 1: train loss 3.758927 test loss 3.737003\n",
            "Epoch 1: train acc 0.115385 test acc 0.060538\n",
            "Epoch 1: train loss 3.529699 test loss 3.766376\n",
            "Epoch 1: train acc 0.076923 test acc 0.058387\n",
            "Epoch 1: train loss 3.984189 test loss 3.711148\n",
            "Epoch 1: train acc 0.038462 test acc 0.052688\n",
            "Epoch 1: train loss 3.870522 test loss 3.635730\n",
            "Epoch 1: train acc 0.000000 test acc 0.069570\n",
            "Epoch 1: train loss 3.689951 test loss 3.610148\n",
            "Epoch 1: train acc 0.076923 test acc 0.080215\n",
            "Epoch 1: train loss 4.075068 test loss 3.605276\n",
            "Epoch 1: train acc 0.000000 test acc 0.036989\n",
            "Epoch 1: train loss 3.986646 test loss 3.597376\n",
            "Epoch 1: train acc 0.038462 test acc 0.034301\n",
            "Epoch 1: train loss 3.600337 test loss 3.608316\n",
            "Epoch 1: train acc 0.000000 test acc 0.039355\n",
            "Epoch 1: train loss 3.671010 test loss 3.634327\n",
            "Epoch 1: train acc 0.000000 test acc 0.036129\n",
            "Epoch 1: train loss 3.472494 test loss 3.686126\n",
            "Epoch 1: train acc 0.038462 test acc 0.037204\n",
            "Epoch 1: train loss 3.702637 test loss 3.735458\n",
            "Epoch 1: train acc 0.038462 test acc 0.037742\n",
            "Epoch 1: train loss 3.983043 test loss 3.704333\n",
            "Epoch 1: train acc 0.115385 test acc 0.049140\n",
            "Epoch 1: train loss 3.454265 test loss 3.677995\n",
            "Epoch 1: train acc 0.000000 test acc 0.036559\n",
            "Epoch 1: train loss 3.482974 test loss 3.697569\n",
            "Epoch 1: train acc 0.038462 test acc 0.061613\n",
            "Epoch 1: train loss 4.006998 test loss 3.667601\n",
            "Epoch 1: train acc 0.115385 test acc 0.070323\n",
            "Epoch 1: train loss 3.110714 test loss 3.749569\n",
            "Epoch 1: train acc 0.038462 test acc 0.065591\n",
            "Epoch 1: train loss 3.550571 test loss 3.811320\n",
            "Epoch 1: train acc 0.076923 test acc 0.065269\n",
            "Epoch 1: train loss 3.316602 test loss 3.842316\n",
            "Epoch 1: train acc 0.076923 test acc 0.073656\n",
            "Epoch 1: train loss 4.411567 test loss 3.844002\n",
            "Epoch 1: train acc 0.000000 test acc 0.063871\n",
            "Epoch 1: train loss 3.860739 test loss 3.820187\n",
            "Epoch 1: train acc 0.000000 test acc 0.041828\n",
            "Epoch 1: train loss 3.535986 test loss 3.719143\n",
            "Epoch 1: train acc 0.076923 test acc 0.052688\n",
            "Epoch 1: train loss 3.614837 test loss 3.636860\n",
            "Epoch 1: train acc 0.038462 test acc 0.042796\n",
            "Epoch 1: train loss 3.590806 test loss 3.644644\n",
            "Epoch 1: train acc 0.076923 test acc 0.046774\n",
            "Epoch 1: train loss 3.643048 test loss 3.731964\n",
            "Epoch 1: train acc 0.000000 test acc 0.035269\n",
            "Epoch 1: train loss 3.833558 test loss 3.776170\n",
            "Epoch 1: train acc 0.115385 test acc 0.038710\n",
            "Epoch 1: train loss 3.782443 test loss 3.672535\n",
            "Epoch 1: train acc 0.000000 test acc 0.068817\n",
            "Epoch 1: train loss 3.767311 test loss 3.822721\n",
            "Epoch 1: train acc 0.038462 test acc 0.036344\n",
            "Epoch 1: train loss 3.479881 test loss 4.042181\n",
            "Epoch 1: train acc 0.076923 test acc 0.034086\n",
            "Epoch 1: train loss 4.620321 test loss 3.770380\n",
            "Epoch 1: train acc 0.000000 test acc 0.038172\n",
            "Epoch 1: train loss 3.798350 test loss 3.558799\n",
            "Epoch 1: train acc 0.038462 test acc 0.051828\n",
            "Epoch 1: train loss 3.444165 test loss 3.675961\n",
            "Epoch 1: train acc 0.115385 test acc 0.056774\n",
            "Epoch 1: train loss 3.522529 test loss 3.848584\n",
            "Epoch 1: train acc 0.038462 test acc 0.043226\n",
            "Epoch 1: train loss 3.610835 test loss 3.953852\n",
            "Epoch 1: train acc 0.076923 test acc 0.036344\n",
            "Epoch 1: train loss 3.652912 test loss 3.862106\n",
            "Epoch 1: train acc 0.076923 test acc 0.037634\n",
            "Epoch 1: train loss 3.788284 test loss 3.608377\n",
            "Epoch 1: train acc 0.038462 test acc 0.050430\n",
            "Epoch 1: train loss 3.307530 test loss 3.638393\n",
            "Epoch 1: train acc 0.038462 test acc 0.066989\n",
            "Epoch 1: train loss 3.791445 test loss 3.716814\n",
            "Epoch 1: train acc 0.076923 test acc 0.066559\n",
            "Epoch 1: train loss 3.539638 test loss 3.812624\n",
            "Epoch 1: train acc 0.115385 test acc 0.049570\n",
            "Epoch 1: train loss 3.133694 test loss 3.983806\n",
            "Epoch 1: train acc 0.076923 test acc 0.037849\n",
            "Epoch 1: train loss 3.783935 test loss 4.064990\n",
            "Epoch 1: train acc 0.038462 test acc 0.037634\n",
            "Epoch 1: train loss 4.361442 test loss 4.047524\n",
            "Epoch 1: train acc 0.000000 test acc 0.051183\n",
            "Epoch 1: train loss 3.713767 test loss 4.027273\n",
            "Epoch 1: train acc 0.000000 test acc 0.064731\n",
            "Epoch 1: train loss 3.959188 test loss 3.976286\n",
            "Epoch 1: train acc 0.076923 test acc 0.077957\n",
            "Epoch 1: train loss 3.576682 test loss 3.949082\n",
            "Epoch 1: train acc 0.076923 test acc 0.065484\n",
            "Epoch 1: train loss 3.817571 test loss 3.934765\n",
            "Epoch 1: train acc 0.115385 test acc 0.071613\n",
            "Epoch 1: train loss 4.288515 test loss 3.849401\n",
            "Epoch 1: train acc 0.000000 test acc 0.071935\n",
            "Epoch 1: train loss 4.090487 test loss 3.801244\n",
            "Epoch 1: train acc 0.000000 test acc 0.060645\n",
            "Epoch 1: train loss 4.393872 test loss 3.844980\n",
            "Epoch 1: train acc 0.076923 test acc 0.059140\n",
            "Epoch 1: train loss 4.273063 test loss 3.882865\n",
            "Epoch 1: train acc 0.038462 test acc 0.062258\n",
            "Epoch 1: train loss 4.461439 test loss 3.845536\n",
            "Epoch 1: train acc 0.076923 test acc 0.054516\n",
            "Epoch 1: train loss 4.650971 test loss 3.662488\n",
            "Epoch 1: train acc 0.000000 test acc 0.035484\n",
            "Epoch 1: train loss 3.787352 test loss 3.548046\n",
            "Epoch 1: train acc 0.038462 test acc 0.045699\n",
            "Epoch 1: train loss 3.371109 test loss 3.551447\n",
            "Epoch 1: train acc 0.038462 test acc 0.044086\n",
            "Epoch 1: train loss 3.557042 test loss 3.632521\n",
            "Epoch 1: train acc 0.076923 test acc 0.064839\n",
            "Epoch 1: train loss 3.781864 test loss 3.656806\n",
            "Epoch 1: train acc 0.038462 test acc 0.047957\n",
            "Epoch 1: train loss 3.628084 test loss 3.694088\n",
            "Epoch 1: train acc 0.038462 test acc 0.033333\n",
            "Epoch 1: train loss 3.454425 test loss 3.667337\n",
            "Epoch 1: train acc 0.038462 test acc 0.035591\n",
            "Epoch 1: train loss 4.150256 test loss 3.609722\n",
            "Epoch 1: train acc 0.038462 test acc 0.057849\n",
            "Epoch 1: train loss 3.511720 test loss 3.632712\n",
            "Epoch 1: train acc 0.115385 test acc 0.063871\n",
            "Epoch 1: train loss 3.610929 test loss 3.648241\n",
            "Epoch 1: train acc 0.038462 test acc 0.061398\n",
            "Epoch 1: train loss 3.326146 test loss 3.699646\n",
            "Epoch 1: train acc 0.076923 test acc 0.072796\n",
            "Epoch 1: train loss 3.454236 test loss 3.809635\n",
            "Epoch 1: train acc 0.038462 test acc 0.050215\n",
            "Epoch 1: train loss 3.638959 test loss 3.916733\n",
            "Epoch 1: train acc 0.076923 test acc 0.036882\n",
            "Epoch 1: train loss 3.791925 test loss 3.789421\n",
            "Epoch 1: train acc 0.000000 test acc 0.049570\n",
            "Epoch 1: train loss 3.618311 test loss 3.736490\n",
            "Epoch 1: train acc 0.000000 test acc 0.034086\n",
            "Epoch 1: train loss 3.773548 test loss 3.694884\n",
            "Epoch 1: train acc 0.076923 test acc 0.045806\n",
            "Epoch 1: train loss 3.522232 test loss 3.677650\n",
            "Epoch 1: train acc 0.076923 test acc 0.039570\n",
            "Epoch 1: train loss 3.452454 test loss 3.670474\n",
            "Epoch 1: train acc 0.000000 test acc 0.045376\n",
            "Epoch 1: train loss 3.744209 test loss 3.632340\n",
            "Epoch 1: train acc 0.076923 test acc 0.053978\n",
            "Epoch 1: train loss 3.625290 test loss 3.612085\n",
            "Epoch 1: train acc 0.115385 test acc 0.058495\n",
            "Epoch 1: train loss 3.399531 test loss 3.748639\n",
            "Epoch 1: train acc 0.115385 test acc 0.035269\n",
            "Epoch 1: train loss 3.666070 test loss 3.834185\n",
            "Epoch 1: train acc 0.000000 test acc 0.034946\n",
            "Epoch 1: train loss 3.775363 test loss 3.836620\n",
            "Epoch 1: train acc 0.038462 test acc 0.059032\n",
            "Epoch 1: train loss 3.650036 test loss 3.748072\n",
            "Epoch 1: train acc 0.076923 test acc 0.078387\n",
            "Epoch 1: train loss 3.347128 test loss 3.677476\n",
            "Epoch 1: train acc 0.115385 test acc 0.075699\n",
            "Epoch 1: train loss 3.897645 test loss 3.596937\n",
            "Epoch 1: train acc 0.076923 test acc 0.062581\n",
            "Epoch 1: train loss 3.651066 test loss 3.536614\n",
            "Epoch 1: train acc 0.038462 test acc 0.056344\n",
            "Epoch 1: train loss 3.975598 test loss 3.510729\n",
            "Epoch 1: train acc 0.000000 test acc 0.056129\n",
            "Epoch 1: train loss 3.320279 test loss 3.552607\n",
            "Epoch 1: train acc 0.076923 test acc 0.033118\n",
            "Epoch 1: train loss 3.335330 test loss 3.596739\n",
            "Epoch 1: train acc 0.000000 test acc 0.040968\n",
            "Epoch 1: train loss 3.825613 test loss 3.586908\n",
            "Epoch 1: train acc 0.038462 test acc 0.054731\n",
            "Epoch 1: train loss 3.617008 test loss 3.569550\n",
            "Epoch 1: train acc 0.038462 test acc 0.062043\n",
            "Epoch 1: train loss 3.498212 test loss 3.578830\n",
            "Epoch 1: train acc 0.076923 test acc 0.069462\n",
            "Epoch 1: train loss 3.615486 test loss 3.605436\n",
            "Epoch 1: train acc 0.115385 test acc 0.067204\n",
            "Epoch 1: train loss 3.635481 test loss 3.562207\n",
            "Epoch 1: train acc 0.038462 test acc 0.081720\n",
            "Epoch 1: train loss 3.737649 test loss 3.541905\n",
            "Epoch 1: train acc 0.115385 test acc 0.079355\n",
            "Epoch 1: train loss 3.453994 test loss 3.553962\n",
            "Epoch 1: train acc 0.038462 test acc 0.050645\n",
            "Epoch 1: train loss 3.355731 test loss 3.599037\n",
            "Epoch 1: train acc 0.038462 test acc 0.036344\n",
            "Epoch 1: train loss 3.549212 test loss 3.668422\n",
            "Epoch 1: train acc 0.115385 test acc 0.037204\n",
            "Epoch 1: train loss 3.763377 test loss 3.708613\n",
            "Epoch 1: train acc 0.000000 test acc 0.035269\n",
            "Epoch 1: train loss 3.704858 test loss 3.684903\n",
            "Epoch 1: train acc 0.000000 test acc 0.036882\n",
            "Epoch 1: train loss 3.920641 test loss 3.699356\n",
            "Epoch 1: train acc 0.000000 test acc 0.035161\n",
            "Epoch 1: train loss 3.810081 test loss 3.686662\n",
            "Epoch 1: train acc 0.000000 test acc 0.038602\n",
            "Epoch 1: train loss 3.420391 test loss 3.635592\n",
            "Epoch 1: train acc 0.000000 test acc 0.038172\n",
            "Epoch 1: train loss 3.443783 test loss 3.593940\n",
            "Epoch 1: train acc 0.000000 test acc 0.034839\n",
            "Epoch 1: train loss 3.609004 test loss 3.586117\n",
            "Epoch 1: train acc 0.038462 test acc 0.041183\n",
            "Epoch 1: train loss 3.657840 test loss 3.579850\n",
            "Epoch 1: train acc 0.000000 test acc 0.052366\n",
            "Epoch 1: train loss 3.305664 test loss 3.638766\n",
            "Epoch 1: train acc 0.115385 test acc 0.052258\n",
            "Epoch 1: train loss 3.979664 test loss 3.682746\n",
            "Epoch 1: train acc 0.000000 test acc 0.069570\n",
            "Epoch 1: train loss 3.852623 test loss 3.690196\n",
            "Epoch 1: train acc 0.000000 test acc 0.061613\n",
            "Epoch 1: train loss 3.716239 test loss 3.641644\n",
            "Epoch 1: train acc 0.153846 test acc 0.059785\n",
            "Epoch 1: train loss 3.588610 test loss 3.593970\n",
            "Epoch 1: train acc 0.115385 test acc 0.055591\n",
            "Epoch 1: train loss 3.582432 test loss 3.570643\n",
            "Epoch 1: train acc 0.038462 test acc 0.047957\n",
            "Epoch 1: train loss 3.435014 test loss 3.638452\n",
            "Epoch 1: train acc 0.076923 test acc 0.032688\n",
            "Epoch 1: train loss 3.484643 test loss 3.657732\n",
            "Epoch 1: train acc 0.000000 test acc 0.033333\n",
            "Epoch 1: train loss 3.966107 test loss 3.600722\n",
            "Epoch 1: train acc 0.038462 test acc 0.030860\n",
            "Epoch 1: train loss 3.524131 test loss 3.590773\n",
            "Epoch 1: train acc 0.000000 test acc 0.030108\n",
            "Epoch 1: train loss 3.680697 test loss 3.549163\n",
            "Epoch 1: train acc 0.000000 test acc 0.056022\n",
            "Epoch 1: train loss 3.585817 test loss 3.561880\n",
            "Epoch 1: train acc 0.038462 test acc 0.055806\n",
            "Epoch 1: train loss 3.715758 test loss 3.580031\n",
            "Epoch 1: train acc 0.000000 test acc 0.071505\n",
            "Epoch 1: train loss 3.464035 test loss 3.635307\n",
            "Epoch 1: train acc 0.038462 test acc 0.097419\n",
            "Epoch 1: train loss 3.570536 test loss 3.735372\n",
            "Epoch 1: train acc 0.076923 test acc 0.049355\n",
            "Epoch 1: train loss 3.752043 test loss 3.844905\n",
            "Epoch 1: train acc 0.038462 test acc 0.038172\n",
            "Epoch 1: train loss 3.980976 test loss 3.917776\n",
            "Epoch 1: train acc 0.038462 test acc 0.037957\n",
            "Epoch 1: train loss 3.691758 test loss 3.953956\n",
            "Epoch 1: train acc 0.038462 test acc 0.039785\n",
            "Epoch 1: train loss 3.622283 test loss 3.985232\n",
            "Epoch 1: train acc 0.000000 test acc 0.036022\n",
            "Epoch 1: train loss 4.121521 test loss 3.852889\n",
            "Epoch 1: train acc 0.000000 test acc 0.039892\n",
            "Epoch 1: train loss 3.507578 test loss 3.798651\n",
            "Epoch 1: train acc 0.038462 test acc 0.056989\n",
            "Epoch 1: train loss 3.778428 test loss 3.735912\n",
            "Epoch 1: train acc 0.115385 test acc 0.068602\n",
            "Epoch 1: train loss 3.628239 test loss 3.649453\n",
            "Epoch 1: train acc 0.153846 test acc 0.057527\n",
            "Epoch 1: train loss 3.667750 test loss 3.648609\n",
            "Epoch 1: train acc 0.076923 test acc 0.066667\n",
            "Epoch 1: train loss 3.376844 test loss 3.754287\n",
            "Epoch 1: train acc 0.038462 test acc 0.038602\n",
            "Epoch 1: train loss 3.449102 test loss 3.916051\n",
            "Epoch 1: train acc 0.000000 test acc 0.057634\n",
            "Epoch 1: train loss 3.641816 test loss 4.062671\n",
            "Epoch 1: train acc 0.038462 test acc 0.030215\n",
            "Epoch 1: train loss 3.915868 test loss 3.962704\n",
            "Epoch 1: train acc 0.038462 test acc 0.040645\n",
            "Epoch 1: train loss 4.084538 test loss 3.801457\n",
            "Epoch 1: train acc 0.076923 test acc 0.053978\n",
            "Epoch 1: train loss 3.899822 test loss 3.846211\n",
            "Epoch 1: train acc 0.076923 test acc 0.034409\n",
            "Epoch 1: train loss 3.922312 test loss 3.945184\n",
            "Epoch 1: train acc 0.038462 test acc 0.032151\n",
            "Epoch 1: train loss 4.454934 test loss 3.815491\n",
            "Epoch 1: train acc 0.076923 test acc 0.033011\n",
            "Epoch 1: train loss 3.700223 test loss 3.699107\n",
            "Epoch 1: train acc 0.076923 test acc 0.062043\n",
            "Epoch 1: train loss 3.677730 test loss 3.791264\n",
            "Epoch 1: train acc 0.038462 test acc 0.036882\n",
            "Epoch 1: train loss 3.743940 test loss 3.866908\n",
            "Epoch 1: train acc 0.076923 test acc 0.031613\n",
            "Epoch 1: train loss 3.818991 test loss 3.729272\n",
            "Epoch 1: train acc 0.038462 test acc 0.041935\n",
            "Epoch 1: train loss 3.597647 test loss 3.805201\n",
            "Epoch 1: train acc 0.076923 test acc 0.043441\n",
            "Epoch 1: train loss 3.951628 test loss 3.937092\n",
            "Epoch 1: train acc 0.000000 test acc 0.035054\n",
            "Epoch 1: train loss 4.689427 test loss 3.884684\n",
            "Epoch 1: train acc 0.000000 test acc 0.031505\n",
            "Epoch 1: train loss 3.842195 test loss 3.762353\n",
            "Epoch 1: train acc 0.000000 test acc 0.034839\n",
            "Epoch 1: train loss 3.594255 test loss 3.655309\n",
            "Epoch 1: train acc 0.076923 test acc 0.049892\n",
            "Epoch 1: train loss 3.397913 test loss 3.701746\n",
            "Epoch 1: train acc 0.115385 test acc 0.064409\n",
            "Epoch 1: train loss 4.035927 test loss 3.783523\n",
            "Epoch 1: train acc 0.115385 test acc 0.052688\n",
            "Epoch 1: train loss 3.885378 test loss 3.702403\n",
            "Epoch 1: train acc 0.076923 test acc 0.049462\n",
            "Epoch 1: train loss 3.833905 test loss 3.595979\n",
            "Epoch 1: train acc 0.038462 test acc 0.073763\n",
            "Epoch 1: train loss 3.580559 test loss 3.628426\n",
            "Epoch 1: train acc 0.038462 test acc 0.041398\n",
            "Epoch 1: train loss 3.713206 test loss 3.703012\n",
            "Epoch 1: train acc 0.076923 test acc 0.046344\n",
            "Epoch 1: train loss 3.753424 test loss 3.825216\n",
            "Epoch 1: train acc 0.115385 test acc 0.034194\n",
            "Epoch 1: train loss 4.148376 test loss 3.792826\n",
            "Epoch 1: train acc 0.000000 test acc 0.031183\n",
            "Epoch 1: train loss 3.957695 test loss 3.727563\n",
            "Epoch 1: train acc 0.076923 test acc 0.028817\n",
            "Epoch 1: train loss 3.578693 test loss 3.666510\n",
            "Epoch 1: train acc 0.038462 test acc 0.037957\n",
            "Epoch 1: train loss 3.717643 test loss 3.615815\n",
            "Epoch 1: train acc 0.000000 test acc 0.040645\n",
            "Epoch 1: train loss 3.669269 test loss 3.622947\n",
            "Epoch 1: train acc 0.076923 test acc 0.053548\n",
            "Epoch 1: train loss 3.426529 test loss 3.682277\n",
            "Epoch 1: train acc 0.192308 test acc 0.065591\n",
            "Epoch 1: train loss 3.717568 test loss 3.707818\n",
            "Epoch 1: train acc 0.076923 test acc 0.061613\n",
            "Epoch 1: train loss 3.587499 test loss 3.703776\n",
            "Epoch 1: train acc 0.115385 test acc 0.084086\n",
            "Epoch 1: train loss 3.936454 test loss 3.651708\n",
            "Epoch 1: train acc 0.038462 test acc 0.056882\n",
            "Epoch 1: train loss 3.595546 test loss 3.629177\n",
            "Epoch 1: train acc 0.076923 test acc 0.062581\n",
            "Epoch 1: train loss 3.631516 test loss 3.660628\n",
            "Epoch 1: train acc 0.038462 test acc 0.087419\n",
            "Epoch 1: train loss 3.643340 test loss 3.749993\n",
            "Epoch 1: train acc 0.038462 test acc 0.042796\n",
            "Epoch 1: train loss 3.979112 test loss 3.750458\n",
            "Epoch 1: train acc 0.038462 test acc 0.036882\n",
            "Epoch 1: train loss 3.719489 test loss 3.694651\n",
            "Epoch 1: train acc 0.000000 test acc 0.047849\n",
            "Epoch 1: train loss 3.536423 test loss 3.694995\n",
            "Epoch 1: train acc 0.076923 test acc 0.042258\n",
            "Epoch 1: train loss 3.971547 test loss 3.588526\n",
            "Epoch 1: train acc 0.038462 test acc 0.045806\n",
            "Epoch 1: train loss 3.715307 test loss 3.546810\n",
            "Epoch 1: train acc 0.000000 test acc 0.049785\n",
            "Epoch 1: train loss 3.655164 test loss 3.533847\n",
            "Epoch 1: train acc 0.115385 test acc 0.039355\n",
            "Epoch 1: train loss 3.348976 test loss 3.587232\n",
            "Epoch 1: train acc 0.076923 test acc 0.056667\n",
            "Epoch 1: train loss 3.394624 test loss 3.641477\n",
            "Epoch 1: train acc 0.038462 test acc 0.039677\n",
            "Epoch 1: train loss 3.833128 test loss 3.624412\n",
            "Epoch 1: train acc 0.038462 test acc 0.057204\n",
            "Epoch 1: train loss 3.587702 test loss 3.598970\n",
            "Epoch 1: train acc 0.076923 test acc 0.106452\n",
            "Epoch 1: train loss 3.742186 test loss 3.551371\n",
            "Epoch 1: train acc 0.038462 test acc 0.089677\n",
            "Epoch 1: train loss 3.557517 test loss 3.518122\n",
            "Epoch 1: train acc 0.153846 test acc 0.073978\n",
            "Epoch 1: train loss 3.609134 test loss 3.554622\n",
            "Epoch 1: train acc 0.038462 test acc 0.063441\n",
            "Epoch 1: train loss 3.524829 test loss 3.623301\n",
            "Epoch 1: train acc 0.115385 test acc 0.041075\n",
            "Epoch 1: train loss 4.078935 test loss 3.544595\n",
            "Epoch 1: train acc 0.000000 test acc 0.060430\n",
            "Epoch 1: train loss 3.368463 test loss 3.515495\n",
            "Epoch 1: train acc 0.000000 test acc 0.061935\n",
            "Epoch 1: train loss 3.452541 test loss 3.519164\n",
            "Epoch 1: train acc 0.000000 test acc 0.057097\n",
            "Epoch 1: train loss 3.076445 test loss 3.617389\n",
            "Epoch 1: train acc 0.153846 test acc 0.057742\n",
            "Epoch 1: train loss 3.967322 test loss 3.614065\n",
            "Epoch 1: train acc 0.038462 test acc 0.061935\n",
            "Epoch 1: train loss 3.714767 test loss 3.536399\n",
            "Epoch 1: train acc 0.038462 test acc 0.086989\n",
            "Epoch 1: train loss 3.646467 test loss 3.473911\n",
            "Epoch 1: train acc 0.038462 test acc 0.064624\n",
            "Epoch 1: train loss 3.467016 test loss 3.483440\n",
            "Epoch 1: train acc 0.000000 test acc 0.059677\n",
            "Epoch 1: train loss 3.471264 test loss 3.549223\n",
            "Epoch 1: train acc 0.076923 test acc 0.058602\n",
            "Epoch 1: train loss 3.770704 test loss 3.569162\n",
            "Epoch 1: train acc 0.076923 test acc 0.032796\n",
            "Epoch 1: train loss 3.716648 test loss 3.521026\n",
            "Epoch 1: train acc 0.000000 test acc 0.032688\n",
            "Epoch 1: train loss 3.550013 test loss 3.435567\n",
            "Epoch 1: train acc 0.038462 test acc 0.067527\n",
            "Epoch 1: train loss 3.328755 test loss 3.466980\n",
            "Epoch 1: train acc 0.076923 test acc 0.045484\n",
            "Epoch 1: train loss 3.448928 test loss 3.517242\n",
            "Epoch 1: train acc 0.076923 test acc 0.053118\n",
            "Epoch 1: train loss 3.369560 test loss 3.576456\n",
            "Epoch 1: train acc 0.115385 test acc 0.036667\n",
            "Epoch 1: train loss 3.552576 test loss 3.576741\n",
            "Epoch 1: train acc 0.000000 test acc 0.064731\n",
            "Epoch 1: train loss 3.601392 test loss 3.534874\n",
            "Epoch 1: train acc 0.038462 test acc 0.062151\n",
            "Epoch 1: train loss 3.499190 test loss 3.492475\n",
            "Epoch 1: train acc 0.076923 test acc 0.063011\n",
            "Epoch 1: train loss 3.303381 test loss 3.495161\n",
            "Epoch 1: train acc 0.115385 test acc 0.061505\n",
            "Epoch 1: train loss 3.385043 test loss 3.514799\n",
            "Epoch 1: train acc 0.115385 test acc 0.057742\n",
            "Epoch 1: train loss 3.575144 test loss 3.508380\n",
            "Epoch 1: train acc 0.038462 test acc 0.065484\n",
            "Epoch 1: train loss 3.528403 test loss 3.513327\n",
            "Epoch 1: train acc 0.076923 test acc 0.057312\n",
            "Epoch 1: train loss 3.554587 test loss 3.567521\n",
            "Epoch 1: train acc 0.038462 test acc 0.041613\n",
            "Epoch 1: train loss 3.530016 test loss 3.612310\n",
            "Epoch 1: train acc 0.000000 test acc 0.042796\n",
            "Epoch 1: train loss 3.581561 test loss 3.597202\n",
            "Epoch 1: train acc 0.076923 test acc 0.066559\n",
            "Epoch 1: train loss 3.795943 test loss 3.541662\n",
            "Epoch 1: train acc 0.038462 test acc 0.069032\n",
            "Epoch 1: train loss 3.368763 test loss 3.496989\n",
            "Epoch 1: train acc 0.115385 test acc 0.066559\n",
            "Epoch 1: train loss 3.186152 test loss 3.476186\n",
            "Epoch 1: train acc 0.153846 test acc 0.067204\n",
            "Epoch 1: train loss 3.464189 test loss 3.477690\n",
            "Epoch 1: train acc 0.038462 test acc 0.089247\n",
            "Epoch 1: train loss 3.258312 test loss 3.519641\n",
            "Epoch 1: train acc 0.192308 test acc 0.061935\n",
            "Epoch 1: train loss 3.590695 test loss 3.567327\n",
            "Epoch 1: train acc 0.076923 test acc 0.063441\n",
            "Epoch 1: train loss 3.918003 test loss 3.550091\n",
            "Epoch 1: train acc 0.000000 test acc 0.052581\n",
            "Epoch 1: train loss 3.716416 test loss 3.507337\n",
            "Epoch 1: train acc 0.038462 test acc 0.054516\n",
            "Epoch 1: train loss 3.616470 test loss 3.468071\n",
            "Epoch 1: train acc 0.038462 test acc 0.046452\n",
            "Epoch 1: train loss 3.449914 test loss 3.505619\n",
            "Epoch 1: train acc 0.038462 test acc 0.033226\n",
            "Epoch 1: train loss 3.557660 test loss 3.562790\n",
            "Epoch 1: train acc 0.000000 test acc 0.036022\n",
            "Epoch 1: train loss 3.217727 test loss 3.612447\n",
            "Epoch 1: train acc 0.038462 test acc 0.042688\n",
            "Epoch 1: train loss 3.312994 test loss 3.685253\n",
            "Epoch 1: train acc 0.076923 test acc 0.034516\n",
            "Epoch 1: train loss 3.633219 test loss 3.713061\n",
            "Epoch 1: train acc 0.038462 test acc 0.031720\n",
            "Epoch 1: train loss 3.450681 test loss 3.753306\n",
            "Epoch 1: train acc 0.038462 test acc 0.028817\n",
            "Epoch 1: train loss 4.213653 test loss 3.667925\n",
            "Epoch 1: train acc 0.038462 test acc 0.029140\n",
            "Epoch 1: train loss 3.763105 test loss 3.557149\n",
            "Epoch 1: train acc 0.000000 test acc 0.034086\n",
            "Epoch 1: train loss 3.522164 test loss 3.518077\n",
            "Epoch 1: train acc 0.038462 test acc 0.033548\n",
            "Epoch 1: train loss 3.533193 test loss 3.527568\n",
            "Epoch 1: train acc 0.000000 test acc 0.033763\n",
            "Epoch 1: train loss 3.521318 test loss 3.558496\n",
            "Epoch 1: train acc 0.000000 test acc 0.048925\n",
            "Epoch 1: train loss 3.699335 test loss 3.568287\n",
            "Epoch 1: train acc 0.076923 test acc 0.035484\n",
            "Epoch 1: train loss 3.605795 test loss 3.523944\n",
            "Epoch 1: train acc 0.076923 test acc 0.046882\n",
            "Epoch 1: train loss 3.426867 test loss 3.539318\n",
            "Epoch 1: train acc 0.115385 test acc 0.061613\n",
            "Epoch 1: train loss 3.515974 test loss 3.565132\n",
            "Epoch 1: train acc 0.038462 test acc 0.055054\n",
            "Epoch 1: train loss 3.572105 test loss 3.586787\n",
            "Epoch 1: train acc 0.038462 test acc 0.065484\n",
            "Epoch 1: train loss 3.618927 test loss 3.576836\n",
            "Epoch 1: train acc 0.038462 test acc 0.084839\n",
            "Epoch 1: train loss 3.360588 test loss 3.589092\n",
            "Epoch 1: train acc 0.115385 test acc 0.071075\n",
            "Epoch 1: train loss 3.580542 test loss 3.562987\n",
            "Epoch 1: train acc 0.076923 test acc 0.073763\n",
            "Epoch 1: train loss 3.725374 test loss 3.522573\n",
            "Epoch 1: train acc 0.076923 test acc 0.070430\n",
            "Epoch 1: train loss 3.441074 test loss 3.571813\n",
            "Epoch 1: train acc 0.153846 test acc 0.058925\n",
            "Epoch 1: train loss 3.385863 test loss 3.674236\n",
            "Epoch 1: train acc 0.115385 test acc 0.043978\n",
            "Epoch 1: train loss 3.618627 test loss 3.763197\n",
            "Epoch 1: train acc 0.076923 test acc 0.037312\n",
            "Epoch 1: train loss 3.544576 test loss 3.762439\n",
            "Epoch 1: train acc 0.038462 test acc 0.040108\n",
            "Epoch 1: train loss 4.035508 test loss 3.643008\n",
            "Epoch 1: train acc 0.000000 test acc 0.040968\n",
            "Epoch 1: train loss 3.616982 test loss 3.626591\n",
            "Epoch 1: train acc 0.076923 test acc 0.033333\n",
            "Epoch 1: train loss 3.428652 test loss 3.664124\n",
            "Epoch 1: train acc 0.038462 test acc 0.033656\n",
            "Epoch 1: train loss 3.664946 test loss 3.638490\n",
            "Epoch 1: train acc 0.038462 test acc 0.042581\n",
            "Epoch 1: train loss 3.497329 test loss 3.666585\n",
            "Epoch 1: train acc 0.115385 test acc 0.033118\n",
            "Epoch 1: train loss 3.684133 test loss 3.636219\n",
            "Epoch 1: train acc 0.000000 test acc 0.033333\n",
            "Epoch 1: train loss 3.720089 test loss 3.575209\n",
            "Epoch 1: train acc 0.038462 test acc 0.034086\n",
            "Epoch 1: train loss 3.688870 test loss 3.593878\n",
            "Epoch 1: train acc 0.038462 test acc 0.035054\n",
            "Epoch 1: train loss 4.048226 test loss 3.613247\n",
            "Epoch 1: train acc 0.000000 test acc 0.050968\n",
            "Epoch 1: train loss 3.968774 test loss 3.560397\n",
            "Epoch 1: train acc 0.000000 test acc 0.064301\n",
            "Epoch 1: train loss 3.460520 test loss 3.569063\n",
            "Epoch 1: train acc 0.038462 test acc 0.093118\n",
            "Epoch 1: train loss 3.259133 test loss 3.620846\n",
            "Epoch 1: train acc 0.115385 test acc 0.094516\n",
            "Epoch 1: train loss 3.695837 test loss 3.701375\n",
            "Epoch 1: train acc 0.076923 test acc 0.066237\n",
            "Epoch 1: train loss 3.877168 test loss 3.765503\n",
            "Epoch 1: train acc 0.115385 test acc 0.053118\n",
            "Epoch 1: train loss 3.792719 test loss 3.736598\n",
            "Epoch 1: train acc 0.038462 test acc 0.042581\n",
            "Epoch 1: train loss 3.626951 test loss 3.724505\n",
            "Epoch 1: train acc 0.076923 test acc 0.033656\n",
            "Epoch 1: train loss 3.523898 test loss 3.757673\n",
            "Epoch 1: train acc 0.076923 test acc 0.030323\n",
            "Epoch 1: train loss 3.570896 test loss 3.717254\n",
            "Epoch 1: train acc 0.153846 test acc 0.030323\n",
            "Epoch 1: train loss 3.531380 test loss 3.657522\n",
            "Epoch 1: train acc 0.076923 test acc 0.033763\n",
            "Epoch 1: train loss 3.700827 test loss 3.640136\n",
            "Epoch 1: train acc 0.000000 test acc 0.047634\n",
            "Epoch 1: train loss 3.890564 test loss 3.680723\n",
            "Epoch 1: train acc 0.038462 test acc 0.033441\n",
            "Epoch 1: train loss 3.754672 test loss 3.728959\n",
            "Epoch 1: train acc 0.000000 test acc 0.042796\n",
            "Epoch 1: train loss 3.911176 test loss 3.745290\n",
            "Epoch 1: train acc 0.000000 test acc 0.043226\n",
            "Epoch 1: train loss 3.654780 test loss 3.744105\n",
            "Epoch 1: train acc 0.000000 test acc 0.035806\n",
            "Epoch 1: train loss 3.754589 test loss 3.694338\n",
            "Epoch 1: train acc 0.000000 test acc 0.059677\n",
            "Epoch 1: train loss 3.852155 test loss 3.646447\n",
            "Epoch 1: train acc 0.076923 test acc 0.058280\n",
            "Epoch 1: train loss 3.584071 test loss 3.597812\n",
            "Epoch 1: train acc 0.076923 test acc 0.055484\n",
            "Epoch 1: train loss 3.755383 test loss 3.609363\n",
            "Epoch 1: train acc 0.076923 test acc 0.058280\n",
            "Epoch 1: train loss 3.419378 test loss 3.666819\n",
            "Epoch 1: train acc 0.076923 test acc 0.029785\n",
            "Epoch 1: train loss 3.679040 test loss 3.670708\n",
            "Epoch 1: train acc 0.000000 test acc 0.033871\n",
            "Epoch 1: train loss 3.926579 test loss 3.584647\n",
            "Epoch 1: train acc 0.000000 test acc 0.060215\n",
            "Epoch 1: train loss 3.841542 test loss 3.582964\n",
            "Epoch 1: train acc 0.076923 test acc 0.065054\n",
            "Epoch 1: train loss 3.406921 test loss 3.720877\n",
            "Epoch 1: train acc 0.076923 test acc 0.055054\n",
            "Epoch 1: train loss 3.996701 test loss 3.755215\n",
            "Epoch 1: train acc 0.038462 test acc 0.034301\n",
            "Epoch 1: train loss 3.585716 test loss 3.677030\n",
            "Epoch 1: train acc 0.076923 test acc 0.032151\n",
            "Epoch 1: train loss 3.758408 test loss 3.618582\n",
            "Epoch 1: train acc 0.000000 test acc 0.029355\n",
            "Epoch 1: train loss 3.760998 test loss 3.598965\n",
            "Epoch 1: train acc 0.000000 test acc 0.034946\n",
            "Epoch 1: train loss 3.681540 test loss 3.619531\n",
            "Epoch 1: train acc 0.038462 test acc 0.035269\n",
            "Epoch 1: train loss 3.718134 test loss 3.558268\n",
            "Epoch 1: train acc 0.000000 test acc 0.035269\n",
            "Epoch 1: train loss 3.773438 test loss 3.504040\n",
            "Epoch 1: train acc 0.000000 test acc 0.037419\n",
            "Epoch 1: train loss 3.411293 test loss 3.547336\n",
            "Epoch 1: train acc 0.000000 test acc 0.055591\n",
            "Epoch 1: train loss 3.573018 test loss 3.664253\n",
            "Epoch 1: train acc 0.076923 test acc 0.033441\n",
            "Epoch 1: train loss 3.127912 test loss 3.837765\n",
            "Epoch 1: train acc 0.115385 test acc 0.031505\n",
            "Epoch 1: train loss 4.265512 test loss 3.729487\n",
            "Epoch 1: train acc 0.000000 test acc 0.057742\n",
            "Epoch 1: train loss 3.934952 test loss 3.662837\n",
            "Epoch 1: train acc 0.076923 test acc 0.064086\n",
            "Epoch 1: train loss 4.165048 test loss 3.650109\n",
            "Epoch 1: train acc 0.038462 test acc 0.055484\n",
            "Epoch 1: train loss 3.335811 test loss 3.736711\n",
            "Epoch 1: train acc 0.153846 test acc 0.029892\n",
            "Epoch 1: train loss 3.669423 test loss 3.816123\n",
            "Epoch 1: train acc 0.000000 test acc 0.030860\n",
            "Epoch 1: train loss 3.851202 test loss 3.785143\n",
            "Epoch 1: train acc 0.000000 test acc 0.032366\n",
            "Epoch 1: train loss 3.865860 test loss 3.656817\n",
            "Epoch 1: train acc 0.038462 test acc 0.044516\n",
            "Epoch 1: train loss 3.615099 test loss 3.625572\n",
            "Epoch 1: train acc 0.115385 test acc 0.065376\n",
            "Epoch 1: train loss 3.839650 test loss 3.745958\n",
            "Epoch 1: train acc 0.038462 test acc 0.063656\n",
            "Epoch 1: train loss 3.955060 test loss 3.767965\n",
            "Epoch 1: train acc 0.000000 test acc 0.049462\n",
            "Epoch 1: train loss 3.838815 test loss 3.702412\n",
            "Epoch 1: train acc 0.038462 test acc 0.053118\n",
            "Epoch 1: train loss 3.690899 test loss 3.594005\n",
            "Epoch 1: train acc 0.000000 test acc 0.043978\n",
            "Epoch 1: train loss 3.953408 test loss 3.526719\n",
            "Epoch 1: train acc 0.000000 test acc 0.033333\n",
            "Epoch 1: train loss 3.431573 test loss 3.590400\n",
            "Epoch 1: train acc 0.038462 test acc 0.031398\n",
            "Epoch 1: train loss 3.488176 test loss 3.678291\n",
            "Epoch 1: train acc 0.192308 test acc 0.034301\n",
            "Epoch 1: train loss 3.644156 test loss 3.746331\n",
            "Epoch 1: train acc 0.076923 test acc 0.034194\n",
            "Epoch 1: train loss 3.797008 test loss 3.709207\n",
            "Epoch 1: train acc 0.038462 test acc 0.032473\n",
            "Epoch 1: train loss 3.490226 test loss 3.612250\n",
            "Epoch 1: train acc 0.038462 test acc 0.032903\n",
            "Epoch 1: train loss 3.590656 test loss 3.563380\n",
            "Epoch 1: train acc 0.038462 test acc 0.076882\n",
            "Epoch 1: train loss 3.366030 test loss 3.649369\n",
            "Epoch 1: train acc 0.115385 test acc 0.059355\n",
            "Epoch 1: train loss 3.782028 test loss 3.721193\n",
            "Epoch 1: train acc 0.000000 test acc 0.055806\n",
            "Epoch 1: train loss 4.214068 test loss 3.641287\n",
            "Epoch 1: train acc 0.076923 test acc 0.076022\n",
            "Epoch 1: train loss 3.766480 test loss 3.587365\n",
            "Epoch 1: train acc 0.038462 test acc 0.054731\n",
            "Epoch 1: train loss 3.480272 test loss 3.555017\n",
            "Epoch 1: train acc 0.038462 test acc 0.046022\n",
            "Epoch 1: train loss 3.918915 test loss 3.483246\n",
            "Epoch 1: train acc 0.000000 test acc 0.066452\n",
            "Epoch 1: train loss 3.525974 test loss 3.495911\n",
            "Epoch 1: train acc 0.038462 test acc 0.061290\n",
            "Epoch 1: train loss 3.323220 test loss 3.585610\n",
            "Epoch 1: train acc 0.076923 test acc 0.065269\n",
            "Epoch 1: train loss 3.153609 test loss 3.691262\n",
            "Epoch 1: train acc 0.153846 test acc 0.065269\n",
            "Epoch 1: train loss 3.813142 test loss 3.689272\n",
            "Epoch 1: train acc 0.076923 test acc 0.066452\n",
            "Epoch 1: train loss 3.609578 test loss 3.667223\n",
            "Epoch 1: train acc 0.038462 test acc 0.062151\n",
            "Epoch 1: train loss 3.774961 test loss 3.600486\n",
            "Epoch 1: train acc 0.076923 test acc 0.060753\n",
            "Epoch 1: train loss 3.581682 test loss 3.559661\n",
            "Epoch 1: train acc 0.153846 test acc 0.054839\n",
            "Epoch 1: train loss 3.615378 test loss 3.569084\n",
            "Epoch 1: train acc 0.000000 test acc 0.034301\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-02ca5a03fde5>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mtesr_correct_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtest_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-02ca5a03fde5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install openpyxl\n",
        "!pip install torch\n",
        "# Neural Network Model\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load CSV data from Google Drive\n",
        "file_path = '/content/drive/My Drive/Ramanspec.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assume the CSV file has a 'target' column and features\n",
        "# Adjust this based on your dataset\n",
        "X = df.drop('label', axis=1).values\n",
        "y = df['label'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.Tensor(X_train)\n",
        "y_train = torch.Tensor(y_train).view(-1, 1)\n",
        "X_test = torch.Tensor(X_test)\n",
        "y_test = torch.Tensor(y_test).view(-1, 1)\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X_train.shape[1]\n",
        "model = SimpleNN(input_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i+batch_size]\n",
        "        labels = y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "# Linear Regression Model\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Load CSV data from Google Drive\n",
        "file_path = '/content/drive/My Drive/Ramanspec.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assume the CSV file has a 'target' column and features\n",
        "# Adjust this based on your dataset\n",
        "X = df.drop('label', axis=1).values\n",
        "y = df['label'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data (optional but can be beneficial for linear regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Instantiate the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R^2 Score: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWPjxWDHE4A7",
        "outputId": "941a3f3c-28a9-4a8f-e7d9-ab65e5008c24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/10], Loss: 24.3670\n",
            "Epoch [2/10], Loss: 11.8204\n",
            "Epoch [3/10], Loss: 9.2096\n",
            "Epoch [4/10], Loss: 6.7472\n",
            "Epoch [5/10], Loss: 5.2288\n",
            "Epoch [6/10], Loss: 4.4195\n",
            "Epoch [7/10], Loss: 3.3215\n",
            "Epoch [8/10], Loss: 2.8524\n",
            "Epoch [9/10], Loss: 2.6055\n",
            "Epoch [10/10], Loss: 2.2503\n",
            "Test Loss: 13.1153\n",
            "Mean Squared Error: 32.8870\n",
            "R^2 Score: 0.5884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Comparison Model\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assume X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Preprocess your data as needed before this step\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "\n",
        "X_train_tensor = torch.Tensor(X_train)\n",
        "y_train_tensor = torch.Tensor(y_train).view(-1, 1)\n",
        "X_test_tensor = torch.Tensor(X_test)\n",
        "y_test_tensor = torch.Tensor(y_test).view(-1, 1)\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the models\n",
        "input_size = X_train.shape[1]\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "neural_net_model = SimpleNN(input_size)\n",
        "\n",
        "# Train the linear regression model\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Train the neural network model\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(neural_net_model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        inputs = X_train_tensor[i:i+batch_size]\n",
        "        labels = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = neural_net_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate linear regression model\n",
        "linear_pred_train = linear_model.predict(X_train)\n",
        "linear_pred_test = linear_model.predict(X_test)\n",
        "\n",
        "linear_mse_train = mean_squared_error(y_train, linear_pred_train)\n",
        "linear_mse_test = mean_squared_error(y_test, linear_pred_test)\n",
        "linear_r2_train = r2_score(y_train, linear_pred_train)\n",
        "linear_r2_test = r2_score(y_test, linear_pred_test)\n",
        "\n",
        "print(\"Linear Regression Results:\")\n",
        "print(f\"Train MSE: {linear_mse_train:.4f}, Test MSE: {linear_mse_test:.4f}\")\n",
        "print(f\"Train R^2: {linear_r2_train:.4f}, Test R^2: {linear_r2_test:.4f}\")\n",
        "\n",
        "# Evaluate neural network model\n",
        "neural_net_model.eval()\n",
        "with torch.no_grad():\n",
        "    neural_net_pred_train = neural_net_model(X_train_tensor).numpy()\n",
        "    neural_net_pred_test = neural_net_model(X_test_tensor).numpy()\n",
        "\n",
        "neural_net_mse_train = mean_squared_error(y_train, neural_net_pred_train)\n",
        "neural_net_mse_test = mean_squared_error(y_test, neural_net_pred_test)\n",
        "neural_net_r2_train = r2_score(y_train, neural_net_pred_train)\n",
        "neural_net_r2_test = r2_score(y_test, neural_net_pred_test)\n",
        "\n",
        "print(\"\\nNeural Network Results:\")\n",
        "print(f\"Train MSE: {neural_net_mse_train:.4f}, Test MSE: {neural_net_mse_test:.4f}\")\n",
        "print(f\"Train R^2: {neural_net_r2_train:.4f}, Test R^2: {neural_net_r2_test:.4f}\")\n",
        "\n",
        "\n",
        "# Linear Regression 2nd Model\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from google.colab import drive\n",
        "\n",
        "# Load CSV data from Google Drive\n",
        "file_path = '/content/drive/My Drive/Ramanspec.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assume the CSV file has a 'target' column and features\n",
        "# Adjust this based on your dataset\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# Feature engineering: Adding polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Instantiate the Ridge Regression model\n",
        "model = Ridge(alpha=1.0)  # You can adjust the alpha parameter for regularization\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R^2 Score: {r2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hzETTTrGJjO0",
        "outputId": "e200b98d-f9a8-4d87-aaae-60de1f53df53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c9c73e1fa215>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Convert data to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import History\n",
        "\n",
        "# Assuming you have defined and compiled your model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create a History callback to record the training history\n",
        "history = History()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=[history])\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_learning_curve(history)\n",
        "\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have a variable `history` containing the training history of your neural network\n",
        "# Replace `history` with the actual variable name you are using\n",
        "plot_learning_curve(history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UhwWr2ftKNqS",
        "outputId": "04fedea6-486c-4c45-a743-49bcd1403632"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b625e2a6f43b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Assuming you have defined and compiled your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model = Sequential([\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}